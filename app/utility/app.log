2025-09-12 15:28:02,429 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:28:02,430 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:28:02,430 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:28:02,430 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:28:02,432 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:28:02,432 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:28:02,432 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:28:02,552 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:28:02,552 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:28:02,552 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:28:02,557 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:28:02,557 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:28:03,069 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:28:03,070 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:28:03,070 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:28:03,071 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:28:03,071 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:28:03,071 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:28:03,172 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:28:03,172 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:28:03,172 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:28:03,174 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:28:03,174 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:28:03,174 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:28:03,174 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:28:03,174 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:28:03,174 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:28:03,174 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:28:03,174 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:28:03,175 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:28:03,175 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:28:03,175 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:28:03,260 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:28:03,261 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:28:03,261 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:28:03,263 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:28:03,263 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:28:03,298 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:28:03,300 [INFO] main: Creating FastAPI app
2025-09-12 15:28:03,300 [INFO] main: CORS middleware added
2025-09-12 15:28:03,302 [INFO] main: API router included
2025-09-12 15:28:42,355 [INFO] app.services.pipeline_orchestrator_service: Starting pipeline processing - prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?
2025-09-12 15:28:42,356 [INFO] app.services.pipeline_orchestrator_service: Resetting PipelineOrchestrator attributes for new query
2025-09-12 15:28:42,356 [INFO] app.services.pipeline_orchestrator_service: Running sanity checks for prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?, conversation: [], conv_history: 
2025-09-12 15:28:42,356 [DEBUG] app.features.sanity_checks.sanity_checks_analyst: run_checks called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?, conversation=[], conv_history=, checks_to_run=['conversation_limit', 'message_length', 'message_pertinence']
2025-09-12 15:28:42,356 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst running checks: ['conversation_limit', 'message_length', 'message_pertinence'] for user_input: Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?
2025-09-12 15:28:42,357 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check medical pertinence prompt sent to LLM.
2025-09-12 15:28:42,361 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nÉvaluez si le message suivant a un rapport avec la santé humaine ou les services de soins.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur la santé.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes de discussions médicales.\nATTENTION: Toute question sur la méthodologie, la fréquence de mise à jour, les critères, ou le fonctionnement du classement des hôpitaux doit TOUJOURS être considérée comme pertinente, même si elle ne concerne pas directement une maladie ou un service de soins.\n\nRépondez UNIQUEMENT avec 1 si pertinent, 0 si non pertinent ou 2 si la question concerne la méthodologie de calcul du classement.\n\nExemples pour messages standalone (repondre 1): \n- \'J\'ai un cancer à Paris\' → 1\n- \'Cataracte\' → 1  \n- \'J\'ai mal aux pieds\' → 1\n- \'Les hôpitaux privés sont ils meilleurs que les publiques?\' → 1\n- \'Comment le classement est-il calculé ?\' → 1\n- \'Quels sont les critères du classement ?\' → 1\n- "Quels experts participent à l\'élaboration du classement ?"\' → 1\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\' → 1\n- "Comment sont traitées les données manquantes dans le classement ?"\' → 1\n- "Le classement est-il le même pour toutes les spécialités ?"\' → 1\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\' → 1\n- "Quels sont les changements dans la méthodologie cette année ?"\' → 1\n- "Comment puis-je accéder au détail de la méthodologie ?"\' → 1\n\nExemples pour messages standalone (repondre 0):\n- \'Je mange des frites\' → 0\n- \'Comment faire une tarte aux pommes ?\' → 0\n- \'Comment s\'abonner Le Point ?\' → 0\n- \'Quel est le meilleur restaurant à Paris ?\' → 0\n\n\nExemples de questions qui concernent la méthodologie de classement (repondre 2):\n- "Comment le classement est-il calculé ?"\n- "Quels sont les critères du classement ?" \n- "Pourquoi l\'hôpital X est mieux classé que Y ?"\n- "Comment sont choisis les critères du classement ?"\n- "Qui réalise le classement des hôpitaux ?"\n- "Quelle est la source des données utilisées pour le classement ?"\n- "Le classement prend-il en compte la satisfaction des patients ?"\n- "Comment sont pondérés les différents critères ?"\n- "Est-ce que le classement est mis à jour chaque année ?"\n- "Pourquoi certains hôpitaux ne figurent pas dans le classement ?"\n- "Comment puis-je vérifier la fiabilité du classement ?"\n- "Quels experts participent à l\'élaboration du classement ?"\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\n- "Comment sont traitées les données manquantes dans le classement ?"\n- "Le classement est-il le même pour toutes les spécialités ?"\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\n- "Quels sont les changements dans la méthodologie cette année ?"\n- "Comment puis-je accéder au détail de la méthodologie ?"\n\nExemples pour messages avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique montrant une discussion sur les hôpitaux, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur la cardiologie, \'Merci\' → 1 (remerciement dans contexte médical)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n- Même avec contexte médical, \'Parle-moi de football\' → 0 (hors-sujet)\n- Avec historique sur les classements, "Comment sont déterminés les scores ?" → 2 (question sur la méthodologie de classement)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:42,393 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:42,394 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-09-12 15:28:42,434 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11c9e7a10>
2025-09-12 15:28:42,434 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x11c79bda0> server_hostname='api.openai.com' timeout=None
2025-09-12 15:28:42,458 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11ca1df90>
2025-09-12 15:28:42,458 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:42,459 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:42,459 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:42,459 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:42,459 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:43,474 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'411'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'543'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'198879'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'336ms'), (b'x-request-id', b'req_daa030e1055448de9188f237bb303c7e'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=HaPOCRr_Px22C8oPf2nQ4OEHojwShX10_m.2qVpX8gc-1757683723-1.0.1.1-MEj1.R_N3GSuGAdbeDNnf6f763zZVz9Ad98dAPZvBcn_p2kAtrtJeyPll.5O4gKirxnfWWl09R1NnTFQGGaisdsBsvJRmipzBi8Cl263uoE; path=/; expires=Fri, 12-Sep-25 13:58:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=aagpmvtmZ87JkePpdOBEh8ejAM7aLr5vNrV1gl.sm9g-1757683723512-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfbfe1ba5e70e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:43,475 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:43,476 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:43,478 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:43,478 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:43,478 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:43,478 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 12 Sep 2025 13:28:43 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'le-point-hv3izr'), ('openai-processing-ms', '411'), ('openai-project', 'proj_auvPnKXq8lce0dksWKRj2pvx'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '543'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '198879'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '336ms'), ('x-request-id', 'req_daa030e1055448de9188f237bb303c7e'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=HaPOCRr_Px22C8oPf2nQ4OEHojwShX10_m.2qVpX8gc-1757683723-1.0.1.1-MEj1.R_N3GSuGAdbeDNnf6f763zZVz9Ad98dAPZvBcn_p2kAtrtJeyPll.5O4gKirxnfWWl09R1NnTFQGGaisdsBsvJRmipzBi8Cl263uoE; path=/; expires=Fri, 12-Sep-25 13:58:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=aagpmvtmZ87JkePpdOBEh8ejAM7aLr5vNrV1gl.sm9g-1757683723512-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '97dfbfe1ba5e70e6-MRS'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-12 15:28:43,479 [DEBUG] openai._base_client: request_id: req_daa030e1055448de9188f237bb303c7e
2025-09-12 15:28:43,485 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_medical_pertinence' successful: {'prompt_tokens': 1111, 'completion_tokens': 1, 'total_tokens': 1112}, cost=0.00016724999999999997
2025-09-12 15:28:43,486 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for medical pertinence:
1
2025-09-12 15:28:43,486 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed medical pertinence value: 1 (type: <class 'int'>)
2025-09-12 15:28:43,486 [DEBUG] app.features.sanity_checks.message_pertinence_check: medical_pertinence_result: {'result': 1, 'cost': 0.00016724999999999997, 'token_usage': 1112}
2025-09-12 15:28:43,486 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check chatbot pertinence prompt sent to LLM.
2025-09-12 15:28:43,489 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nVérifiez si cette question concerne le classement des hôpitaux.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur les classements d\'hôpitaux.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes.\n\nRépondez UNIQUEMENT avec:\n- 1 si la question est pertinente pour le chatbot (classement, recherche d\'établissement, etc.)\n- 0 si la question n\'est pas pertinente\n\nUne question est pertinente si elle concerne au moins un des cas suivants:\n- Une maladie, un symptôme ou une spécialité médicale  \n- Le classement des hôpitaux et cliniques  \n- La recherche d\'un hôpital, d\'une clinique ou d\'un service médical  \n- Une question de suivi sur les secteurs public/privé des hôpitaux\n\nExemples de questions pertinentes pour messages standalone (repondre 1):  \n- Quel est la meilleur clinique de France ?\n- Conseille moi un hôpital à Lyon \n- Je chercher un service de pneumologie\n- Où faire soigner mon glaucome ? \n- Je veux corriger mon audition\n- Il y a fréquemment du sang dans mes urines. Conseille-moi un hôpital. \n- Je veux cherche à faire soigner mes troubles bipôlaires\n- Est-ce que l\'Institut mutualiste Montsouris est bon ?\n- Y a-t-il des hôpitaux privés avec un service de cardiologie interventionnelle ?\n\nExemples de questions non pertinentes pour messages standalone (repondre 0):  \n- Pourquoi les hôpitaux sont-ils en crise ?  #Il s\'agit d\'une demande d\'information qui n\'est pas dans le cadre direct de la recherche d\'un établissement de soin\n- Dois-je prendre du paracétamol pour ma fièvre ? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n- Puis-je perdre la vue si j\'ai un glaucome? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n\n\n\nExemples avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique sur les hôpitaux parisiens, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur les classements, \'Combien coûte une consultation ?\' → 0 (question sur les coûts, pas sur les classements)\n- Avec historique sur la recherche d\'hôpital, \'Merci beaucoup\' → 1 (remerciement dans contexte de recherche d\'hôpital)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:43,490 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:43,490 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:43,490 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:43,491 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:43,491 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:43,491 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:44,282 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'186'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'331'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199170'), (b'x-ratelimit-reset-requests', b'16.253s'), (b'x-ratelimit-reset-tokens', b'249ms'), (b'x-request-id', b'req_a797848d83844614b9d0a65ce63fceb1'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfbfe828d370e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:44,283 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:44,283 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:44,283 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:44,283 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:44,283 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:44,283 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '186', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '331', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199170', 'x-ratelimit-reset-requests': '16.253s', 'x-ratelimit-reset-tokens': '249ms', 'x-request-id': 'req_a797848d83844614b9d0a65ce63fceb1', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfbfe828d370e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:44,284 [DEBUG] openai._base_client: request_id: req_a797848d83844614b9d0a65ce63fceb1
2025-09-12 15:28:44,284 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_chatbot_pertinence' successful: {'prompt_tokens': 809, 'completion_tokens': 1, 'total_tokens': 810}, cost=0.00012195
2025-09-12 15:28:44,284 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for chatbot pertinence:
1
2025-09-12 15:28:44,284 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed chatbot pertinence value: 1 (type: <class 'int'>)
2025-09-12 15:28:44,285 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst completed checks. All passed: True, Total cost: 0.0002892, Total tokens: 1922
2025-09-12 15:28:44,285 [INFO] app.features.sanity_checks.sanity_checks_analyst: Sanity check results: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.0002892, 'token_usage': 1922}, 'passed': True, 'total_cost': 0.0002892, 'total_tokens': 1922}
2025-09-12 15:28:44,285 [INFO] app.services.pipeline_orchestrator_service: Sanity checks result: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.0002892, 'token_usage': 1922}, 'passed': True, 'total_cost': 0.0002892, 'total_tokens': 1922}
2025-09-12 15:28:44,285 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?', detected_specialty='None', conv_history=''
2025-09-12 15:28:44,285 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 15:28:44,285 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 15:28:44,285 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 15:28:44,285 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 15:28:44,486 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:28:44,486 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?, conv_history: 
2025-09-12 15:28:44,487 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'
2025-09-12 15:28:44,489 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:44,490 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:44,490 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:44,490 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:44,490 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:44,491 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:44,491 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:45,358 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'259'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'420'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199554'), (b'x-ratelimit-reset-requests', b'23.884s'), (b'x-ratelimit-reset-tokens', b'133ms'), (b'x-request-id', b'req_65800cb9cf5546faa23d9a5b2de64497'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfbfee6f0170e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:45,359 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:45,359 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:45,364 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:45,364 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:45,365 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:45,365 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '259', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '420', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '199554', 'x-ratelimit-reset-requests': '23.884s', 'x-ratelimit-reset-tokens': '133ms', 'x-request-id': 'req_65800cb9cf5546faa23d9a5b2de64497', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfbfee6f0170e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:45,365 [DEBUG] openai._base_client: request_id: req_65800cb9cf5546faa23d9a5b2de64497
2025-09-12 15:28:45,366 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 430, 'completion_tokens': 5, 'total_tokens': 435}, cost=6.75e-05
2025-09-12 15:28:45,366 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer de la vessie, method: llm
2025-09-12 15:28:45,366 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer de la vessie', 'detection_method': 'llm', 'cost': 6.75e-05, 'token_usage': 0}
2025-09-12 15:28:45,366 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?', conv_history: ''
2025-09-12 15:28:45,369 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:45,369 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:45,370 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:45,370 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:45,370 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:45,370 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:45,370 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:45,702 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'168'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'184'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'23.45s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_52c9f03b1ef842d08cf2e6fc76cf031e'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfbff3ec7f70e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:45,702 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:45,703 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:45,707 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:45,707 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:45,707 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:45,708 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '168', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '184', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '23.45s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_52c9f03b1ef842d08cf2e6fc76cf031e', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfbff3ec7f70e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:45,708 [DEBUG] openai._base_client: request_id: req_52c9f03b1ef842d08cf2e6fc76cf031e
2025-09-12 15:28:45,709 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 198, 'completion_tokens': 1, 'total_tokens': 199}, cost=3.03e-05
2025-09-12 15:28:45,712 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:45,713 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:45,713 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:45,713 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:45,714 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:45,714 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:45,714 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:46,074 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'170'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'183'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'199649'), (b'x-ratelimit-reset-requests', b'31.744s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_9694191394214383ad3ac17e96aef90b'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfbff60ed470e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:46,075 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:46,075 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:46,075 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:46,076 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:46,076 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:46,076 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '170', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '183', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9996', 'x-ratelimit-remaining-tokens': '199649', 'x-ratelimit-reset-requests': '31.744s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_9694191394214383ad3ac17e96aef90b', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfbff60ed470e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:46,076 [DEBUG] openai._base_client: request_id: req_9694191394214383ad3ac17e96aef90b
2025-09-12 15:28:46,077 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}, cost=4.8e-05
2025-09-12 15:28:46,077 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.83e-05, tokens={'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}
2025-09-12 15:28:46,077 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': 'Paris', 'detection_method': 'llm', 'cost': 7.83e-05, 'status_code': 3, 'token_usage': {'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}}
2025-09-12 15:28:46,077 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?, conv_history=
2025-09-12 15:28:46,080 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:46,080 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:46,081 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:46,081 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:46,081 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:46,081 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:46,081 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:47,055 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'253'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'415'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'199782'), (b'x-ratelimit-reset-requests', b'48.096s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_06fa1f194516468a8d6b244ba47ff3cd'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfbff8595270e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:47,055 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:47,056 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:47,056 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:47,056 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:47,056 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:47,057 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '253', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '415', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9994', 'x-ratelimit-remaining-tokens': '199782', 'x-ratelimit-reset-requests': '48.096s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_06fa1f194516468a8d6b244ba47ff3cd', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfbff8595270e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:47,057 [DEBUG] openai._base_client: request_id: req_06fa1f194516468a8d6b244ba47ff3cd
2025-09-12 15:28:47,058 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 198, 'completion_tokens': 1, 'total_tokens': 199}, cost=3.03e-05
2025-09-12 15:28:47,060 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:47,061 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:47,061 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:47,062 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:47,062 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:47,062 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:47,062 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:47,758 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'127'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'270'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'199649'), (b'x-ratelimit-reset-requests', b'47.262s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_d96b9336e4e4440ea5c4308945b4b3c5'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfbffe7f3a70e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:47,758 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:47,758 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:47,761 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:47,761 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:47,761 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:47,761 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '127', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '270', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9994', 'x-ratelimit-remaining-tokens': '199649', 'x-ratelimit-reset-requests': '47.262s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_d96b9336e4e4440ea5c4308945b4b3c5', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfbffe7f3a70e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:47,761 [DEBUG] openai._base_client: request_id: req_d96b9336e4e4440ea5c4308945b4b3c5
2025-09-12 15:28:47,762 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}, cost=4.8e-05
2025-09-12 15:28:47,762 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.83e-05, tokens={'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}
2025-09-12 15:28:47,762 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 3, 'city_detected': True, 'city': 'Paris', 'detection_method': 'llm', 'cost': 7.83e-05, 'token_usage': 317}
2025-09-12 15:28:47,762 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?' with conv_history: ''
2025-09-12 15:28:47,765 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:47,766 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:47,766 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:47,766 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:47,766 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:47,767 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:47,767 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:48,248 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'331'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'345'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'198987'), (b'x-ratelimit-reset-requests', b'55.62s'), (b'x-ratelimit-reset-tokens', b'303ms'), (b'x-request-id', b'req_eb497b73bc67408598ba2ac895db4d42'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfc002ebb570e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:48,249 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:48,249 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:48,251 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:48,251 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:48,251 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:48,251 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '331', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '345', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9993', 'x-ratelimit-remaining-tokens': '198987', 'x-ratelimit-reset-requests': '55.62s', 'x-ratelimit-reset-tokens': '303ms', 'x-request-id': 'req_eb497b73bc67408598ba2ac895db4d42', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfc002ebb570e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:48,252 [DEBUG] openai._base_client: request_id: req_eb497b73bc67408598ba2ac895db4d42
2025-09-12 15:28:48,252 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1092, 'completion_tokens': 15, 'total_tokens': 1107}, cost=0.0001728
2025-09-12 15:28:48,253 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 15:28:48,253 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 15:28:48,253 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': [], 'intent': 'none'}
2025-09-12 15:28:48,253 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: [], intent: none, cost: 0.0001728, token_usage: {'prompt_tokens': 1092, 'completion_tokens': 15, 'total_tokens': 1107}
2025-09-12 15:28:48,253 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | []
2025-09-12 15:28:48,253 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=[] and institution_list length=553)
2025-09-12 15:28:48,253 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: []
2025-09-12 15:28:48,253 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: none
2025-09-12 15:28:48,253 [INFO] app.features.query_analysis.institution_names.institution_names_validation: No specific institution detected
2025-09-12 15:28:48,254 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': None, 'institution_name_mentioned': False, 'error': 'No institution detected', 'intent': 'none', 'detection_method': 'llm', 'cost': 0.0001728, 'token_usage': 1107}
2025-09-12 15:28:48,256 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:48,257 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:48,257 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:48,258 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:48,258 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:48,258 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:48,258 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:48,575 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'170'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'191'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'199782'), (b'x-ratelimit-reset-requests', b'55.132s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_5c70e11597324deba425e02408e9072b'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfc005fe5870e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:48,575 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:48,576 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:48,583 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:48,583 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:48,583 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:48,583 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '170', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '191', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9993', 'x-ratelimit-remaining-tokens': '199782', 'x-ratelimit-reset-requests': '55.132s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_5c70e11597324deba425e02408e9072b', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfc005fe5870e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:48,583 [DEBUG] openai._base_client: request_id: req_5c70e11597324deba425e02408e9072b
2025-09-12 15:28:48,584 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 213, 'completion_tokens': 1, 'total_tokens': 214}, cost=3.255e-05
2025-09-12 15:28:48,584 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.255e-05, {'prompt_tokens': 213, 'completion_tokens': 1, 'total_tokens': 214}
2025-09-12 15:28:48,584 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.255e-05, 'token_usage': 214}
2025-09-12 15:28:48,587 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:48,588 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:48,588 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:48,588 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:48,588 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:48,589 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:48,589 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:48,994 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'240'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'255'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9992'), (b'x-ratelimit-remaining-tokens', b'199679'), (b'x-ratelimit-reset-requests', b'1m3.429s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_d77302b3ff724f58b1e88e317896b6b6'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfc008083e70e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:48,994 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:48,994 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:48,998 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:48,998 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:48,998 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:48,999 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '240', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '255', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9992', 'x-ratelimit-remaining-tokens': '199679', 'x-ratelimit-reset-requests': '1m3.429s', 'x-ratelimit-reset-tokens': '96ms', 'x-request-id': 'req_d77302b3ff724f58b1e88e317896b6b6', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfc008083e70e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:48,999 [DEBUG] openai._base_client: request_id: req_d77302b3ff724f58b1e88e317896b6b6
2025-09-12 15:28:48,999 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 309, 'completion_tokens': 1, 'total_tokens': 310}, cost=4.6949999999999996e-05
2025-09-12 15:28:49,000 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.6949999999999996e-05, {'prompt_tokens': 309, 'completion_tokens': 1, 'total_tokens': 310}
2025-09-12 15:28:49,000 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.6949999999999996e-05, 'token_usage': 310}
2025-09-12 15:28:49,000 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer de la vessie, city=Paris, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 15:28:49,000 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.75e-05, city_cost=7.83e-05, institution_names_cost=0.0001728, institution_type_cost=3.255e-05, number_institutions_cost=4.6949999999999996e-05
2025-09-12 15:28:49,000 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=317, institution_names_tokens=1107, institution_type_tokens=214, number_institutions_tokens=310
2025-09-12 15:28:49,000 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.83e-05, 'city_token_usage': 317, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.0001728, 'institution_names_token_usage': 1107, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.255e-05, 'institution_type_token_usage': 214, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.75e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.6949999999999996e-05, 'number_institutions_token_usage': 310, 'total_cost': 0.0003981, 'total_token_usage': 1948}
2025-09-12 15:28:49,000 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer de la vessie', city='Paris', city_detected=True, institution_type='aucune correspondance', number_institutions=3, institution_names=None, institution_name_mentioned=False
2025-09-12 15:28:49,000 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer de la vessie'
2025-09-12 15:28:49,000 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: 'Paris'
2025-09-12 15:28:49,000 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: True
2025-09-12 15:28:49,000 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 15:28:49,001 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 3
2025-09-12 15:28:49,001 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: []
2025-09-12 15:28:49,001 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 15:28:49,001 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'none'
2025-09-12 15:28:49,001 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: False
2025-09-12 15:28:49,037 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:28:49,038 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 15:28:49,264 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 15:28:49,264 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 15:28:49,264 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer de la vessie'
2025-09-12 15:28:49,264 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: 'Paris'
2025-09-12 15:28:49,265 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: True
2025-09-12 15:28:49,265 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 15:28:49,265 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: []
2025-09-12 15:28:49,265 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: False
2025-09-12 15:28:49,265 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 3
2025-09-12 15:28:49,265 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer de la vessie, city: Paris, institution_type: aucune correspondance, institution: [], institution_name_mentioned: False
2025-09-12 15:28:49,265 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 15:28:49,265 [DEBUG] app.services.pipeline_orchestrator_service: [CITY DETECTION] Detected city: 'Paris', city_detected: True, DataProcessor.city: 'Paris', DataProcessor.city_detected: True
2025-09-12 15:28:49,265 [DEBUG] app.services.pipeline_orchestrator_service: Calling build_ranking_dataframe_with_distances
2025-09-12 15:28:49,265 [INFO] app.services.pipeline_orchestrator_service: Building ranking DataFrame with distances: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?', excel_path='/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx', detected_specialty='cancer de la vessie'
2025-09-12 15:28:49,265 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?', detected_specialty='cancer de la vessie', conv_history='None'
2025-09-12 15:28:49,266 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 15:28:49,266 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 15:28:49,266 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 15:28:49,266 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 15:28:49,456 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:28:49,457 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?, conv_history: 
2025-09-12 15:28:49,457 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'
2025-09-12 15:28:49,460 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:49,460 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:49,461 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:49,461 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:49,461 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:49,461 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:49,461 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:50,348 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'290'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'411'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'199554'), (b'x-ratelimit-reset-requests', b'1m28.065s'), (b'x-ratelimit-reset-tokens', b'133ms'), (b'x-request-id', b'req_e8718d60659046be809afb109ee453fe'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfc00d7de070e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:50,348 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:50,348 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:50,349 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:50,349 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:50,349 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:50,349 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:50 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '290', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '411', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9989', 'x-ratelimit-remaining-tokens': '199554', 'x-ratelimit-reset-requests': '1m28.065s', 'x-ratelimit-reset-tokens': '133ms', 'x-request-id': 'req_e8718d60659046be809afb109ee453fe', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfc00d7de070e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:50,349 [DEBUG] openai._base_client: request_id: req_e8718d60659046be809afb109ee453fe
2025-09-12 15:28:50,350 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 430, 'completion_tokens': 5, 'total_tokens': 435}, cost=6.75e-05
2025-09-12 15:28:50,350 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer de la vessie, method: llm
2025-09-12 15:28:50,350 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer de la vessie', 'detection_method': 'llm', 'cost': 6.75e-05, 'token_usage': 0}
2025-09-12 15:28:50,351 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?', conv_history: ''
2025-09-12 15:28:50,353 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:50,354 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:50,354 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:50,354 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:50,354 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:50,354 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:50,355 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:50,698 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'177'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'192'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'199782'), (b'x-ratelimit-reset-requests', b'1m27.582s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_afef406a211f426c93d5cc9e15619d8b'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfc0130b4970e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:50,699 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:50,699 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:50,701 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:50,701 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:50,701 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:50,702 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:50 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '177', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '192', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9989', 'x-ratelimit-remaining-tokens': '199782', 'x-ratelimit-reset-requests': '1m27.582s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_afef406a211f426c93d5cc9e15619d8b', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfc0130b4970e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:50,702 [DEBUG] openai._base_client: request_id: req_afef406a211f426c93d5cc9e15619d8b
2025-09-12 15:28:50,703 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 198, 'completion_tokens': 1, 'total_tokens': 199}, cost=3.03e-05
2025-09-12 15:28:50,706 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:50,707 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:50,707 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:50,707 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:50,707 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:50,708 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:50,708 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:50,989 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'138'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'150'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9988'), (b'x-ratelimit-remaining-tokens', b'199649'), (b'x-ratelimit-reset-requests', b'1m35.88s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_bf4767a4249f4a349e873901e404a3c2'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfc0154d3170e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:50,989 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:50,989 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:50,993 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:50,993 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:50,993 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:50,993 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:51 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '138', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '150', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9988', 'x-ratelimit-remaining-tokens': '199649', 'x-ratelimit-reset-requests': '1m35.88s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_bf4767a4249f4a349e873901e404a3c2', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfc0154d3170e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:50,993 [DEBUG] openai._base_client: request_id: req_bf4767a4249f4a349e873901e404a3c2
2025-09-12 15:28:50,994 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}, cost=4.8e-05
2025-09-12 15:28:50,994 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.83e-05, tokens={'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}
2025-09-12 15:28:50,994 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': 'Paris', 'detection_method': 'llm', 'cost': 7.83e-05, 'status_code': 3, 'token_usage': {'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}}
2025-09-12 15:28:50,994 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?, conv_history=
2025-09-12 15:28:50,997 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:50,997 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:50,998 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:50,998 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:50,998 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:50,998 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:50,998 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:51,341 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'188'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'205'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9988'), (b'x-ratelimit-remaining-tokens', b'199782'), (b'x-ratelimit-reset-requests', b'1m35.586s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_589bf980b7524d4c97a014bf42195647'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfc0171ed170e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:51,342 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:51,342 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:51,346 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:51,346 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:51,346 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:51,346 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:51 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '188', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '205', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9988', 'x-ratelimit-remaining-tokens': '199782', 'x-ratelimit-reset-requests': '1m35.586s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_589bf980b7524d4c97a014bf42195647', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfc0171ed170e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:51,347 [DEBUG] openai._base_client: request_id: req_589bf980b7524d4c97a014bf42195647
2025-09-12 15:28:51,347 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 198, 'completion_tokens': 1, 'total_tokens': 199}, cost=3.03e-05
2025-09-12 15:28:51,351 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:51,352 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:51,352 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:51,352 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:51,352 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:51,353 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:51,353 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:52,214 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'159'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'339'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9986'), (b'x-ratelimit-remaining-tokens', b'199649'), (b'x-ratelimit-reset-requests', b'2m0.609s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_cfb970a58dfe46e4ab06f6eae1f9ad75'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfc01949b470e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:52,214 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:52,215 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:52,217 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:52,217 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:52,217 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:52,217 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '159', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '339', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9986', 'x-ratelimit-remaining-tokens': '199649', 'x-ratelimit-reset-requests': '2m0.609s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_cfb970a58dfe46e4ab06f6eae1f9ad75', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfc01949b470e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:52,218 [DEBUG] openai._base_client: request_id: req_cfb970a58dfe46e4ab06f6eae1f9ad75
2025-09-12 15:28:52,218 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}, cost=4.8e-05
2025-09-12 15:28:52,218 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.83e-05, tokens={'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}
2025-09-12 15:28:52,219 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 3, 'city_detected': True, 'city': 'Paris', 'detection_method': 'llm', 'cost': 7.83e-05, 'token_usage': 317}
2025-09-12 15:28:52,219 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?' with conv_history: ''
2025-09-12 15:28:52,221 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:52,222 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:52,223 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:52,223 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:52,223 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:52,223 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:52,223 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:53,273 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'892'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'915'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9986'), (b'x-ratelimit-remaining-tokens', b'198987'), (b'x-ratelimit-reset-requests', b'2m0.276s'), (b'x-ratelimit-reset-tokens', b'303ms'), (b'x-request-id', b'req_d65dd77c17c54250aabf84e892947633'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfc01ebf1070e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:53,273 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:53,273 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:53,276 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:53,277 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:53,277 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:53,277 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '892', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '915', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9986', 'x-ratelimit-remaining-tokens': '198987', 'x-ratelimit-reset-requests': '2m0.276s', 'x-ratelimit-reset-tokens': '303ms', 'x-request-id': 'req_d65dd77c17c54250aabf84e892947633', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfc01ebf1070e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:53,277 [DEBUG] openai._base_client: request_id: req_d65dd77c17c54250aabf84e892947633
2025-09-12 15:28:53,278 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1092, 'completion_tokens': 15, 'total_tokens': 1107}, cost=0.0001728
2025-09-12 15:28:53,278 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 15:28:53,278 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 15:28:53,279 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': [], 'intent': 'none'}
2025-09-12 15:28:53,279 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: [], intent: none, cost: 0.0001728, token_usage: {'prompt_tokens': 1092, 'completion_tokens': 15, 'total_tokens': 1107}
2025-09-12 15:28:53,280 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | []
2025-09-12 15:28:53,280 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=[] and institution_list length=553)
2025-09-12 15:28:53,280 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: []
2025-09-12 15:28:53,280 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: none
2025-09-12 15:28:53,280 [INFO] app.features.query_analysis.institution_names.institution_names_validation: No specific institution detected
2025-09-12 15:28:53,280 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': None, 'institution_name_mentioned': False, 'error': 'No institution detected', 'intent': 'none', 'detection_method': 'llm', 'cost': 0.0001728, 'token_usage': 1107}
2025-09-12 15:28:53,284 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:53,284 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:53,284 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:53,285 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:53,285 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:53,285 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:53,285 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:53,780 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'190'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'325'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9984'), (b'x-ratelimit-remaining-tokens', b'199782'), (b'x-ratelimit-reset-requests', b'2m16.37s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_832e8b661d8d4236bfab046c0a9a6997'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfc0255d3770e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:53,781 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:53,781 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:53,785 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:53,786 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:53,786 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:53,786 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '190', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '325', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9984', 'x-ratelimit-remaining-tokens': '199782', 'x-ratelimit-reset-requests': '2m16.37s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_832e8b661d8d4236bfab046c0a9a6997', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfc0255d3770e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:53,786 [DEBUG] openai._base_client: request_id: req_832e8b661d8d4236bfab046c0a9a6997
2025-09-12 15:28:53,787 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 213, 'completion_tokens': 1, 'total_tokens': 214}, cost=3.255e-05
2025-09-12 15:28:53,787 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.255e-05, {'prompt_tokens': 213, 'completion_tokens': 1, 'total_tokens': 214}
2025-09-12 15:28:53,787 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.255e-05, 'token_usage': 214}
2025-09-12 15:28:53,791 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:28:53,791 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:28:53,792 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:28:53,792 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:28:53,792 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:28:53,792 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:28:53,793 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:28:54,231 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:28:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'284'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'304'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9984'), (b'x-ratelimit-remaining-tokens', b'199679'), (b'x-ratelimit-reset-requests', b'2m15.993s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_08d0e15cc77b421498aec4ef9a067fa7'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfc02888d570e6-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:28:54,232 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:28:54,232 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:28:54,232 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:28:54,233 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:28:54,233 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:28:54,233 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:28:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '284', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '304', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9984', 'x-ratelimit-remaining-tokens': '199679', 'x-ratelimit-reset-requests': '2m15.993s', 'x-ratelimit-reset-tokens': '96ms', 'x-request-id': 'req_08d0e15cc77b421498aec4ef9a067fa7', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfc02888d570e6-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:28:54,233 [DEBUG] openai._base_client: request_id: req_08d0e15cc77b421498aec4ef9a067fa7
2025-09-12 15:28:54,234 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 309, 'completion_tokens': 1, 'total_tokens': 310}, cost=4.6949999999999996e-05
2025-09-12 15:28:54,234 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.6949999999999996e-05, {'prompt_tokens': 309, 'completion_tokens': 1, 'total_tokens': 310}
2025-09-12 15:28:54,234 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.6949999999999996e-05, 'token_usage': 310}
2025-09-12 15:28:54,234 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer de la vessie, city=Paris, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 15:28:54,234 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.75e-05, city_cost=7.83e-05, institution_names_cost=0.0001728, institution_type_cost=3.255e-05, number_institutions_cost=4.6949999999999996e-05
2025-09-12 15:28:54,235 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=317, institution_names_tokens=1107, institution_type_tokens=214, number_institutions_tokens=310
2025-09-12 15:28:54,235 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.83e-05, 'city_token_usage': 317, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.0001728, 'institution_names_token_usage': 1107, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.255e-05, 'institution_type_token_usage': 214, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.75e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.6949999999999996e-05, 'number_institutions_token_usage': 310, 'total_cost': 0.0003981, 'total_token_usage': 1948}
2025-09-12 15:28:54,235 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer de la vessie', city='Paris', city_detected=True, institution_type='aucune correspondance', number_institutions=3, institution_names=None, institution_name_mentioned=False
2025-09-12 15:28:54,235 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer de la vessie'
2025-09-12 15:28:54,235 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: 'Paris'
2025-09-12 15:28:54,235 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: True
2025-09-12 15:28:54,235 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 15:28:54,235 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 3
2025-09-12 15:28:54,235 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: []
2025-09-12 15:28:54,235 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 15:28:54,235 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'none'
2025-09-12 15:28:54,235 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: False
2025-09-12 15:28:54,266 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:28:54,267 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 15:28:54,424 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 15:28:54,424 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 15:28:54,424 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer de la vessie'
2025-09-12 15:28:54,424 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: 'Paris'
2025-09-12 15:28:54,425 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: True
2025-09-12 15:28:54,425 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 15:28:54,425 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: []
2025-09-12 15:28:54,425 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: False
2025-09-12 15:28:54,425 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 3
2025-09-12 15:28:54,425 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer de la vessie, city: Paris, institution_type: aucune correspondance, institution: [], institution_name_mentioned: False
2025-09-12 15:28:54,425 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 15:28:54,425 [INFO] app.services.data_processing_service: generate_data_response called
2025-09-12 15:28:54,425 [DEBUG] app.services.data_processing_service: Extracted values - specialty: 'cancer de la vessie', institution_type: 'aucune correspondance', city: 'Paris'
2025-09-12 15:28:54,425 [DEBUG] app.services.data_processing_service: No institution type match found, loading by specialty only
2025-09-12 15:28:54,425 [INFO] app.services.data_processing_service: Filtering ranking by criteria: specialty='cancer de la vessie', institution_type='None'
2025-09-12 15:28:54,425 [DEBUG] app.services.data_processing_service: Filtering ranking data - specialty: 'cancer de la vessie', institution_type: 'None'
2025-09-12 15:28:54,425 [DEBUG] app.services.data_processing_service: Specialty type: <class 'str'>, length: 19
2025-09-12 15:28:54,426 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer de la vessie
2025-09-12 15:28:54,426 [DEBUG] app.services.data_processing_service: No specialty provided or specialty is 'no match', returning empty DataFrame
2025-09-12 15:28:54,426 [INFO] app.services.data_processing_service: generate_response_links called with matching_rows: <class 'pandas.core.frame.DataFrame'>
2025-09-12 15:28:54,426 [INFO] app.services.data_processing_service: Generating ranking links
2025-09-12 15:28:54,426 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer de la vessie
2025-09-12 15:28:54,426 [DEBUG] app.services.data_processing_service: No specialty detected, generating general ranking links
2025-09-12 15:28:54,426 [INFO] app.services.data_processing_service: load_excel_sheets called with matching_rows of length: 0
2025-09-12 15:28:54,427 [WARNING] app.services.data_processing_service: No matching rows provided to load_excel_sheets
2025-09-12 15:28:54,427 [INFO] app.services.data_processing_service: Loaded specialty DataFrame
2025-09-12 15:28:54,427 [WARNING] app.services.pipeline_orchestrator_service: Ranking not found for requested specialty/type
2025-09-12 15:28:54,427 [DEBUG] app.services.pipeline_orchestrator_service: build_ranking_dataframe_with_distances returned DataFrame: <class 'pandas.core.frame.DataFrame'>
2025-09-12 15:28:54,427 [DEBUG] app.services.pipeline_orchestrator_service: Checking if DataFrame is None
2025-09-12 15:28:54,427 [DEBUG] app.services.pipeline_orchestrator_service: Retrieved DataFrame shape: (0, 0)
2025-09-12 15:28:54,427 [DEBUG] app.services.pipeline_orchestrator_service: Checking for geolocation API errors
2025-09-12 15:28:54,427 [DEBUG] app.services.pipeline_orchestrator_service: Getting ranking link for UI
2025-09-12 15:28:54,428 [DEBUG] app.services.pipeline_orchestrator_service: Checking for specialty_ranking_unavailable
2025-09-12 15:28:54,428 [WARNING] app.services.pipeline_orchestrator_service: Ranking not found for requested specialty/type, suggesting alternative
2025-09-12 15:28:54,428 [DEBUG] app.services.pipeline_orchestrator_service: Checking if institution is mentioned
2025-09-12 15:28:54,428 [DEBUG] app.services.pipeline_orchestrator_service: Checking if city is detected
2025-09-12 15:28:54,428 [DEBUG] app.services.pipeline_orchestrator_service: [DF COLUMNS] DataFrame columns before city/distance selection: []
2025-09-12 15:28:54,428 [INFO] app.services.pipeline_orchestrator_service: No city detected, returning general ranking
2025-09-12 15:28:54,428 [DEBUG] app.services.pipeline_orchestrator_service: [GENERAL RANKING] DataFrame columns: []
2025-09-12 15:28:54,428 [ERROR] app.services.pipeline_orchestrator_service: Exception in general ranking response: 'Catégorie'
Traceback (most recent call last):
  File "/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/app/services/pipeline_orchestrator_service.py", line 856, in generate_response
    public_df = self.df_gen[self.df_gen["Catégorie"] == "Public"].nlargest(self.number_institutions, "Note / 20")
                            ~~~~~~~~~~~^^^^^^^^^^^^^
  File "/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/chatbot_hop/lib/python3.13/site-packages/pandas/core/frame.py", line 4102, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/chatbot_hop/lib/python3.13/site-packages/pandas/core/indexes/range.py", line 417, in get_loc
    raise KeyError(key)
KeyError: 'Catégorie'
2025-09-12 15:28:54,435 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 15:36:12,395 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:36:12,396 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:36:12,396 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:36:12,396 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:36:12,398 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:36:12,398 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:36:12,398 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:36:12,499 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:36:12,499 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:36:12,499 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:36:12,503 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:36:12,503 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:36:12,695 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:36:12,695 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:36:12,695 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:36:12,696 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:36:12,696 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:36:12,696 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:36:12,768 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:36:12,768 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:36:12,769 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:36:12,770 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:36:12,771 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:36:12,771 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:36:12,771 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:36:12,771 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:36:12,771 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:36:12,771 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:36:12,771 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:36:12,772 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:36:12,772 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:36:12,772 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:36:12,845 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:36:12,845 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:36:12,846 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:36:12,847 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:36:12,847 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:36:12,876 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:36:12,878 [INFO] main: Creating FastAPI app
2025-09-12 15:36:12,878 [INFO] main: CORS middleware added
2025-09-12 15:36:12,880 [INFO] main: API router included
2025-09-12 15:36:12,886 [INFO] app.services.pipeline_orchestrator_service: Starting pipeline processing - prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 15:36:12,886 [INFO] app.services.pipeline_orchestrator_service: Resetting PipelineOrchestrator attributes for new query
2025-09-12 15:36:12,886 [INFO] app.services.pipeline_orchestrator_service: Running sanity checks for prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conversation: [], conv_history: 
2025-09-12 15:36:12,886 [DEBUG] app.features.sanity_checks.sanity_checks_analyst: run_checks called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conversation=[], conv_history=, checks_to_run=['conversation_limit', 'message_length', 'message_pertinence']
2025-09-12 15:36:12,886 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst running checks: ['conversation_limit', 'message_length', 'message_pertinence'] for user_input: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 15:36:12,886 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check medical pertinence prompt sent to LLM.
2025-09-12 15:36:12,891 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nÉvaluez si le message suivant a un rapport avec la santé humaine ou les services de soins.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur la santé.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes de discussions médicales.\nATTENTION: Toute question sur la méthodologie, la fréquence de mise à jour, les critères, ou le fonctionnement du classement des hôpitaux doit TOUJOURS être considérée comme pertinente, même si elle ne concerne pas directement une maladie ou un service de soins.\n\nRépondez UNIQUEMENT avec 1 si pertinent, 0 si non pertinent ou 2 si la question concerne la méthodologie de calcul du classement.\n\nExemples pour messages standalone (repondre 1): \n- \'J\'ai un cancer à Paris\' → 1\n- \'Cataracte\' → 1  \n- \'J\'ai mal aux pieds\' → 1\n- \'Les hôpitaux privés sont ils meilleurs que les publiques?\' → 1\n- \'Comment le classement est-il calculé ?\' → 1\n- \'Quels sont les critères du classement ?\' → 1\n- "Quels experts participent à l\'élaboration du classement ?"\' → 1\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\' → 1\n- "Comment sont traitées les données manquantes dans le classement ?"\' → 1\n- "Le classement est-il le même pour toutes les spécialités ?"\' → 1\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\' → 1\n- "Quels sont les changements dans la méthodologie cette année ?"\' → 1\n- "Comment puis-je accéder au détail de la méthodologie ?"\' → 1\n\nExemples pour messages standalone (repondre 0):\n- \'Je mange des frites\' → 0\n- \'Comment faire une tarte aux pommes ?\' → 0\n- \'Comment s\'abonner Le Point ?\' → 0\n- \'Quel est le meilleur restaurant à Paris ?\' → 0\n\n\nExemples de questions qui concernent la méthodologie de classement (repondre 2):\n- "Comment le classement est-il calculé ?"\n- "Quels sont les critères du classement ?" \n- "Pourquoi l\'hôpital X est mieux classé que Y ?"\n- "Comment sont choisis les critères du classement ?"\n- "Qui réalise le classement des hôpitaux ?"\n- "Quelle est la source des données utilisées pour le classement ?"\n- "Le classement prend-il en compte la satisfaction des patients ?"\n- "Comment sont pondérés les différents critères ?"\n- "Est-ce que le classement est mis à jour chaque année ?"\n- "Pourquoi certains hôpitaux ne figurent pas dans le classement ?"\n- "Comment puis-je vérifier la fiabilité du classement ?"\n- "Quels experts participent à l\'élaboration du classement ?"\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\n- "Comment sont traitées les données manquantes dans le classement ?"\n- "Le classement est-il le même pour toutes les spécialités ?"\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\n- "Quels sont les changements dans la méthodologie cette année ?"\n- "Comment puis-je accéder au détail de la méthodologie ?"\n\nExemples pour messages avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique montrant une discussion sur les hôpitaux, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur la cardiologie, \'Merci\' → 1 (remerciement dans contexte médical)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n- Même avec contexte médical, \'Parle-moi de football\' → 0 (hors-sujet)\n- Avec historique sur les classements, "Comment sont déterminés les scores ?" → 2 (question sur la méthodologie de classement)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:12,921 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:12,921 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-09-12 15:36:12,959 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11dd43a10>
2025-09-12 15:36:12,959 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x11dacbda0> server_hostname='api.openai.com' timeout=None
2025-09-12 15:36:12,984 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11dd11f90>
2025-09-12 15:36:12,984 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:12,984 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:12,984 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:12,984 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:12,985 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:13,523 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'353'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'373'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'198878'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'336ms'), (b'x-request-id', b'req_73c279a568f34ab1b2a77e4a15447bac'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=hr.nhMfm9f2fMPFQ0bcK1eMir.nViYRkQ8_.6fXEIyg-1757684173-1.0.1.1-aA6DA5D9IV3HJ_DBA71ezYpx6rIt2NTiGF5YsPO7dT0Jjmfn6Ru4J5eIBIhD.slxCH7BozQzlNDbU89EM_fflcnqdzE0BTh388f41TQzmpY; path=/; expires=Fri, 12-Sep-25 14:06:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=ReSt0dodL49h.8_C91vamHMQRnCCc2qMptyjYyo6aNo-1757684173597-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcae1bf88adb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:13,525 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:13,525 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:13,530 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:13,530 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:13,530 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:13,530 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 12 Sep 2025 13:36:13 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'le-point-hv3izr'), ('openai-processing-ms', '353'), ('openai-project', 'proj_auvPnKXq8lce0dksWKRj2pvx'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '373'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '198878'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '336ms'), ('x-request-id', 'req_73c279a568f34ab1b2a77e4a15447bac'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=hr.nhMfm9f2fMPFQ0bcK1eMir.nViYRkQ8_.6fXEIyg-1757684173-1.0.1.1-aA6DA5D9IV3HJ_DBA71ezYpx6rIt2NTiGF5YsPO7dT0Jjmfn6Ru4J5eIBIhD.slxCH7BozQzlNDbU89EM_fflcnqdzE0BTh388f41TQzmpY; path=/; expires=Fri, 12-Sep-25 14:06:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=ReSt0dodL49h.8_C91vamHMQRnCCc2qMptyjYyo6aNo-1757684173597-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '97dfcae1bf88adb5-MRS'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-12 15:36:13,531 [DEBUG] openai._base_client: request_id: req_73c279a568f34ab1b2a77e4a15447bac
2025-09-12 15:36:13,538 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_medical_pertinence' successful: {'prompt_tokens': 1112, 'completion_tokens': 1, 'total_tokens': 1113}, cost=0.00016739999999999998
2025-09-12 15:36:13,538 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for medical pertinence:
1
2025-09-12 15:36:13,538 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed medical pertinence value: 1 (type: <class 'int'>)
2025-09-12 15:36:13,538 [DEBUG] app.features.sanity_checks.message_pertinence_check: medical_pertinence_result: {'result': 1, 'cost': 0.00016739999999999998, 'token_usage': 1113}
2025-09-12 15:36:13,538 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check chatbot pertinence prompt sent to LLM.
2025-09-12 15:36:13,541 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nVérifiez si cette question concerne le classement des hôpitaux.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur les classements d\'hôpitaux.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes.\n\nRépondez UNIQUEMENT avec:\n- 1 si la question est pertinente pour le chatbot (classement, recherche d\'établissement, etc.)\n- 0 si la question n\'est pas pertinente\n\nUne question est pertinente si elle concerne au moins un des cas suivants:\n- Une maladie, un symptôme ou une spécialité médicale  \n- Le classement des hôpitaux et cliniques  \n- La recherche d\'un hôpital, d\'une clinique ou d\'un service médical  \n- Une question de suivi sur les secteurs public/privé des hôpitaux\n\nExemples de questions pertinentes pour messages standalone (repondre 1):  \n- Quel est la meilleur clinique de France ?\n- Conseille moi un hôpital à Lyon \n- Je chercher un service de pneumologie\n- Où faire soigner mon glaucome ? \n- Je veux corriger mon audition\n- Il y a fréquemment du sang dans mes urines. Conseille-moi un hôpital. \n- Je veux cherche à faire soigner mes troubles bipôlaires\n- Est-ce que l\'Institut mutualiste Montsouris est bon ?\n- Y a-t-il des hôpitaux privés avec un service de cardiologie interventionnelle ?\n\nExemples de questions non pertinentes pour messages standalone (repondre 0):  \n- Pourquoi les hôpitaux sont-ils en crise ?  #Il s\'agit d\'une demande d\'information qui n\'est pas dans le cadre direct de la recherche d\'un établissement de soin\n- Dois-je prendre du paracétamol pour ma fièvre ? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n- Puis-je perdre la vue si j\'ai un glaucome? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n\n\n\nExemples avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique sur les hôpitaux parisiens, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur les classements, \'Combien coûte une consultation ?\' → 0 (question sur les coûts, pas sur les classements)\n- Avec historique sur la recherche d\'hôpital, \'Merci beaucoup\' → 1 (remerciement dans contexte de recherche d\'hôpital)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:13,542 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:13,542 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:13,543 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:13,543 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:13,543 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:13,543 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:13,944 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'250'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'263'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199169'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'249ms'), (b'x-request-id', b'req_5f10e9b9d770451bb5a60d913c37b97e'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcae53aeaadb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:13,944 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:13,945 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:13,948 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:13,948 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:13,949 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:13,949 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '250', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '263', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199169', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '249ms', 'x-request-id': 'req_5f10e9b9d770451bb5a60d913c37b97e', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcae53aeaadb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:13,949 [DEBUG] openai._base_client: request_id: req_5f10e9b9d770451bb5a60d913c37b97e
2025-09-12 15:36:13,950 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_chatbot_pertinence' successful: {'prompt_tokens': 810, 'completion_tokens': 1, 'total_tokens': 811}, cost=0.00012209999999999999
2025-09-12 15:36:13,950 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for chatbot pertinence:
1
2025-09-12 15:36:13,950 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed chatbot pertinence value: 1 (type: <class 'int'>)
2025-09-12 15:36:13,950 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst completed checks. All passed: True, Total cost: 0.00028949999999999994, Total tokens: 1924
2025-09-12 15:36:13,950 [INFO] app.features.sanity_checks.sanity_checks_analyst: Sanity check results: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 15:36:13,950 [INFO] app.services.pipeline_orchestrator_service: Sanity checks result: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 15:36:13,950 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', detected_specialty='None', conv_history=''
2025-09-12 15:36:13,950 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 15:36:13,950 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 15:36:13,951 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 15:36:13,951 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 15:36:14,150 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:36:14,150 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history: 
2025-09-12 15:36:14,150 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'
2025-09-12 15:36:14,153 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:14,154 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:14,154 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:14,154 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:14,154 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:14,154 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:14,155 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:14,614 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'312'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'327'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199552'), (b'x-ratelimit-reset-requests', b'24.79s'), (b'x-ratelimit-reset-tokens', b'134ms'), (b'x-request-id', b'req_4d868f24082645a1b3b6522a3d8e658a'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcae90ed2adb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:14,614 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:14,615 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:14,617 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:14,617 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:14,618 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:14,618 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '312', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '327', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '199552', 'x-ratelimit-reset-requests': '24.79s', 'x-ratelimit-reset-tokens': '134ms', 'x-request-id': 'req_4d868f24082645a1b3b6522a3d8e658a', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcae90ed2adb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:14,619 [DEBUG] openai._base_client: request_id: req_4d868f24082645a1b3b6522a3d8e658a
2025-09-12 15:36:14,619 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 431, 'completion_tokens': 6, 'total_tokens': 437}, cost=6.825e-05
2025-09-12 15:36:14,620 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer de la vessie., method: llm
2025-09-12 15:36:14,620 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer de la vessie', 'detection_method': 'llm', 'cost': 6.825e-05, 'token_usage': 0}
2025-09-12 15:36:14,620 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', conv_history: ''
2025-09-12 15:36:14,623 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:14,624 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:14,624 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:14,625 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:14,625 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:14,625 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:14,625 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:14,965 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'164'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'178'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'24.298s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_3729ebd0283b45a69f3977b2c0af7161'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcaebf9c5adb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:14,965 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:14,965 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:14,968 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:14,968 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:14,968 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:14,968 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:15 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '164', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '178', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '24.298s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_3729ebd0283b45a69f3977b2c0af7161', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcaebf9c5adb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:14,968 [DEBUG] openai._base_client: request_id: req_3729ebd0283b45a69f3977b2c0af7161
2025-09-12 15:36:14,969 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 15:36:14,971 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:14,972 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:14,972 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:14,973 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:14,973 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:14,973 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:14,973 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:15,470 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'331'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'345'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'33.118s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_2080e981f322459f8a6457ab84a0b5fa'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcaee2c01adb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:15,470 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:15,471 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:15,471 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:15,471 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:15,471 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:15,471 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:15 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '331', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '345', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9996', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '33.118s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_2080e981f322459f8a6457ab84a0b5fa', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcaee2c01adb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:15,471 [DEBUG] openai._base_client: request_id: req_2080e981f322459f8a6457ab84a0b5fa
2025-09-12 15:36:15,472 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 15:36:15,472 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 15:36:15,472 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'status_code': 3, 'token_usage': {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}}
2025-09-12 15:36:15,472 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history=
2025-09-12 15:36:15,475 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:15,475 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:15,476 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:15,476 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:15,476 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:15,477 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:15,477 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:15,838 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'180'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'202'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'32.087s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_b16fc97777124b79b424612b9c28566a'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcaf14f3badb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:15,839 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:15,839 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:15,841 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:15,842 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:15,842 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:15,842 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:15 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '180', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '202', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9996', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '32.087s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_b16fc97777124b79b424612b9c28566a', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcaf14f3badb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:15,843 [DEBUG] openai._base_client: request_id: req_b16fc97777124b79b424612b9c28566a
2025-09-12 15:36:15,844 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 15:36:15,847 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:15,847 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:15,848 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:15,848 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:15,848 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:15,848 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:15,848 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:16,319 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'288'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'303'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9995'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'40.367s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_93b6a5852eea45a2aa154e4bae51e2ed'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcaf39a1fadb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:16,319 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:16,320 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:16,320 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:16,320 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:16,320 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:16,321 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:16 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '288', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '303', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9995', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '40.367s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_93b6a5852eea45a2aa154e4bae51e2ed', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcaf39a1fadb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:16,321 [DEBUG] openai._base_client: request_id: req_93b6a5852eea45a2aa154e4bae51e2ed
2025-09-12 15:36:16,322 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 15:36:16,322 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 15:36:16,322 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 3, 'city_detected': True, 'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'token_usage': 318}
2025-09-12 15:36:16,322 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?' with conv_history: ''
2025-09-12 15:36:16,328 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:16,331 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:16,331 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:16,331 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:16,331 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:16,332 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:16,332 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:16,928 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'440'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'455'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'198986'), (b'x-ratelimit-reset-requests', b'57.687s'), (b'x-ratelimit-reset-tokens', b'304ms'), (b'x-request-id', b'req_285f0d4c2e3f47d2be7ed94c493a51d6'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcaf6ad94adb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:16,931 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:16,931 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:17,034 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:17,034 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:17,035 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:17,035 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '440', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '455', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9993', 'x-ratelimit-remaining-tokens': '198986', 'x-ratelimit-reset-requests': '57.687s', 'x-ratelimit-reset-tokens': '304ms', 'x-request-id': 'req_285f0d4c2e3f47d2be7ed94c493a51d6', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcaf6ad94adb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:17,035 [DEBUG] openai._base_client: request_id: req_285f0d4c2e3f47d2be7ed94c493a51d6
2025-09-12 15:36:17,036 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}, cost=0.00017295
2025-09-12 15:36:17,036 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 15:36:17,037 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 15:36:17,037 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': [], 'intent': 'none'}
2025-09-12 15:36:17,037 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: [], intent: none, cost: 0.00017295, token_usage: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}
2025-09-12 15:36:17,037 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | []
2025-09-12 15:36:17,037 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=[] and institution_list length=553)
2025-09-12 15:36:17,037 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: []
2025-09-12 15:36:17,037 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: none
2025-09-12 15:36:17,037 [INFO] app.features.query_analysis.institution_names.institution_names_validation: No specific institution detected
2025-09-12 15:36:17,038 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': None, 'institution_name_mentioned': False, 'error': 'No institution detected', 'intent': 'none', 'detection_method': 'llm', 'cost': 0.00017295, 'token_usage': 1108}
2025-09-12 15:36:17,040 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:17,041 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:17,041 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:17,041 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:17,042 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:17,042 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:17,042 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:17,506 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'296'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'313'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9991'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m13.737s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_b8005642f7b646f7a1cb01d22602e02c'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcafb1ad1adb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:17,506 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:17,506 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:17,507 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:17,507 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:17,507 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:17,507 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '296', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '313', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9991', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m13.737s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_b8005642f7b646f7a1cb01d22602e02c', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcafb1ad1adb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:17,507 [DEBUG] openai._base_client: request_id: req_b8005642f7b646f7a1cb01d22602e02c
2025-09-12 15:36:17,508 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}, cost=3.27e-05
2025-09-12 15:36:17,508 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.27e-05, {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}
2025-09-12 15:36:17,508 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.27e-05, 'token_usage': 215}
2025-09-12 15:36:17,510 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:17,511 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:17,511 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:17,512 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:17,512 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:17,512 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:17,512 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:17,856 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'197'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'209'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9991'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'1m13.267s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_99d7c5bbb8854d9e9bcf61a484d8b420'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcafe0ddbadb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:17,856 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:17,857 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:17,860 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:17,860 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:17,860 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:17,860 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '197', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '209', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9991', 'x-ratelimit-remaining-tokens': '199678', 'x-ratelimit-reset-requests': '1m13.267s', 'x-ratelimit-reset-tokens': '96ms', 'x-request-id': 'req_99d7c5bbb8854d9e9bcf61a484d8b420', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcafe0ddbadb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:17,860 [DEBUG] openai._base_client: request_id: req_99d7c5bbb8854d9e9bcf61a484d8b420
2025-09-12 15:36:17,861 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}, cost=4.71e-05
2025-09-12 15:36:17,861 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.71e-05, {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}
2025-09-12 15:36:17,861 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.71e-05, 'token_usage': 311}
2025-09-12 15:36:17,861 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer de la vessie, city=Paris, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 15:36:17,861 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.825e-05, city_cost=7.86e-05, institution_names_cost=0.00017295, institution_type_cost=3.27e-05, number_institutions_cost=4.71e-05
2025-09-12 15:36:17,862 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=318, institution_names_tokens=1108, institution_type_tokens=215, number_institutions_tokens=311
2025-09-12 15:36:17,862 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.86e-05, 'city_token_usage': 318, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017295, 'institution_names_token_usage': 1108, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.27e-05, 'institution_type_token_usage': 215, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.825e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.71e-05, 'number_institutions_token_usage': 311, 'total_cost': 0.0003996, 'total_token_usage': 1952}
2025-09-12 15:36:17,862 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer de la vessie', city='Paris', city_detected=True, institution_type='aucune correspondance', number_institutions=3, institution_names=None, institution_name_mentioned=False
2025-09-12 15:36:17,862 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer de la vessie'
2025-09-12 15:36:17,862 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: 'Paris'
2025-09-12 15:36:17,862 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: True
2025-09-12 15:36:17,862 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 15:36:17,862 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 3
2025-09-12 15:36:17,862 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: []
2025-09-12 15:36:17,862 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 15:36:17,863 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'none'
2025-09-12 15:36:17,863 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: False
2025-09-12 15:36:17,892 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:36:17,892 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 15:36:18,107 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 15:36:18,108 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 15:36:18,108 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer de la vessie'
2025-09-12 15:36:18,108 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: 'Paris'
2025-09-12 15:36:18,108 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: True
2025-09-12 15:36:18,108 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 15:36:18,108 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: []
2025-09-12 15:36:18,108 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: False
2025-09-12 15:36:18,108 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 3
2025-09-12 15:36:18,108 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer de la vessie, city: Paris, institution_type: aucune correspondance, institution: [], institution_name_mentioned: False
2025-09-12 15:36:18,108 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 15:36:18,108 [DEBUG] app.services.pipeline_orchestrator_service: [CITY DETECTION] Detected city: 'Paris', city_detected: True, DataProcessor.city: 'Paris', DataProcessor.city_detected: True
2025-09-12 15:36:18,108 [DEBUG] app.services.pipeline_orchestrator_service: Calling build_ranking_dataframe_with_distances
2025-09-12 15:36:18,109 [INFO] app.services.pipeline_orchestrator_service: Building ranking DataFrame with distances: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', excel_path='/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx', detected_specialty='cancer de la vessie'
2025-09-12 15:36:18,109 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', detected_specialty='cancer de la vessie', conv_history='None'
2025-09-12 15:36:18,109 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 15:36:18,109 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 15:36:18,109 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 15:36:18,109 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 15:36:18,324 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:36:18,324 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history: 
2025-09-12 15:36:18,324 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'
2025-09-12 15:36:18,327 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:18,327 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:18,328 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:18,328 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:18,328 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:18,328 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:18,328 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:18,845 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'345'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'369'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9990'), (b'x-ratelimit-remaining-tokens', b'199553'), (b'x-ratelimit-reset-requests', b'1m21.076s'), (b'x-ratelimit-reset-tokens', b'134ms'), (b'x-request-id', b'req_2b61001c921444fea3dcc001e7cfc38e'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcb031b3cadb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:18,846 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:18,846 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:18,853 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:18,853 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:18,854 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:18,854 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:18 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '345', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '369', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9990', 'x-ratelimit-remaining-tokens': '199553', 'x-ratelimit-reset-requests': '1m21.076s', 'x-ratelimit-reset-tokens': '134ms', 'x-request-id': 'req_2b61001c921444fea3dcc001e7cfc38e', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcb031b3cadb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:18,854 [DEBUG] openai._base_client: request_id: req_2b61001c921444fea3dcc001e7cfc38e
2025-09-12 15:36:18,855 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 431, 'completion_tokens': 5, 'total_tokens': 436}, cost=6.765e-05
2025-09-12 15:36:18,855 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer de la vessie, method: llm
2025-09-12 15:36:18,855 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer de la vessie', 'detection_method': 'llm', 'cost': 6.765e-05, 'token_usage': 0}
2025-09-12 15:36:18,855 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', conv_history: ''
2025-09-12 15:36:18,857 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:18,858 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:18,858 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:18,859 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:18,859 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:18,859 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:18,859 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:19,183 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'153'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'165'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9988'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m37.827s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_a4efac10c1544dffa63bfdcb071077bc'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcb066ed2adb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:19,183 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:19,183 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:19,186 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:19,186 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:19,186 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:19,186 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:19 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '153', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '165', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9988', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m37.827s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_a4efac10c1544dffa63bfdcb071077bc', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcb066ed2adb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:19,186 [DEBUG] openai._base_client: request_id: req_a4efac10c1544dffa63bfdcb071077bc
2025-09-12 15:36:19,187 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 15:36:19,189 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:19,190 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:19,190 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:19,191 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:19,191 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:19,191 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:19,191 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:19,763 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'233'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'374'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'1m29.229s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_9bf08e7bfa814fe2ac9eab0f2f67cf63'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcb0888cfadb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:19,763 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:19,763 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:19,764 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:19,764 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:19,764 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:19,764 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:19 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '233', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '374', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9989', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '1m29.229s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_9bf08e7bfa814fe2ac9eab0f2f67cf63', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcb0888cfadb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:19,764 [DEBUG] openai._base_client: request_id: req_9bf08e7bfa814fe2ac9eab0f2f67cf63
2025-09-12 15:36:19,765 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 15:36:19,765 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 15:36:19,765 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'status_code': 3, 'token_usage': {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}}
2025-09-12 15:36:19,765 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history=
2025-09-12 15:36:19,769 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:19,770 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:19,771 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:19,771 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:19,771 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:19,771 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:19,771 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:20,231 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'266'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'289'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9987'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m45.547s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_d9700fd4b618422c859e7a60a99a6075'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcb0c2cb5adb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:20,232 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:20,233 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:20,243 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:20,243 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:20,243 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:20,244 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '266', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '289', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9987', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m45.547s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_d9700fd4b618422c859e7a60a99a6075', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcb0c2cb5adb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:20,244 [DEBUG] openai._base_client: request_id: req_d9700fd4b618422c859e7a60a99a6075
2025-09-12 15:36:20,245 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 15:36:20,247 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:20,248 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:20,248 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:20,249 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:20,249 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:20,249 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:20,249 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:20,643 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'249'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'262'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9988'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'1m36.454s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_2f6d88d59f6340b2824c22469bb4054a'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcb0f1fbeadb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:20,643 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:20,643 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:20,647 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:20,647 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:20,647 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:20,647 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '249', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '262', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9988', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '1m36.454s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_2f6d88d59f6340b2824c22469bb4054a', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcb0f1fbeadb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:20,647 [DEBUG] openai._base_client: request_id: req_2f6d88d59f6340b2824c22469bb4054a
2025-09-12 15:36:20,648 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 15:36:20,648 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 15:36:20,648 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 3, 'city_detected': True, 'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'token_usage': 318}
2025-09-12 15:36:20,648 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?' with conv_history: ''
2025-09-12 15:36:20,651 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:20,651 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:20,652 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:20,652 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:20,652 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:20,652 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:20,652 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:21,408 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'602'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'624'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9986'), (b'x-ratelimit-remaining-tokens', b'198986'), (b'x-ratelimit-reset-requests', b'1m53.328s'), (b'x-ratelimit-reset-tokens', b'304ms'), (b'x-request-id', b'req_b05fb714659945a6a4be35b19c549a9f'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcb11aabdadb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:21,408 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:21,408 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:21,413 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:21,413 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:21,413 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:21,413 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:21 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '602', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '624', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9986', 'x-ratelimit-remaining-tokens': '198986', 'x-ratelimit-reset-requests': '1m53.328s', 'x-ratelimit-reset-tokens': '304ms', 'x-request-id': 'req_b05fb714659945a6a4be35b19c549a9f', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcb11aabdadb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:21,414 [DEBUG] openai._base_client: request_id: req_b05fb714659945a6a4be35b19c549a9f
2025-09-12 15:36:21,414 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}, cost=0.00017295
2025-09-12 15:36:21,414 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 15:36:21,414 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 15:36:21,415 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': [], 'intent': 'none'}
2025-09-12 15:36:21,415 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: [], intent: none, cost: 0.00017295, token_usage: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}
2025-09-12 15:36:21,415 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | []
2025-09-12 15:36:21,415 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=[] and institution_list length=553)
2025-09-12 15:36:21,415 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: []
2025-09-12 15:36:21,415 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: none
2025-09-12 15:36:21,415 [INFO] app.features.query_analysis.institution_names.institution_names_validation: No specific institution detected
2025-09-12 15:36:21,415 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': None, 'institution_name_mentioned': False, 'error': 'No institution detected', 'intent': 'none', 'detection_method': 'llm', 'cost': 0.00017295, 'token_usage': 1108}
2025-09-12 15:36:21,418 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:21,418 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:21,419 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:21,419 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:21,419 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:21,419 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:21,419 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:21,852 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'242'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'267'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9985'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'2m1.179s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_fd388028436a4eabbe79cd642c9b1ddf'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcb166810adb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:21,852 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:21,853 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:21,853 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:21,853 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:21,853 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:21,853 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:21 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '242', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '267', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9985', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '2m1.179s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_fd388028436a4eabbe79cd642c9b1ddf', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcb166810adb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:21,853 [DEBUG] openai._base_client: request_id: req_fd388028436a4eabbe79cd642c9b1ddf
2025-09-12 15:36:21,854 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}, cost=3.27e-05
2025-09-12 15:36:21,854 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.27e-05, {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}
2025-09-12 15:36:21,854 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.27e-05, 'token_usage': 215}
2025-09-12 15:36:21,857 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:36:21,857 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:36:21,858 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:36:21,858 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:36:21,858 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:36:21,858 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:36:21,858 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:36:22,465 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:36:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'419'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'438'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9984'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'2m18.021s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_1a28ccd0263b4d9696f9516a507b29a1'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfcb192b14adb5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:36:22,465 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:36:22,465 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:36:22,468 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:36:22,469 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:36:22,469 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:36:22,469 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:36:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '419', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '438', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9984', 'x-ratelimit-remaining-tokens': '199678', 'x-ratelimit-reset-requests': '2m18.021s', 'x-ratelimit-reset-tokens': '96ms', 'x-request-id': 'req_1a28ccd0263b4d9696f9516a507b29a1', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfcb192b14adb5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:36:22,469 [DEBUG] openai._base_client: request_id: req_1a28ccd0263b4d9696f9516a507b29a1
2025-09-12 15:36:22,470 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}, cost=4.71e-05
2025-09-12 15:36:22,470 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.71e-05, {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}
2025-09-12 15:36:22,470 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.71e-05, 'token_usage': 311}
2025-09-12 15:36:22,470 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer de la vessie, city=Paris, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 15:36:22,470 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.765e-05, city_cost=7.86e-05, institution_names_cost=0.00017295, institution_type_cost=3.27e-05, number_institutions_cost=4.71e-05
2025-09-12 15:36:22,470 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=318, institution_names_tokens=1108, institution_type_tokens=215, number_institutions_tokens=311
2025-09-12 15:36:22,470 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.86e-05, 'city_token_usage': 318, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017295, 'institution_names_token_usage': 1108, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.27e-05, 'institution_type_token_usage': 215, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.765e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.71e-05, 'number_institutions_token_usage': 311, 'total_cost': 0.000399, 'total_token_usage': 1952}
2025-09-12 15:36:22,470 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer de la vessie', city='Paris', city_detected=True, institution_type='aucune correspondance', number_institutions=3, institution_names=None, institution_name_mentioned=False
2025-09-12 15:36:22,471 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer de la vessie'
2025-09-12 15:36:22,471 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: 'Paris'
2025-09-12 15:36:22,471 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: True
2025-09-12 15:36:22,471 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 15:36:22,471 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 3
2025-09-12 15:36:22,471 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: []
2025-09-12 15:36:22,471 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 15:36:22,471 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'none'
2025-09-12 15:36:22,471 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: False
2025-09-12 15:36:22,506 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:36:22,507 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 15:36:22,681 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 15:36:22,682 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 15:36:22,682 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer de la vessie'
2025-09-12 15:36:22,682 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: 'Paris'
2025-09-12 15:36:22,682 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: True
2025-09-12 15:36:22,682 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 15:36:22,682 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: []
2025-09-12 15:36:22,682 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: False
2025-09-12 15:36:22,682 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 3
2025-09-12 15:36:22,682 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer de la vessie, city: Paris, institution_type: aucune correspondance, institution: [], institution_name_mentioned: False
2025-09-12 15:36:22,682 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 15:36:22,682 [INFO] app.services.data_processing_service: generate_data_response called
2025-09-12 15:36:22,683 [DEBUG] app.services.data_processing_service: Extracted values - specialty: 'cancer de la vessie', institution_type: 'aucune correspondance', city: 'Paris'
2025-09-12 15:36:22,683 [DEBUG] app.services.data_processing_service: No institution type match found, loading by specialty only
2025-09-12 15:36:22,683 [INFO] app.services.data_processing_service: Filtering ranking by criteria: specialty='cancer de la vessie', institution_type='None'
2025-09-12 15:36:22,683 [DEBUG] app.services.data_processing_service: Filtering ranking data - specialty: 'cancer de la vessie', institution_type: 'None'
2025-09-12 15:36:22,683 [DEBUG] app.services.data_processing_service: Specialty type: <class 'str'>, length: 19
2025-09-12 15:36:22,683 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer de la vessie
2025-09-12 15:36:22,683 [DEBUG] app.services.data_processing_service: No specialty provided or specialty is 'no match', returning empty DataFrame
2025-09-12 15:36:22,684 [INFO] app.services.data_processing_service: generate_response_links called with matching_rows: <class 'pandas.core.frame.DataFrame'>
2025-09-12 15:36:22,684 [INFO] app.services.data_processing_service: Generating ranking links
2025-09-12 15:36:22,684 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer de la vessie
2025-09-12 15:36:22,684 [DEBUG] app.services.data_processing_service: No specialty detected, generating general ranking links
2025-09-12 15:36:22,684 [INFO] app.services.data_processing_service: load_excel_sheets called with matching_rows of length: 0
2025-09-12 15:36:22,684 [WARNING] app.services.data_processing_service: No matching rows provided to load_excel_sheets
2025-09-12 15:36:22,684 [INFO] app.services.data_processing_service: Loaded specialty DataFrame
2025-09-12 15:36:22,684 [WARNING] app.services.pipeline_orchestrator_service: Ranking not found for requested specialty/type
2025-09-12 15:36:22,684 [DEBUG] app.services.pipeline_orchestrator_service: build_ranking_dataframe_with_distances returned DataFrame: <class 'pandas.core.frame.DataFrame'>
2025-09-12 15:36:22,685 [DEBUG] app.services.pipeline_orchestrator_service: Checking if DataFrame is None
2025-09-12 15:36:22,685 [DEBUG] app.services.pipeline_orchestrator_service: Retrieved DataFrame shape: (0, 0)
2025-09-12 15:36:22,685 [DEBUG] app.services.pipeline_orchestrator_service: Checking for geolocation API errors
2025-09-12 15:36:22,685 [DEBUG] app.services.pipeline_orchestrator_service: Getting ranking link for UI
2025-09-12 15:36:22,685 [DEBUG] app.services.pipeline_orchestrator_service: Checking for specialty_ranking_unavailable
2025-09-12 15:36:22,685 [WARNING] app.services.pipeline_orchestrator_service: Ranking not found for requested specialty/type, suggesting alternative
2025-09-12 15:36:22,685 [DEBUG] app.services.pipeline_orchestrator_service: Checking if institution is mentioned
2025-09-12 15:36:22,685 [DEBUG] app.services.pipeline_orchestrator_service: Checking if city is detected
2025-09-12 15:36:22,685 [DEBUG] app.services.pipeline_orchestrator_service: [DF COLUMNS] DataFrame columns before city/distance selection: []
2025-09-12 15:36:22,685 [INFO] app.services.pipeline_orchestrator_service: No city detected, returning general ranking
2025-09-12 15:36:22,685 [DEBUG] app.services.pipeline_orchestrator_service: [GENERAL RANKING] DataFrame columns: []
2025-09-12 15:36:22,685 [ERROR] app.services.pipeline_orchestrator_service: Exception in general ranking response: 'Catégorie'
Traceback (most recent call last):
  File "/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/app/services/pipeline_orchestrator_service.py", line 856, in generate_response
    public_df = self.df_gen[self.df_gen["Catégorie"] == "Public"].nlargest(self.number_institutions, "Note / 20")
                            ~~~~~~~~~~~^^^^^^^^^^^^^
  File "/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/chatbot_hop/lib/python3.13/site-packages/pandas/core/frame.py", line 4102, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/chatbot_hop/lib/python3.13/site-packages/pandas/core/indexes/range.py", line 417, in get_loc
    raise KeyError(key)
KeyError: 'Catégorie'
2025-09-12 15:36:22,692 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 15:40:32,138 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:40:32,139 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:40:32,139 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:40:32,139 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:40:32,141 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:40:32,141 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:40:32,141 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:40:32,252 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:40:32,252 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:40:32,253 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:40:32,257 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:40:32,257 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:40:32,481 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:40:32,481 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:40:32,481 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:40:32,482 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:40:32,482 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:40:32,482 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:40:32,565 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:40:32,565 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:40:32,565 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:40:32,568 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:40:32,569 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:40:32,569 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:40:32,569 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:40:32,571 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:40:32,571 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:40:32,572 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:40:32,572 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:40:32,573 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:40:32,573 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:40:32,573 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:40:32,652 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:40:32,652 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:40:32,653 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:40:32,654 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:40:32,655 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:40:32,688 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:40:32,690 [INFO] main: Creating FastAPI app
2025-09-12 15:40:32,690 [INFO] main: CORS middleware added
2025-09-12 15:40:32,692 [INFO] main: API router included
2025-09-12 15:42:20,063 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:42:20,063 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:42:20,063 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:42:20,063 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:42:20,064 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:42:20,064 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:42:20,064 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:42:20,159 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:42:20,160 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:42:20,160 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:42:20,163 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:42:20,163 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:42:20,315 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:42:20,315 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:42:20,315 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:42:20,316 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:42:20,316 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:42:20,316 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:42:20,388 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:42:20,388 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:42:20,388 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:42:20,390 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:42:20,390 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:42:20,390 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:42:20,390 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:42:20,390 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:42:20,390 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:42:20,391 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:42:20,391 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:42:20,391 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:42:20,391 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:42:20,392 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:42:20,465 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:42:20,465 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:42:20,465 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:42:20,467 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:42:20,467 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:42:20,496 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:42:20,498 [INFO] main: Creating FastAPI app
2025-09-12 15:42:20,498 [INFO] main: CORS middleware added
2025-09-12 15:42:20,500 [INFO] main: API router included
2025-09-12 15:42:23,099 [INFO] app.services.pipeline_orchestrator_service: Starting pipeline processing - prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 15:42:23,099 [INFO] app.services.pipeline_orchestrator_service: Resetting PipelineOrchestrator attributes for new query
2025-09-12 15:42:23,099 [INFO] app.services.pipeline_orchestrator_service: Running sanity checks for prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conversation: [], conv_history: 
2025-09-12 15:42:23,099 [DEBUG] app.features.sanity_checks.sanity_checks_analyst: run_checks called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conversation=[], conv_history=, checks_to_run=['conversation_limit', 'message_length', 'message_pertinence']
2025-09-12 15:42:23,099 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst running checks: ['conversation_limit', 'message_length', 'message_pertinence'] for user_input: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 15:42:23,099 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check medical pertinence prompt sent to LLM.
2025-09-12 15:42:23,104 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nÉvaluez si le message suivant a un rapport avec la santé humaine ou les services de soins.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur la santé.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes de discussions médicales.\nATTENTION: Toute question sur la méthodologie, la fréquence de mise à jour, les critères, ou le fonctionnement du classement des hôpitaux doit TOUJOURS être considérée comme pertinente, même si elle ne concerne pas directement une maladie ou un service de soins.\n\nRépondez UNIQUEMENT avec 1 si pertinent, 0 si non pertinent ou 2 si la question concerne la méthodologie de calcul du classement.\n\nExemples pour messages standalone (repondre 1): \n- \'J\'ai un cancer à Paris\' → 1\n- \'Cataracte\' → 1  \n- \'J\'ai mal aux pieds\' → 1\n- \'Les hôpitaux privés sont ils meilleurs que les publiques?\' → 1\n- \'Comment le classement est-il calculé ?\' → 1\n- \'Quels sont les critères du classement ?\' → 1\n- "Quels experts participent à l\'élaboration du classement ?"\' → 1\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\' → 1\n- "Comment sont traitées les données manquantes dans le classement ?"\' → 1\n- "Le classement est-il le même pour toutes les spécialités ?"\' → 1\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\' → 1\n- "Quels sont les changements dans la méthodologie cette année ?"\' → 1\n- "Comment puis-je accéder au détail de la méthodologie ?"\' → 1\n\nExemples pour messages standalone (repondre 0):\n- \'Je mange des frites\' → 0\n- \'Comment faire une tarte aux pommes ?\' → 0\n- \'Comment s\'abonner Le Point ?\' → 0\n- \'Quel est le meilleur restaurant à Paris ?\' → 0\n\n\nExemples de questions qui concernent la méthodologie de classement (repondre 2):\n- "Comment le classement est-il calculé ?"\n- "Quels sont les critères du classement ?" \n- "Pourquoi l\'hôpital X est mieux classé que Y ?"\n- "Comment sont choisis les critères du classement ?"\n- "Qui réalise le classement des hôpitaux ?"\n- "Quelle est la source des données utilisées pour le classement ?"\n- "Le classement prend-il en compte la satisfaction des patients ?"\n- "Comment sont pondérés les différents critères ?"\n- "Est-ce que le classement est mis à jour chaque année ?"\n- "Pourquoi certains hôpitaux ne figurent pas dans le classement ?"\n- "Comment puis-je vérifier la fiabilité du classement ?"\n- "Quels experts participent à l\'élaboration du classement ?"\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\n- "Comment sont traitées les données manquantes dans le classement ?"\n- "Le classement est-il le même pour toutes les spécialités ?"\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\n- "Quels sont les changements dans la méthodologie cette année ?"\n- "Comment puis-je accéder au détail de la méthodologie ?"\n\nExemples pour messages avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique montrant une discussion sur les hôpitaux, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur la cardiologie, \'Merci\' → 1 (remerciement dans contexte médical)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n- Même avec contexte médical, \'Parle-moi de football\' → 0 (hors-sujet)\n- Avec historique sur les classements, "Comment sont déterminés les scores ?" → 2 (question sur la méthodologie de classement)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:23,131 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:23,132 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-09-12 15:42:23,168 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11c657a10>
2025-09-12 15:42:23,169 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x11c0afda0> server_hostname='api.openai.com' timeout=None
2025-09-12 15:42:23,188 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11c685f90>
2025-09-12 15:42:23,188 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:23,189 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:23,189 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:23,189 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:23,189 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:23,683 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'293'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'308'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'198878'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'336ms'), (b'x-request-id', b'req_5604c5d4201949e6b382d415d09b2996'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0nmUPzcRZzd85SGuKtS5lj1aBHOHHztdhLRlP3x9STA-1757684543-1.0.1.1-ru_S7S_jlZQJjnEeZoriamjyZjmp7J1UdI9DWaDWu572Wo7hi97iLApuWOivkrXwh6wVpWCc9XPJ.d5c8nNqwpW8OiZgfGMxOoPCgk3I3gg; path=/; expires=Fri, 12-Sep-25 14:12:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=yq9PGoYRqn4mnTAhV..iar39x4R9kl5FAxsRdSaK7lE-1757684543787-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd3ebab541ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:23,684 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:23,684 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:23,685 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:23,685 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:23,685 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:23,685 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 12 Sep 2025 13:42:23 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'le-point-hv3izr'), ('openai-processing-ms', '293'), ('openai-project', 'proj_auvPnKXq8lce0dksWKRj2pvx'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '308'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '198878'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '336ms'), ('x-request-id', 'req_5604c5d4201949e6b382d415d09b2996'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=0nmUPzcRZzd85SGuKtS5lj1aBHOHHztdhLRlP3x9STA-1757684543-1.0.1.1-ru_S7S_jlZQJjnEeZoriamjyZjmp7J1UdI9DWaDWu572Wo7hi97iLApuWOivkrXwh6wVpWCc9XPJ.d5c8nNqwpW8OiZgfGMxOoPCgk3I3gg; path=/; expires=Fri, 12-Sep-25 14:12:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=yq9PGoYRqn4mnTAhV..iar39x4R9kl5FAxsRdSaK7lE-1757684543787-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '97dfd3ebab541ed5-MRS'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-12 15:42:23,685 [DEBUG] openai._base_client: request_id: req_5604c5d4201949e6b382d415d09b2996
2025-09-12 15:42:23,693 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_medical_pertinence' successful: {'prompt_tokens': 1112, 'completion_tokens': 1, 'total_tokens': 1113}, cost=0.00016739999999999998
2025-09-12 15:42:23,693 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for medical pertinence:
1
2025-09-12 15:42:23,693 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed medical pertinence value: 1 (type: <class 'int'>)
2025-09-12 15:42:23,693 [DEBUG] app.features.sanity_checks.message_pertinence_check: medical_pertinence_result: {'result': 1, 'cost': 0.00016739999999999998, 'token_usage': 1113}
2025-09-12 15:42:23,694 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check chatbot pertinence prompt sent to LLM.
2025-09-12 15:42:23,697 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nVérifiez si cette question concerne le classement des hôpitaux.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur les classements d\'hôpitaux.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes.\n\nRépondez UNIQUEMENT avec:\n- 1 si la question est pertinente pour le chatbot (classement, recherche d\'établissement, etc.)\n- 0 si la question n\'est pas pertinente\n\nUne question est pertinente si elle concerne au moins un des cas suivants:\n- Une maladie, un symptôme ou une spécialité médicale  \n- Le classement des hôpitaux et cliniques  \n- La recherche d\'un hôpital, d\'une clinique ou d\'un service médical  \n- Une question de suivi sur les secteurs public/privé des hôpitaux\n\nExemples de questions pertinentes pour messages standalone (repondre 1):  \n- Quel est la meilleur clinique de France ?\n- Conseille moi un hôpital à Lyon \n- Je chercher un service de pneumologie\n- Où faire soigner mon glaucome ? \n- Je veux corriger mon audition\n- Il y a fréquemment du sang dans mes urines. Conseille-moi un hôpital. \n- Je veux cherche à faire soigner mes troubles bipôlaires\n- Est-ce que l\'Institut mutualiste Montsouris est bon ?\n- Y a-t-il des hôpitaux privés avec un service de cardiologie interventionnelle ?\n\nExemples de questions non pertinentes pour messages standalone (repondre 0):  \n- Pourquoi les hôpitaux sont-ils en crise ?  #Il s\'agit d\'une demande d\'information qui n\'est pas dans le cadre direct de la recherche d\'un établissement de soin\n- Dois-je prendre du paracétamol pour ma fièvre ? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n- Puis-je perdre la vue si j\'ai un glaucome? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n\n\n\nExemples avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique sur les hôpitaux parisiens, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur les classements, \'Combien coûte une consultation ?\' → 0 (question sur les coûts, pas sur les classements)\n- Avec historique sur la recherche d\'hôpital, \'Merci beaucoup\' → 1 (remerciement dans contexte de recherche d\'hôpital)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:23,698 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:23,698 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:23,699 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:23,699 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:23,699 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:23,699 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:24,305 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'342'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'440'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199169'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'249ms'), (b'x-request-id', b'req_8cca4e49ac66401c835010fe7937940f'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd3eedaed1ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:24,306 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:24,306 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:24,309 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:24,309 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:24,310 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:24,310 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '342', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '440', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199169', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '249ms', 'x-request-id': 'req_8cca4e49ac66401c835010fe7937940f', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd3eedaed1ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:24,310 [DEBUG] openai._base_client: request_id: req_8cca4e49ac66401c835010fe7937940f
2025-09-12 15:42:24,311 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_chatbot_pertinence' successful: {'prompt_tokens': 810, 'completion_tokens': 1, 'total_tokens': 811}, cost=0.00012209999999999999
2025-09-12 15:42:24,311 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for chatbot pertinence:
1
2025-09-12 15:42:24,311 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed chatbot pertinence value: 1 (type: <class 'int'>)
2025-09-12 15:42:24,311 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst completed checks. All passed: True, Total cost: 0.00028949999999999994, Total tokens: 1924
2025-09-12 15:42:24,311 [INFO] app.features.sanity_checks.sanity_checks_analyst: Sanity check results: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 15:42:24,311 [INFO] app.services.pipeline_orchestrator_service: Sanity checks result: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 15:42:24,311 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', detected_specialty='None', conv_history=''
2025-09-12 15:42:24,311 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 15:42:24,312 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 15:42:24,312 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 15:42:24,312 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 15:42:24,511 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:42:24,511 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history: 
2025-09-12 15:42:24,511 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'
2025-09-12 15:42:24,515 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:24,517 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:24,517 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:24,517 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:24,517 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:24,517 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:24,517 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:25,151 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'445'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'479'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199553'), (b'x-ratelimit-reset-requests', b'24.609s'), (b'x-ratelimit-reset-tokens', b'134ms'), (b'x-request-id', b'req_5ac7c42a70124631abcf7b97bd0ede80'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd3f3fe7a1ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:25,152 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:25,152 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:25,153 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:25,153 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:25,153 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:25,153 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '445', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '479', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '199553', 'x-ratelimit-reset-requests': '24.609s', 'x-ratelimit-reset-tokens': '134ms', 'x-request-id': 'req_5ac7c42a70124631abcf7b97bd0ede80', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd3f3fe7a1ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:25,153 [DEBUG] openai._base_client: request_id: req_5ac7c42a70124631abcf7b97bd0ede80
2025-09-12 15:42:25,154 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 431, 'completion_tokens': 5, 'total_tokens': 436}, cost=6.765e-05
2025-09-12 15:42:25,154 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer de la vessie, method: llm
2025-09-12 15:42:25,155 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer de la vessie', 'detection_method': 'llm', 'cost': 6.765e-05, 'token_usage': 0}
2025-09-12 15:42:25,155 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', conv_history: ''
2025-09-12 15:42:25,158 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:25,159 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:25,159 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:25,159 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:25,159 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:25,159 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:25,159 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:25,582 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'198'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'262'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'32.606s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_234551fefd094c9cb44bb274d245b0bf'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd3f7ff7b1ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:25,582 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:25,583 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:25,591 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:25,591 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:25,591 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:25,592 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '198', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '262', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9996', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '32.606s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_234551fefd094c9cb44bb274d245b0bf', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd3f7ff7b1ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:25,592 [DEBUG] openai._base_client: request_id: req_234551fefd094c9cb44bb274d245b0bf
2025-09-12 15:42:25,593 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 15:42:25,595 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:25,595 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:25,596 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:25,596 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:25,596 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:25,596 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:25,596 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:26,040 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'258'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'273'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'32.74s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_d0078d181bda4ae1b92337a036c46d1c'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd3fabddf1ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:26,040 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:26,040 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:26,045 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:26,045 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:26,045 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:26,046 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '258', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '273', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9996', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '32.74s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_d0078d181bda4ae1b92337a036c46d1c', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd3fabddf1ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:26,046 [DEBUG] openai._base_client: request_id: req_d0078d181bda4ae1b92337a036c46d1c
2025-09-12 15:42:26,046 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 15:42:26,047 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 15:42:26,047 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'status_code': 3, 'token_usage': {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}}
2025-09-12 15:42:26,047 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history=
2025-09-12 15:42:26,049 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:26,050 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:26,050 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:26,050 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:26,050 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:26,050 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:26,051 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:26,975 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'241'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'431'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'48.49s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_e8de2372480b47ee86457874aedc0f6c'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd3fd9c541ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:26,976 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:26,976 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:26,980 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:26,980 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:26,980 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:26,980 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '241', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '431', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9994', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '48.49s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_e8de2372480b47ee86457874aedc0f6c', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd3fd9c541ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:26,980 [DEBUG] openai._base_client: request_id: req_e8de2372480b47ee86457874aedc0f6c
2025-09-12 15:42:26,981 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 15:42:26,984 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:26,984 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:26,984 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:26,985 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:26,985 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:26,985 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:26,985 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:27,540 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'360'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'382'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'48.635s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_e540cce9d29b4c29af8808645e4d4dde'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd40369701ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:27,541 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:27,541 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:27,542 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:27,542 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:27,542 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:27,542 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '360', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '382', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9994', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '48.635s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_e540cce9d29b4c29af8808645e4d4dde', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd40369701ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:27,542 [DEBUG] openai._base_client: request_id: req_e540cce9d29b4c29af8808645e4d4dde
2025-09-12 15:42:27,543 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 15:42:27,543 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 15:42:27,543 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 3, 'city_detected': True, 'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'token_usage': 318}
2025-09-12 15:42:27,544 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?' with conv_history: ''
2025-09-12 15:42:27,546 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:27,547 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:27,548 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:27,548 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:27,548 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:27,548 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:27,548 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:28,507 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'488'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'826'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'198986'), (b'x-ratelimit-reset-requests', b'47.963s'), (b'x-ratelimit-reset-tokens', b'304ms'), (b'x-request-id', b'req_830293bd8f2542b286904a7cc3fa60b9'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd406e9841ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:28,508 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:28,508 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:28,514 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:28,514 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:28,514 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:28,515 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '488', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '826', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9994', 'x-ratelimit-remaining-tokens': '198986', 'x-ratelimit-reset-requests': '47.963s', 'x-ratelimit-reset-tokens': '304ms', 'x-request-id': 'req_830293bd8f2542b286904a7cc3fa60b9', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd406e9841ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:28,515 [DEBUG] openai._base_client: request_id: req_830293bd8f2542b286904a7cc3fa60b9
2025-09-12 15:42:28,516 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}, cost=0.00017295
2025-09-12 15:42:28,516 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 15:42:28,516 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 15:42:28,517 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': [], 'intent': 'none'}
2025-09-12 15:42:28,517 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: [], intent: none, cost: 0.00017295, token_usage: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}
2025-09-12 15:42:28,517 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | []
2025-09-12 15:42:28,517 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=[] and institution_list length=553)
2025-09-12 15:42:28,517 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: []
2025-09-12 15:42:28,517 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: none
2025-09-12 15:42:28,517 [INFO] app.features.query_analysis.institution_names.institution_names_validation: No specific institution detected
2025-09-12 15:42:28,517 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': None, 'institution_name_mentioned': False, 'error': 'No institution detected', 'intent': 'none', 'detection_method': 'llm', 'cost': 0.00017295, 'token_usage': 1108}
2025-09-12 15:42:28,520 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:28,521 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:28,521 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:28,521 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:28,521 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:28,521 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:28,521 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:29,003 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'283'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'307'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9992'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m4.367s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_d595b456ce8f480a8f1ac3d8e0067780'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd40d0f351ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:29,004 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:29,004 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:29,013 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:29,014 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:29,014 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:29,014 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '283', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '307', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9992', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m4.367s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_d595b456ce8f480a8f1ac3d8e0067780', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd40d0f351ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:29,014 [DEBUG] openai._base_client: request_id: req_d595b456ce8f480a8f1ac3d8e0067780
2025-09-12 15:42:29,015 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}, cost=3.27e-05
2025-09-12 15:42:29,015 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.27e-05, {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}
2025-09-12 15:42:29,015 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.27e-05, 'token_usage': 215}
2025-09-12 15:42:29,018 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:29,018 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:29,018 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:29,019 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:29,019 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:29,019 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:29,019 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:29,549 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'340'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'369'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9991'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'1m11.941s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_3fb4a5bd66944576bc439b839e32829a'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd4101e201ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:29,549 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:29,550 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:29,554 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:29,554 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:29,555 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:29,555 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '340', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '369', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9991', 'x-ratelimit-remaining-tokens': '199678', 'x-ratelimit-reset-requests': '1m11.941s', 'x-ratelimit-reset-tokens': '96ms', 'x-request-id': 'req_3fb4a5bd66944576bc439b839e32829a', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd4101e201ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:29,555 [DEBUG] openai._base_client: request_id: req_3fb4a5bd66944576bc439b839e32829a
2025-09-12 15:42:29,556 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}, cost=4.71e-05
2025-09-12 15:42:29,556 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.71e-05, {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}
2025-09-12 15:42:29,556 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.71e-05, 'token_usage': 311}
2025-09-12 15:42:29,556 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer de la vessie, city=Paris, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 15:42:29,556 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.765e-05, city_cost=7.86e-05, institution_names_cost=0.00017295, institution_type_cost=3.27e-05, number_institutions_cost=4.71e-05
2025-09-12 15:42:29,556 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=318, institution_names_tokens=1108, institution_type_tokens=215, number_institutions_tokens=311
2025-09-12 15:42:29,556 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.86e-05, 'city_token_usage': 318, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017295, 'institution_names_token_usage': 1108, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.27e-05, 'institution_type_token_usage': 215, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.765e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.71e-05, 'number_institutions_token_usage': 311, 'total_cost': 0.000399, 'total_token_usage': 1952}
2025-09-12 15:42:29,556 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer de la vessie', city='Paris', city_detected=True, institution_type='aucune correspondance', number_institutions=3, institution_names=None, institution_name_mentioned=False
2025-09-12 15:42:29,556 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer de la vessie'
2025-09-12 15:42:29,556 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: 'Paris'
2025-09-12 15:42:29,557 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: True
2025-09-12 15:42:29,557 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 15:42:29,557 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 3
2025-09-12 15:42:29,557 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: []
2025-09-12 15:42:29,557 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 15:42:29,557 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'none'
2025-09-12 15:42:29,557 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: False
2025-09-12 15:42:29,587 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:42:29,587 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 15:42:29,806 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 15:42:29,806 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 15:42:29,806 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer de la vessie'
2025-09-12 15:42:29,806 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: 'Paris'
2025-09-12 15:42:29,806 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: True
2025-09-12 15:42:29,806 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 15:42:29,806 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: []
2025-09-12 15:42:29,807 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: False
2025-09-12 15:42:29,807 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 3
2025-09-12 15:42:29,807 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer de la vessie, city: Paris, institution_type: aucune correspondance, institution: [], institution_name_mentioned: False
2025-09-12 15:42:29,807 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 15:42:29,807 [DEBUG] app.services.pipeline_orchestrator_service: [CITY DETECTION] Detected city: 'Paris', city_detected: True, DataProcessor.city: 'Paris', DataProcessor.city_detected: True
2025-09-12 15:42:29,807 [DEBUG] app.services.pipeline_orchestrator_service: Calling build_ranking_dataframe_with_distances
2025-09-12 15:42:29,807 [INFO] app.services.pipeline_orchestrator_service: Building ranking DataFrame with distances: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', excel_path='/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx', detected_specialty='cancer de la vessie'
2025-09-12 15:42:29,807 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', detected_specialty='cancer de la vessie', conv_history='None'
2025-09-12 15:42:29,807 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 15:42:29,807 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 15:42:29,807 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 15:42:29,808 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 15:42:29,996 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:42:29,997 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history: 
2025-09-12 15:42:29,997 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'
2025-09-12 15:42:30,000 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:30,001 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:30,001 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:30,001 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:30,001 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:30,001 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:30,001 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:30,439 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'293'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'310'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9990'), (b'x-ratelimit-remaining-tokens', b'199552'), (b'x-ratelimit-reset-requests', b'1m20.205s'), (b'x-ratelimit-reset-tokens', b'134ms'), (b'x-request-id', b'req_e3e847b402044674a3c012ef974d71d0'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd4164c0a1ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:30,440 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:30,440 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:30,441 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:30,441 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:30,441 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:30,442 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '293', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '310', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9990', 'x-ratelimit-remaining-tokens': '199552', 'x-ratelimit-reset-requests': '1m20.205s', 'x-ratelimit-reset-tokens': '134ms', 'x-request-id': 'req_e3e847b402044674a3c012ef974d71d0', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd4164c0a1ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:30,442 [DEBUG] openai._base_client: request_id: req_e3e847b402044674a3c012ef974d71d0
2025-09-12 15:42:30,443 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 431, 'completion_tokens': 5, 'total_tokens': 436}, cost=6.765e-05
2025-09-12 15:42:30,443 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer de la vessie, method: llm
2025-09-12 15:42:30,443 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer de la vessie', 'detection_method': 'llm', 'cost': 6.765e-05, 'token_usage': 0}
2025-09-12 15:42:30,443 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', conv_history: ''
2025-09-12 15:42:30,445 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:30,446 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:30,446 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:30,446 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:30,447 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:30,447 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:30,447 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:31,189 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'394'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'603'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m27.628s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_9e83d200152a41a9ab841adc3fff3c11'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd4190a7d1ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:31,190 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:31,190 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:31,194 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:31,194 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:31,195 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:31,195 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '394', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '603', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9989', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m27.628s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_9e83d200152a41a9ab841adc3fff3c11', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd4190a7d1ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:31,195 [DEBUG] openai._base_client: request_id: req_9e83d200152a41a9ab841adc3fff3c11
2025-09-12 15:42:31,196 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 15:42:31,198 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:31,199 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:31,199 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:31,200 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:31,200 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:31,200 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:31,200 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:31,651 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'286'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'305'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9988'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'1m35.684s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_9438e5f603c74a639cb3e4c34d542154'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd41dcd631ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:31,652 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:31,652 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:31,652 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:31,652 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:31,652 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:31,653 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '286', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '305', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9988', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '1m35.684s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_9438e5f603c74a639cb3e4c34d542154', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd41dcd631ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:31,653 [DEBUG] openai._base_client: request_id: req_9438e5f603c74a639cb3e4c34d542154
2025-09-12 15:42:31,654 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 15:42:31,654 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 15:42:31,654 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'status_code': 3, 'token_usage': {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}}
2025-09-12 15:42:31,654 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history=
2025-09-12 15:42:31,657 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:31,657 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:31,658 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:31,658 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:31,658 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:31,658 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:31,658 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:32,126 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'271'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'298'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9987'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m43.853s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_5950cbb208a7466bb59f4c595a9d50f0'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd4209b7d1ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:32,127 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:32,127 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:32,128 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:32,128 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:32,128 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:32,128 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '271', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '298', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9987', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m43.853s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_5950cbb208a7466bb59f4c595a9d50f0', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd4209b7d1ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:32,129 [DEBUG] openai._base_client: request_id: req_5950cbb208a7466bb59f4c595a9d50f0
2025-09-12 15:42:32,130 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 15:42:32,132 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:32,133 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:32,133 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:32,133 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:32,134 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:32,134 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:32,134 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:32,504 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'220'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'238'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9986'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'1m52.625s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_8b0986b0f797463ab517df5da4dc2a03'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd4239a0d1ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:32,505 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:32,505 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:32,510 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:32,511 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:32,511 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:32,511 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '220', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '238', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9986', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '1m52.625s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_8b0986b0f797463ab517df5da4dc2a03', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd4239a0d1ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:32,511 [DEBUG] openai._base_client: request_id: req_8b0986b0f797463ab517df5da4dc2a03
2025-09-12 15:42:32,512 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 15:42:32,512 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 15:42:32,512 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 3, 'city_detected': True, 'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'token_usage': 318}
2025-09-12 15:42:32,512 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?' with conv_history: ''
2025-09-12 15:42:32,514 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:32,515 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:32,516 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:32,516 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:32,516 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:32,516 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:32,516 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:33,204 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'502'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'525'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9986'), (b'x-ratelimit-remaining-tokens', b'198986'), (b'x-ratelimit-reset-requests', b'2m0.277s'), (b'x-ratelimit-reset-tokens', b'304ms'), (b'x-request-id', b'req_e0962042c2cc4923bffa21c14e83c9bd'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd425ff8b1ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:33,204 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:33,204 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:33,208 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:33,208 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:33,208 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:33,208 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:33 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '502', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '525', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9986', 'x-ratelimit-remaining-tokens': '198986', 'x-ratelimit-reset-requests': '2m0.277s', 'x-ratelimit-reset-tokens': '304ms', 'x-request-id': 'req_e0962042c2cc4923bffa21c14e83c9bd', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd425ff8b1ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:33,208 [DEBUG] openai._base_client: request_id: req_e0962042c2cc4923bffa21c14e83c9bd
2025-09-12 15:42:33,209 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1093, 'completion_tokens': 11, 'total_tokens': 1104}, cost=0.00017055
2025-09-12 15:42:33,209 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{"institutions": [], "intent": "none"}'
2025-09-12 15:42:33,209 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{"institutions": [], "intent": "none"}'
2025-09-12 15:42:33,209 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': [], 'intent': 'none'}
2025-09-12 15:42:33,210 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: [], intent: none, cost: 0.00017055, token_usage: {'prompt_tokens': 1093, 'completion_tokens': 11, 'total_tokens': 1104}
2025-09-12 15:42:33,210 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | []
2025-09-12 15:42:33,210 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=[] and institution_list length=553)
2025-09-12 15:42:33,210 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: []
2025-09-12 15:42:33,210 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: none
2025-09-12 15:42:33,210 [INFO] app.features.query_analysis.institution_names.institution_names_validation: No specific institution detected
2025-09-12 15:42:33,210 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': None, 'institution_name_mentioned': False, 'error': 'No institution detected', 'intent': 'none', 'detection_method': 'llm', 'cost': 0.00017055, 'token_usage': 1104}
2025-09-12 15:42:33,212 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:33,213 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:33,213 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:33,214 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:33,214 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:33,214 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:33,214 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:33,621 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'240'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'259'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9985'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'2m8.236s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_dde5a910ece44066bad05fa3bf450e76'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd42a58951ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:33,621 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:33,621 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:33,627 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:33,627 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:33,627 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:33,627 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:33 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '240', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '259', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9985', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '2m8.236s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_dde5a910ece44066bad05fa3bf450e76', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd42a58951ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:33,627 [DEBUG] openai._base_client: request_id: req_dde5a910ece44066bad05fa3bf450e76
2025-09-12 15:42:33,628 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}, cost=3.27e-05
2025-09-12 15:42:33,628 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.27e-05, {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}
2025-09-12 15:42:33,628 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.27e-05, 'token_usage': 215}
2025-09-12 15:42:33,631 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:42:33,631 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:42:33,632 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:42:33,632 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:42:33,632 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:42:33,632 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:42:33,632 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:42:34,002 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:42:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'217'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'238'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9986'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'1m59.185s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_65af07960179429c8d3a61c3affb6384'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfd42cfe8c1ed5-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:42:34,003 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:42:34,003 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:42:34,003 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:42:34,003 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:42:34,003 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:42:34,003 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:42:34 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '217', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '238', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9986', 'x-ratelimit-remaining-tokens': '199678', 'x-ratelimit-reset-requests': '1m59.185s', 'x-ratelimit-reset-tokens': '96ms', 'x-request-id': 'req_65af07960179429c8d3a61c3affb6384', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfd42cfe8c1ed5-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:42:34,004 [DEBUG] openai._base_client: request_id: req_65af07960179429c8d3a61c3affb6384
2025-09-12 15:42:34,004 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}, cost=4.71e-05
2025-09-12 15:42:34,004 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.71e-05, {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}
2025-09-12 15:42:34,004 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.71e-05, 'token_usage': 311}
2025-09-12 15:42:34,005 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer de la vessie, city=Paris, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 15:42:34,005 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.765e-05, city_cost=7.86e-05, institution_names_cost=0.00017055, institution_type_cost=3.27e-05, number_institutions_cost=4.71e-05
2025-09-12 15:42:34,005 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=318, institution_names_tokens=1104, institution_type_tokens=215, number_institutions_tokens=311
2025-09-12 15:42:34,005 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.86e-05, 'city_token_usage': 318, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017055, 'institution_names_token_usage': 1104, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.27e-05, 'institution_type_token_usage': 215, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.765e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.71e-05, 'number_institutions_token_usage': 311, 'total_cost': 0.0003966, 'total_token_usage': 1948}
2025-09-12 15:42:34,005 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer de la vessie', city='Paris', city_detected=True, institution_type='aucune correspondance', number_institutions=3, institution_names=None, institution_name_mentioned=False
2025-09-12 15:42:34,005 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer de la vessie'
2025-09-12 15:42:34,005 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: 'Paris'
2025-09-12 15:42:34,005 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: True
2025-09-12 15:42:34,005 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 15:42:34,005 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 3
2025-09-12 15:42:34,005 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: []
2025-09-12 15:42:34,005 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 15:42:34,005 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'none'
2025-09-12 15:42:34,005 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: False
2025-09-12 15:42:34,034 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:42:34,035 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 15:42:34,184 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 15:42:34,184 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 15:42:34,184 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer de la vessie'
2025-09-12 15:42:34,184 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: 'Paris'
2025-09-12 15:42:34,184 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: True
2025-09-12 15:42:34,184 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 15:42:34,184 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: []
2025-09-12 15:42:34,184 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: False
2025-09-12 15:42:34,184 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 3
2025-09-12 15:42:34,184 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer de la vessie, city: Paris, institution_type: aucune correspondance, institution: [], institution_name_mentioned: False
2025-09-12 15:42:34,185 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 15:42:34,185 [INFO] app.services.data_processing_service: generate_data_response called
2025-09-12 15:42:34,185 [DEBUG] app.services.data_processing_service: Extracted values - specialty: 'cancer de la vessie', institution_type: 'aucune correspondance', city: 'Paris'
2025-09-12 15:42:34,185 [DEBUG] app.services.data_processing_service: No institution type match found, loading by specialty only
2025-09-12 15:42:34,185 [INFO] app.services.data_processing_service: Filtering ranking by criteria: specialty='cancer de la vessie', institution_type='None'
2025-09-12 15:42:34,185 [DEBUG] app.services.data_processing_service: Filtering ranking data - specialty: 'cancer de la vessie', institution_type: 'None'
2025-09-12 15:42:34,185 [DEBUG] app.services.data_processing_service: Specialty type: <class 'str'>, length: 19
2025-09-12 15:42:34,185 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer de la vessie
2025-09-12 15:42:34,185 [DEBUG] app.services.data_processing_service: No specialty provided or specialty is 'no match', returning empty DataFrame
2025-09-12 15:42:34,186 [INFO] app.services.data_processing_service: generate_response_links called with matching_rows: <class 'pandas.core.frame.DataFrame'>
2025-09-12 15:42:34,186 [INFO] app.services.data_processing_service: Generating ranking links
2025-09-12 15:42:34,186 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer de la vessie
2025-09-12 15:42:34,186 [DEBUG] app.services.data_processing_service: No specialty detected, generating general ranking links
2025-09-12 15:42:34,186 [INFO] app.services.data_processing_service: load_excel_sheets called with matching_rows of length: 0
2025-09-12 15:42:34,186 [WARNING] app.services.data_processing_service: No matching rows provided to load_excel_sheets
2025-09-12 15:42:34,186 [INFO] app.services.data_processing_service: Loaded specialty DataFrame
2025-09-12 15:42:34,186 [WARNING] app.services.pipeline_orchestrator_service: Ranking not found for requested specialty/type
2025-09-12 15:42:34,187 [DEBUG] app.services.pipeline_orchestrator_service: build_ranking_dataframe_with_distances returned DataFrame: <class 'pandas.core.frame.DataFrame'>
2025-09-12 15:42:34,187 [DEBUG] app.services.pipeline_orchestrator_service: Checking if DataFrame is None
2025-09-12 15:42:34,187 [DEBUG] app.services.pipeline_orchestrator_service: Retrieved DataFrame shape: (0, 0)
2025-09-12 15:42:34,187 [DEBUG] app.services.pipeline_orchestrator_service: Checking for geolocation API errors
2025-09-12 15:42:34,187 [DEBUG] app.services.pipeline_orchestrator_service: Getting ranking link for UI
2025-09-12 15:42:34,187 [DEBUG] app.services.pipeline_orchestrator_service: Checking for specialty_ranking_unavailable
2025-09-12 15:42:34,187 [WARNING] app.services.pipeline_orchestrator_service: Ranking not found for requested specialty/type, suggesting alternative
2025-09-12 15:42:34,187 [DEBUG] app.services.pipeline_orchestrator_service: Checking if institution is mentioned
2025-09-12 15:42:34,187 [DEBUG] app.services.pipeline_orchestrator_service: Checking if city is detected
2025-09-12 15:42:34,187 [DEBUG] app.services.pipeline_orchestrator_service: [DF COLUMNS] DataFrame columns before city/distance selection: []
2025-09-12 15:42:34,187 [INFO] app.services.pipeline_orchestrator_service: No city detected, returning general ranking
2025-09-12 15:42:34,187 [DEBUG] app.services.pipeline_orchestrator_service: [GENERAL RANKING] DataFrame columns: []
2025-09-12 15:42:34,187 [ERROR] app.services.pipeline_orchestrator_service: Exception in general ranking response: 'Catégorie'
Traceback (most recent call last):
  File "/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/app/services/pipeline_orchestrator_service.py", line 856, in generate_response
    public_df = self.df_gen[self.df_gen["Catégorie"] == "Public"].nlargest(self.number_institutions, "Note / 20")
                            ~~~~~~~~~~~^^^^^^^^^^^^^
  File "/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/chatbot_hop/lib/python3.13/site-packages/pandas/core/frame.py", line 4102, in __getitem__
    indexer = self.columns.get_loc(key)
  File "/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/chatbot_hop/lib/python3.13/site-packages/pandas/core/indexes/range.py", line 417, in get_loc
    raise KeyError(key)
KeyError: 'Catégorie'
2025-09-12 15:42:34,194 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 15:47:15,773 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:47:15,773 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:47:15,773 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:47:15,773 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:47:15,775 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:47:15,775 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:47:15,775 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:47:15,882 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:47:15,882 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:47:15,882 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:47:15,887 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:47:15,887 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:47:16,087 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:47:16,087 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:47:16,087 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:47:16,088 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:47:16,088 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:47:16,088 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:47:16,161 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:47:16,161 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:47:16,161 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:47:16,163 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:47:16,163 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:47:16,163 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:47:16,163 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:47:16,163 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:47:16,163 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:47:16,163 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:47:16,164 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:47:16,164 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:47:16,164 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:47:16,165 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:47:16,238 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:47:16,239 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:47:16,239 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:47:16,240 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:47:16,241 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:47:16,272 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:47:16,273 [INFO] main: Creating FastAPI app
2025-09-12 15:47:16,274 [INFO] main: CORS middleware added
2025-09-12 15:47:16,275 [INFO] main: API router included
2025-09-12 15:47:20,599 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:47:20,599 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:47:20,600 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:47:20,600 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:47:20,600 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:47:20,601 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:47:20,601 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:47:20,692 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:47:20,693 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:47:20,693 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:47:20,695 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:47:20,696 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:47:20,840 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:47:20,841 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:47:20,841 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:47:20,841 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:47:20,841 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:47:20,842 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:47:20,916 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:47:20,916 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:47:20,916 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:47:20,918 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:47:20,918 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:47:20,918 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:47:20,918 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:47:20,918 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:47:20,918 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:47:20,918 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:47:20,918 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:47:20,919 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:47:20,919 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:47:20,919 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:47:20,992 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:47:20,992 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:47:20,992 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:47:20,994 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:47:20,994 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:47:21,025 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:47:21,027 [INFO] main: Creating FastAPI app
2025-09-12 15:47:21,027 [INFO] main: CORS middleware added
2025-09-12 15:47:21,029 [INFO] main: API router included
2025-09-12 15:49:22,705 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:49:22,705 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:49:22,705 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:49:22,705 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:49:22,707 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:49:22,707 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:49:22,707 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:49:22,920 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:49:22,920 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:49:22,921 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:49:22,925 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:49:22,925 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:49:23,129 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:49:23,129 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:49:23,129 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:49:23,130 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:49:23,130 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:49:23,130 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:49:23,202 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:49:23,203 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:49:23,203 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:49:23,205 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:49:23,205 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:49:23,205 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:49:23,205 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:49:23,205 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:49:23,206 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:49:23,206 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:49:23,206 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:49:23,207 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:49:23,207 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:49:23,207 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:49:23,284 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:49:23,284 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:49:23,284 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:49:23,286 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:49:23,286 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:49:23,320 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:49:23,322 [INFO] main: Creating FastAPI app
2025-09-12 15:49:23,322 [INFO] main: CORS middleware added
2025-09-12 15:49:23,324 [INFO] main: API router included
2025-09-12 15:52:00,413 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:52:00,414 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:52:00,414 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:52:00,414 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:52:00,415 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:52:00,415 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:52:00,415 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:52:00,520 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:52:00,520 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:52:00,520 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:52:00,523 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:52:00,523 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:52:00,736 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:52:00,736 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:52:00,736 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:52:00,737 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:52:00,737 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:52:00,737 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:52:00,827 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:52:00,830 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:52:00,830 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:52:00,833 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:52:00,833 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:52:00,833 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:52:00,833 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:52:00,833 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:52:00,834 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:52:00,834 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:52:00,834 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:52:00,835 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:52:00,835 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:52:00,835 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:52:00,916 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:52:00,916 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:52:00,916 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:52:00,919 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:52:00,919 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:52:00,953 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:52:00,954 [INFO] main: Creating FastAPI app
2025-09-12 15:52:00,955 [INFO] main: CORS middleware added
2025-09-12 15:52:00,956 [INFO] main: API router included
2025-09-12 15:52:02,805 [INFO] app.services.pipeline_orchestrator_service: Starting pipeline processing - prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 15:52:02,806 [INFO] app.services.pipeline_orchestrator_service: Resetting PipelineOrchestrator attributes for new query
2025-09-12 15:52:02,806 [INFO] app.services.pipeline_orchestrator_service: Running sanity checks for prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conversation: [], conv_history: 
2025-09-12 15:52:02,806 [DEBUG] app.features.sanity_checks.sanity_checks_analyst: run_checks called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conversation=[], conv_history=, checks_to_run=['conversation_limit', 'message_length', 'message_pertinence']
2025-09-12 15:52:02,806 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst running checks: ['conversation_limit', 'message_length', 'message_pertinence'] for user_input: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 15:52:02,806 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check medical pertinence prompt sent to LLM.
2025-09-12 15:52:02,810 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nÉvaluez si le message suivant a un rapport avec la santé humaine ou les services de soins.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur la santé.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes de discussions médicales.\nATTENTION: Toute question sur la méthodologie, la fréquence de mise à jour, les critères, ou le fonctionnement du classement des hôpitaux doit TOUJOURS être considérée comme pertinente, même si elle ne concerne pas directement une maladie ou un service de soins.\n\nRépondez UNIQUEMENT avec 1 si pertinent, 0 si non pertinent ou 2 si la question concerne la méthodologie de calcul du classement.\n\nExemples pour messages standalone (repondre 1): \n- \'J\'ai un cancer à Paris\' → 1\n- \'Cataracte\' → 1  \n- \'J\'ai mal aux pieds\' → 1\n- \'Les hôpitaux privés sont ils meilleurs que les publiques?\' → 1\n- \'Comment le classement est-il calculé ?\' → 1\n- \'Quels sont les critères du classement ?\' → 1\n- "Quels experts participent à l\'élaboration du classement ?"\' → 1\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\' → 1\n- "Comment sont traitées les données manquantes dans le classement ?"\' → 1\n- "Le classement est-il le même pour toutes les spécialités ?"\' → 1\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\' → 1\n- "Quels sont les changements dans la méthodologie cette année ?"\' → 1\n- "Comment puis-je accéder au détail de la méthodologie ?"\' → 1\n\nExemples pour messages standalone (repondre 0):\n- \'Je mange des frites\' → 0\n- \'Comment faire une tarte aux pommes ?\' → 0\n- \'Comment s\'abonner Le Point ?\' → 0\n- \'Quel est le meilleur restaurant à Paris ?\' → 0\n\n\nExemples de questions qui concernent la méthodologie de classement (repondre 2):\n- "Comment le classement est-il calculé ?"\n- "Quels sont les critères du classement ?" \n- "Pourquoi l\'hôpital X est mieux classé que Y ?"\n- "Comment sont choisis les critères du classement ?"\n- "Qui réalise le classement des hôpitaux ?"\n- "Quelle est la source des données utilisées pour le classement ?"\n- "Le classement prend-il en compte la satisfaction des patients ?"\n- "Comment sont pondérés les différents critères ?"\n- "Est-ce que le classement est mis à jour chaque année ?"\n- "Pourquoi certains hôpitaux ne figurent pas dans le classement ?"\n- "Comment puis-je vérifier la fiabilité du classement ?"\n- "Quels experts participent à l\'élaboration du classement ?"\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\n- "Comment sont traitées les données manquantes dans le classement ?"\n- "Le classement est-il le même pour toutes les spécialités ?"\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\n- "Quels sont les changements dans la méthodologie cette année ?"\n- "Comment puis-je accéder au détail de la méthodologie ?"\n\nExemples pour messages avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique montrant une discussion sur les hôpitaux, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur la cardiologie, \'Merci\' → 1 (remerciement dans contexte médical)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n- Même avec contexte médical, \'Parle-moi de football\' → 0 (hors-sujet)\n- Avec historique sur les classements, "Comment sont déterminés les scores ?" → 2 (question sur la méthodologie de classement)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:02,837 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:02,838 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-09-12 15:52:02,876 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11c2d7a10>
2025-09-12 15:52:02,876 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x11bd2fda0> server_hostname='api.openai.com' timeout=None
2025-09-12 15:52:02,896 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11c30df90>
2025-09-12 15:52:02,897 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:02,897 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:02,897 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:02,897 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:02,897 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:03,914 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'698'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'861'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'198878'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'336ms'), (b'x-request-id', b'req_5f77f4e58c564d789339bfd9c0c09351'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=SLGafV3hVlmNeOlL3FwdZ.8wuOpnz095mqRi9hoiJ5U-1757685124-1.0.1.1-Q0slPxrCtvcDa9B3.lSSuB_dEHBbUMbLbladZWTnHiFcdEvXQN_jTUZE8J5g1nYQWinxFpcWHX72wf1IC3.2kV8nL4QP0Tk3x4c1sbjO5SQ; path=/; expires=Fri, 12-Sep-25 14:22:04 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=zzAVYiPHj8c.mfG3QtplvNzty4Rl9ehx6MOElvTThtg-1757685124065-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe213287ee28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:03,916 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:03,916 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:03,923 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:03,924 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:03,924 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:03,924 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 12 Sep 2025 13:52:04 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'le-point-hv3izr'), ('openai-processing-ms', '698'), ('openai-project', 'proj_auvPnKXq8lce0dksWKRj2pvx'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '861'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '198878'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '336ms'), ('x-request-id', 'req_5f77f4e58c564d789339bfd9c0c09351'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=SLGafV3hVlmNeOlL3FwdZ.8wuOpnz095mqRi9hoiJ5U-1757685124-1.0.1.1-Q0slPxrCtvcDa9B3.lSSuB_dEHBbUMbLbladZWTnHiFcdEvXQN_jTUZE8J5g1nYQWinxFpcWHX72wf1IC3.2kV8nL4QP0Tk3x4c1sbjO5SQ; path=/; expires=Fri, 12-Sep-25 14:22:04 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=zzAVYiPHj8c.mfG3QtplvNzty4Rl9ehx6MOElvTThtg-1757685124065-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '97dfe213287ee28d-MRS'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-12 15:52:03,924 [DEBUG] openai._base_client: request_id: req_5f77f4e58c564d789339bfd9c0c09351
2025-09-12 15:52:03,932 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_medical_pertinence' successful: {'prompt_tokens': 1112, 'completion_tokens': 1, 'total_tokens': 1113}, cost=0.00016739999999999998
2025-09-12 15:52:03,933 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for medical pertinence:
1
2025-09-12 15:52:03,933 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed medical pertinence value: 1 (type: <class 'int'>)
2025-09-12 15:52:03,933 [DEBUG] app.features.sanity_checks.message_pertinence_check: medical_pertinence_result: {'result': 1, 'cost': 0.00016739999999999998, 'token_usage': 1113}
2025-09-12 15:52:03,933 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check chatbot pertinence prompt sent to LLM.
2025-09-12 15:52:03,936 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nVérifiez si cette question concerne le classement des hôpitaux.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur les classements d\'hôpitaux.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes.\n\nRépondez UNIQUEMENT avec:\n- 1 si la question est pertinente pour le chatbot (classement, recherche d\'établissement, etc.)\n- 0 si la question n\'est pas pertinente\n\nUne question est pertinente si elle concerne au moins un des cas suivants:\n- Une maladie, un symptôme ou une spécialité médicale  \n- Le classement des hôpitaux et cliniques  \n- La recherche d\'un hôpital, d\'une clinique ou d\'un service médical  \n- Une question de suivi sur les secteurs public/privé des hôpitaux\n\nExemples de questions pertinentes pour messages standalone (repondre 1):  \n- Quel est la meilleur clinique de France ?\n- Conseille moi un hôpital à Lyon \n- Je chercher un service de pneumologie\n- Où faire soigner mon glaucome ? \n- Je veux corriger mon audition\n- Il y a fréquemment du sang dans mes urines. Conseille-moi un hôpital. \n- Je veux cherche à faire soigner mes troubles bipôlaires\n- Est-ce que l\'Institut mutualiste Montsouris est bon ?\n- Y a-t-il des hôpitaux privés avec un service de cardiologie interventionnelle ?\n\nExemples de questions non pertinentes pour messages standalone (repondre 0):  \n- Pourquoi les hôpitaux sont-ils en crise ?  #Il s\'agit d\'une demande d\'information qui n\'est pas dans le cadre direct de la recherche d\'un établissement de soin\n- Dois-je prendre du paracétamol pour ma fièvre ? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n- Puis-je perdre la vue si j\'ai un glaucome? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n\n\n\nExemples avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique sur les hôpitaux parisiens, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur les classements, \'Combien coûte une consultation ?\' → 0 (question sur les coûts, pas sur les classements)\n- Avec historique sur la recherche d\'hôpital, \'Merci beaucoup\' → 1 (remerciement dans contexte de recherche d\'hôpital)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:03,937 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:03,937 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:03,938 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:03,938 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:03,938 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:03,938 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:04,459 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'346'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'368'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199169'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'249ms'), (b'x-request-id', b'req_f9b0749c1b6448a7afca609f74d05dd8'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe219a8c9e28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:04,460 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:04,460 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:04,469 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:04,469 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:04,469 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:04,469 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:52:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '346', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '368', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199169', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '249ms', 'x-request-id': 'req_f9b0749c1b6448a7afca609f74d05dd8', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe219a8c9e28d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:52:04,469 [DEBUG] openai._base_client: request_id: req_f9b0749c1b6448a7afca609f74d05dd8
2025-09-12 15:52:04,470 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_chatbot_pertinence' successful: {'prompt_tokens': 810, 'completion_tokens': 1, 'total_tokens': 811}, cost=0.00012209999999999999
2025-09-12 15:52:04,470 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for chatbot pertinence:
1
2025-09-12 15:52:04,470 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed chatbot pertinence value: 1 (type: <class 'int'>)
2025-09-12 15:52:04,470 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst completed checks. All passed: True, Total cost: 0.00028949999999999994, Total tokens: 1924
2025-09-12 15:52:04,470 [INFO] app.features.sanity_checks.sanity_checks_analyst: Sanity check results: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 15:52:04,470 [INFO] app.services.pipeline_orchestrator_service: Sanity checks result: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 15:52:04,471 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', detected_specialty='None', conv_history=''
2025-09-12 15:52:04,471 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 15:52:04,471 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 15:52:04,471 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 15:52:04,471 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 15:52:04,667 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:52:04,667 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history: 
2025-09-12 15:52:04,667 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'
2025-09-12 15:52:04,670 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:04,670 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:04,671 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:04,671 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:04,671 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:04,671 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:04,671 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:05,302 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'341'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'473'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199553'), (b'x-ratelimit-reset-requests', b'15.516s'), (b'x-ratelimit-reset-tokens', b'134ms'), (b'x-request-id', b'req_19e3a93c30e84e3da9d8b33c5f222645'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe21e3c6ae28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:05,302 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:05,302 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:05,307 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:05,307 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:05,307 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:05,307 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:52:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '341', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '473', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199553', 'x-ratelimit-reset-requests': '15.516s', 'x-ratelimit-reset-tokens': '134ms', 'x-request-id': 'req_19e3a93c30e84e3da9d8b33c5f222645', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe21e3c6ae28d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:52:05,308 [DEBUG] openai._base_client: request_id: req_19e3a93c30e84e3da9d8b33c5f222645
2025-09-12 15:52:05,308 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 431, 'completion_tokens': 6, 'total_tokens': 437}, cost=6.825e-05
2025-09-12 15:52:05,308 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer de la vessie., method: llm
2025-09-12 15:52:05,309 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer de la vessie', 'detection_method': 'llm', 'cost': 6.825e-05, 'token_usage': 0}
2025-09-12 15:52:05,309 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', conv_history: ''
2025-09-12 15:52:05,312 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:05,312 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:05,312 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:05,313 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:05,313 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:05,313 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:05,313 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:05,769 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'176'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'318'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'23.523s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_07b7e6e2b2c24087b119e67f6d997127'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe2223e04e28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:05,769 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:05,769 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:05,772 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:05,772 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:05,772 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:05,772 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:52:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '176', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '318', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '23.523s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_07b7e6e2b2c24087b119e67f6d997127', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe2223e04e28d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:52:05,772 [DEBUG] openai._base_client: request_id: req_07b7e6e2b2c24087b119e67f6d997127
2025-09-12 15:52:05,773 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 15:52:05,776 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:05,776 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:05,777 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:05,777 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:05,777 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:05,777 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:05,777 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:06,206 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'278'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'292'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'14.553s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_40a33967836043afaca2255b2b192379'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe2252d1ae28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:06,207 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:06,207 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:06,208 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:06,208 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:06,208 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:06,208 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:52:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '278', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '292', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '14.553s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_40a33967836043afaca2255b2b192379', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe2252d1ae28d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:52:06,209 [DEBUG] openai._base_client: request_id: req_40a33967836043afaca2255b2b192379
2025-09-12 15:52:06,210 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 15:52:06,210 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 15:52:06,210 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'status_code': 3, 'token_usage': {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}}
2025-09-12 15:52:06,210 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history=
2025-09-12 15:52:06,213 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:06,213 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:06,214 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:06,214 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:06,214 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:06,214 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:06,214 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:06,710 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'296'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'340'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'32.275s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_bcc21dd7897a46659c95a80150ed1c46'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe227eb8ce28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:06,710 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:06,711 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:06,723 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:06,723 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:06,723 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:06,724 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:52:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '296', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '340', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9996', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '32.275s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_bcc21dd7897a46659c95a80150ed1c46', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe227eb8ce28d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:52:06,724 [DEBUG] openai._base_client: request_id: req_bcc21dd7897a46659c95a80150ed1c46
2025-09-12 15:52:06,725 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 15:52:06,727 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:06,728 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:06,728 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:06,728 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:06,728 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:06,728 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:06,728 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:07,158 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'252'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'267'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'49.037s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_9cb2215101cf4b6883cf8ff8c81db80c'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe22b1b12e28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:07,158 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:07,158 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:07,164 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:07,164 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:07,164 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:07,164 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:52:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '252', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '267', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9994', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '49.037s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_9cb2215101cf4b6883cf8ff8c81db80c', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe22b1b12e28d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:52:07,165 [DEBUG] openai._base_client: request_id: req_9cb2215101cf4b6883cf8ff8c81db80c
2025-09-12 15:52:07,166 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 15:52:07,166 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 15:52:07,166 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 3, 'city_detected': True, 'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'token_usage': 318}
2025-09-12 15:52:07,166 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?' with conv_history: ''
2025-09-12 15:52:07,168 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:07,171 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:07,171 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:07,171 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:07,171 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:07,171 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:07,172 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:08,002 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'537'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'680'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'198986'), (b'x-ratelimit-reset-requests', b'56.215s'), (b'x-ratelimit-reset-tokens', b'304ms'), (b'x-request-id', b'req_b6aa145af9d6484b99646e9fb0f2e233'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe22ddaace28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:08,002 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:08,002 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:08,006 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:08,006 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:08,006 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:08,006 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:52:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '537', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '680', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9993', 'x-ratelimit-remaining-tokens': '198986', 'x-ratelimit-reset-requests': '56.215s', 'x-ratelimit-reset-tokens': '304ms', 'x-request-id': 'req_b6aa145af9d6484b99646e9fb0f2e233', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe22ddaace28d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:52:08,006 [DEBUG] openai._base_client: request_id: req_b6aa145af9d6484b99646e9fb0f2e233
2025-09-12 15:52:08,007 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}, cost=0.00017295
2025-09-12 15:52:08,007 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 15:52:08,007 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 15:52:08,008 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': [], 'intent': 'none'}
2025-09-12 15:52:08,008 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: [], intent: none, cost: 0.00017295, token_usage: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}
2025-09-12 15:52:08,008 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | []
2025-09-12 15:52:08,008 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=[] and institution_list length=553)
2025-09-12 15:52:08,008 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: []
2025-09-12 15:52:08,008 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: none
2025-09-12 15:52:08,009 [INFO] app.features.query_analysis.institution_names.institution_names_validation: No specific institution detected
2025-09-12 15:52:08,009 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': None, 'institution_name_mentioned': False, 'error': 'No institution detected', 'intent': 'none', 'detection_method': 'llm', 'cost': 0.00017295, 'token_usage': 1108}
2025-09-12 15:52:08,012 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:08,013 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:08,013 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:08,013 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:08,013 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:08,014 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:08,014 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:08,540 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'379'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'396'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'55.515s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_4c32f8640e0042578de87a7623cd5ab8'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe2332f33e28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:08,540 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:08,540 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:08,543 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:08,544 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:08,544 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:08,544 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:52:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '379', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '396', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9993', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '55.515s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_4c32f8640e0042578de87a7623cd5ab8', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe2332f33e28d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:52:08,544 [DEBUG] openai._base_client: request_id: req_4c32f8640e0042578de87a7623cd5ab8
2025-09-12 15:52:08,545 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}, cost=3.27e-05
2025-09-12 15:52:08,545 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.27e-05, {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}
2025-09-12 15:52:08,545 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.27e-05, 'token_usage': 215}
2025-09-12 15:52:08,547 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:08,548 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:08,548 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:08,548 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:08,548 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:08,549 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:08,549 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:08,973 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'268'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'284'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9991'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'1m12.254s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_c10cc0f93bae4a549d65ae2cac92000e'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe2367f28e28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:08,974 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:08,974 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:08,981 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:08,981 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:08,981 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:08,981 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:52:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '268', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '284', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9991', 'x-ratelimit-remaining-tokens': '199678', 'x-ratelimit-reset-requests': '1m12.254s', 'x-ratelimit-reset-tokens': '96ms', 'x-request-id': 'req_c10cc0f93bae4a549d65ae2cac92000e', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe2367f28e28d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:52:08,981 [DEBUG] openai._base_client: request_id: req_c10cc0f93bae4a549d65ae2cac92000e
2025-09-12 15:52:08,982 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}, cost=4.71e-05
2025-09-12 15:52:08,982 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.71e-05, {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}
2025-09-12 15:52:08,982 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.71e-05, 'token_usage': 311}
2025-09-12 15:52:08,982 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer de la vessie, city=Paris, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 15:52:08,982 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.825e-05, city_cost=7.86e-05, institution_names_cost=0.00017295, institution_type_cost=3.27e-05, number_institutions_cost=4.71e-05
2025-09-12 15:52:08,983 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=318, institution_names_tokens=1108, institution_type_tokens=215, number_institutions_tokens=311
2025-09-12 15:52:08,983 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.86e-05, 'city_token_usage': 318, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017295, 'institution_names_token_usage': 1108, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.27e-05, 'institution_type_token_usage': 215, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.825e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.71e-05, 'number_institutions_token_usage': 311, 'total_cost': 0.0003996, 'total_token_usage': 1952}
2025-09-12 15:52:08,983 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer de la vessie', city='Paris', city_detected=True, institution_type='aucune correspondance', number_institutions=3, institution_names=None, institution_name_mentioned=False
2025-09-12 15:52:08,983 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer de la vessie'
2025-09-12 15:52:08,983 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: 'Paris'
2025-09-12 15:52:08,983 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: True
2025-09-12 15:52:08,983 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 15:52:08,983 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 3
2025-09-12 15:52:08,983 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: []
2025-09-12 15:52:08,983 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 15:52:08,983 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'none'
2025-09-12 15:52:08,983 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: False
2025-09-12 15:52:09,015 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:52:09,016 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 15:52:09,237 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 15:52:09,254 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 15:52:09,254 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer de la vessie'
2025-09-12 15:52:09,254 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: 'Paris'
2025-09-12 15:52:09,254 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: True
2025-09-12 15:52:09,254 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 15:52:09,255 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: []
2025-09-12 15:52:09,255 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: False
2025-09-12 15:52:09,255 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 3
2025-09-12 15:52:09,255 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer de la vessie, city: Paris, institution_type: aucune correspondance, institution: [], institution_name_mentioned: False
2025-09-12 15:52:09,255 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 15:52:09,255 [DEBUG] app.services.pipeline_orchestrator_service: [CITY DETECTION] Detected city: 'Paris', city_detected: True, DataProcessor.city: 'Paris', DataProcessor.city_detected: True
2025-09-12 15:52:09,255 [DEBUG] app.services.pipeline_orchestrator_service: Calling build_ranking_dataframe_with_distances
2025-09-12 15:52:09,255 [INFO] app.services.pipeline_orchestrator_service: Building ranking DataFrame with distances: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', excel_path='/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx', detected_specialty='cancer de la vessie'
2025-09-12 15:52:09,255 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', detected_specialty='cancer de la vessie', conv_history='None'
2025-09-12 15:52:09,255 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 15:52:09,255 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 15:52:09,255 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 15:52:09,255 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 15:52:09,453 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:52:09,454 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history: 
2025-09-12 15:52:09,454 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'
2025-09-12 15:52:09,456 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:09,457 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:09,457 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:09,457 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:09,457 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:09,458 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:09,458 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:10,083 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'435'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'456'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'199553'), (b'x-ratelimit-reset-requests', b'1m28.601s'), (b'x-ratelimit-reset-tokens', b'134ms'), (b'x-request-id', b'req_5a3c092214eb47e98178cf0c2db6698d'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe23c2ca6e28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:10,084 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:10,084 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:10,086 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:10,086 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:10,087 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:10,087 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:52:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '435', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '456', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9989', 'x-ratelimit-remaining-tokens': '199553', 'x-ratelimit-reset-requests': '1m28.601s', 'x-ratelimit-reset-tokens': '134ms', 'x-request-id': 'req_5a3c092214eb47e98178cf0c2db6698d', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe23c2ca6e28d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:52:10,087 [DEBUG] openai._base_client: request_id: req_5a3c092214eb47e98178cf0c2db6698d
2025-09-12 15:52:10,088 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 431, 'completion_tokens': 6, 'total_tokens': 437}, cost=6.825e-05
2025-09-12 15:52:10,088 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer de la vessie., method: llm
2025-09-12 15:52:10,088 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer de la vessie', 'detection_method': 'llm', 'cost': 6.825e-05, 'token_usage': 0}
2025-09-12 15:52:10,088 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', conv_history: ''
2025-09-12 15:52:10,091 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:10,092 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:10,093 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:10,094 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:10,095 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:10,095 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:10,095 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:10,489 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'250'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'265'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m27.995s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_12f0af0ac52b4fffbcca2dcbbacc2b2e'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe2402d98e28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:10,490 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:10,490 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:10,497 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:10,497 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:10,498 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:10,498 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:52:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '250', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '265', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9989', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m27.995s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_12f0af0ac52b4fffbcca2dcbbacc2b2e', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe2402d98e28d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:52:10,499 [DEBUG] openai._base_client: request_id: req_12f0af0ac52b4fffbcca2dcbbacc2b2e
2025-09-12 15:52:10,500 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 15:52:10,503 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:10,504 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:10,505 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:10,505 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:10,505 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:10,505 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:10,505 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:10,940 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'274'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'289'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'199647'), (b'x-ratelimit-reset-requests', b'1m27.572s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_4a719ae299e84b5d9cd93a23523cd71a'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe242bb5be28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:10,941 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:10,941 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:10,943 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:10,944 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:10,944 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:10,944 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:52:11 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '274', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '289', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9989', 'x-ratelimit-remaining-tokens': '199647', 'x-ratelimit-reset-requests': '1m27.572s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_4a719ae299e84b5d9cd93a23523cd71a', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe242bb5be28d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:52:10,944 [DEBUG] openai._base_client: request_id: req_4a719ae299e84b5d9cd93a23523cd71a
2025-09-12 15:52:10,945 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 15:52:10,945 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 15:52:10,945 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'status_code': 3, 'token_usage': {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}}
2025-09-12 15:52:10,945 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history=
2025-09-12 15:52:10,948 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:10,948 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:10,948 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:10,949 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:10,949 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:10,949 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:10,949 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:12,342 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'1228'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1242'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9987'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m45.306s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_934862c66b084e8da7945352d36e2eb1'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe2457a04e28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:12,343 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:12,343 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:12,346 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:12,346 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:12,346 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:12,346 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:52:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '1228', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1242', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9987', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m45.306s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_934862c66b084e8da7945352d36e2eb1', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe2457a04e28d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:52:12,347 [DEBUG] openai._base_client: request_id: req_934862c66b084e8da7945352d36e2eb1
2025-09-12 15:52:12,347 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 60, 'total_tokens': 259}, cost=6.585e-05
2025-09-12 15:52:12,348 [WARNING] app.features.query_analysis.city.city_detection: Invalid city status: Dans le message à analyser, "Quels sont les meilleurs hôpitaux à Paris pour le cancer de la vessie ?", la ville de Paris est clairement mentionnée. 

En tenant compte du contexte conversationnel, la localisation est explicite. 

Ainsi, la réponse est : **3**., defaulting to CITY_NO_CITY_MENTIONED
2025-09-12 15:52:12,348 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=None, status=0, method=status, cost=6.585e-05, tokens={'prompt_tokens': 199, 'completion_tokens': 60, 'total_tokens': 259}
2025-09-12 15:52:12,348 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 3, 'city_detected': True, 'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'token_usage': 318}
2025-09-12 15:52:12,348 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?' with conv_history: ''
2025-09-12 15:52:12,351 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:12,351 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:12,352 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:12,352 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:12,352 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:12,352 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:12,352 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:13,124 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'582'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'611'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9985'), (b'x-ratelimit-remaining-tokens', b'198986'), (b'x-ratelimit-reset-requests', b'2m1.171s'), (b'x-ratelimit-reset-tokens', b'304ms'), (b'x-request-id', b'req_0127b34954df4464ba6461a29e87c2ab'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe24e3dafe28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:13,125 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:13,125 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:13,129 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:13,129 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:13,129 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:13,129 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:52:13 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '582', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '611', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9985', 'x-ratelimit-remaining-tokens': '198986', 'x-ratelimit-reset-requests': '2m1.171s', 'x-ratelimit-reset-tokens': '304ms', 'x-request-id': 'req_0127b34954df4464ba6461a29e87c2ab', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe24e3dafe28d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:52:13,130 [DEBUG] openai._base_client: request_id: req_0127b34954df4464ba6461a29e87c2ab
2025-09-12 15:52:13,130 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}, cost=0.00017295
2025-09-12 15:52:13,131 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 15:52:13,131 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 15:52:13,131 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': [], 'intent': 'none'}
2025-09-12 15:52:13,131 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: [], intent: none, cost: 0.00017295, token_usage: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}
2025-09-12 15:52:13,131 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | []
2025-09-12 15:52:13,131 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=[] and institution_list length=553)
2025-09-12 15:52:13,131 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: []
2025-09-12 15:52:13,131 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: none
2025-09-12 15:52:13,131 [INFO] app.features.query_analysis.institution_names.institution_names_validation: No specific institution detected
2025-09-12 15:52:13,131 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': None, 'institution_name_mentioned': False, 'error': 'No institution detected', 'intent': 'none', 'detection_method': 'llm', 'cost': 0.00017295, 'token_usage': 1108}
2025-09-12 15:52:13,134 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:13,135 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:13,135 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:13,135 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:13,136 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:13,136 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:13,136 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:13,648 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'314'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'377'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9986'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m59.511s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_aabd253f5ff1457482119408bb82ea7c'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe253292ee28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:13,649 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:13,649 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:13,652 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:13,652 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:13,652 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:13,653 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:52:13 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '314', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '377', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9986', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m59.511s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_aabd253f5ff1457482119408bb82ea7c', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe253292ee28d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:52:13,653 [DEBUG] openai._base_client: request_id: req_aabd253f5ff1457482119408bb82ea7c
2025-09-12 15:52:13,654 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}, cost=3.27e-05
2025-09-12 15:52:13,654 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.27e-05, {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}
2025-09-12 15:52:13,655 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.27e-05, 'token_usage': 215}
2025-09-12 15:52:13,657 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:52:13,658 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:52:13,659 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:52:13,659 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:52:13,659 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:52:13,659 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:52:13,659 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:52:14,017 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:52:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'218'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'231'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9985'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'2m7.636s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_1241885c564746e4bde554138baa8c83'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe256689ee28d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:52:14,018 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:52:14,018 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:52:14,021 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:52:14,021 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:52:14,021 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:52:14,021 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:52:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '218', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '231', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9985', 'x-ratelimit-remaining-tokens': '199678', 'x-ratelimit-reset-requests': '2m7.636s', 'x-ratelimit-reset-tokens': '96ms', 'x-request-id': 'req_1241885c564746e4bde554138baa8c83', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe256689ee28d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:52:14,021 [DEBUG] openai._base_client: request_id: req_1241885c564746e4bde554138baa8c83
2025-09-12 15:52:14,022 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}, cost=4.71e-05
2025-09-12 15:52:14,022 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.71e-05, {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}
2025-09-12 15:52:14,022 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.71e-05, 'token_usage': 311}
2025-09-12 15:52:14,022 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer de la vessie, city=Paris, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 15:52:14,022 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.825e-05, city_cost=7.86e-05, institution_names_cost=0.00017295, institution_type_cost=3.27e-05, number_institutions_cost=4.71e-05
2025-09-12 15:52:14,023 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=318, institution_names_tokens=1108, institution_type_tokens=215, number_institutions_tokens=311
2025-09-12 15:52:14,023 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.86e-05, 'city_token_usage': 318, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017295, 'institution_names_token_usage': 1108, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.27e-05, 'institution_type_token_usage': 215, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.825e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.71e-05, 'number_institutions_token_usage': 311, 'total_cost': 0.0003996, 'total_token_usage': 1952}
2025-09-12 15:52:14,023 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer de la vessie', city='Paris', city_detected=True, institution_type='aucune correspondance', number_institutions=3, institution_names=None, institution_name_mentioned=False
2025-09-12 15:52:14,023 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer de la vessie'
2025-09-12 15:52:14,023 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: 'Paris'
2025-09-12 15:52:14,023 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: True
2025-09-12 15:52:14,023 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 15:52:14,023 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 3
2025-09-12 15:52:14,023 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: []
2025-09-12 15:52:14,023 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 15:52:14,023 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'none'
2025-09-12 15:52:14,023 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: False
2025-09-12 15:52:14,055 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:52:14,055 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 15:52:14,214 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 15:52:14,215 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 15:52:14,215 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer de la vessie'
2025-09-12 15:52:14,215 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: 'Paris'
2025-09-12 15:52:14,215 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: True
2025-09-12 15:52:14,215 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 15:52:14,215 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: []
2025-09-12 15:52:14,215 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: False
2025-09-12 15:52:14,215 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 3
2025-09-12 15:52:14,215 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer de la vessie, city: Paris, institution_type: aucune correspondance, institution: [], institution_name_mentioned: False
2025-09-12 15:52:14,215 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 15:52:14,215 [INFO] app.services.data_processing_service: generate_data_response called
2025-09-12 15:52:14,216 [DEBUG] app.services.data_processing_service: Extracted values - specialty: 'cancer de la vessie', institution_type: 'aucune correspondance', city: 'Paris'
2025-09-12 15:52:14,216 [DEBUG] app.services.data_processing_service: No institution type match found, loading by specialty only
2025-09-12 15:52:14,216 [INFO] app.services.data_processing_service: Filtering ranking by criteria: specialty='cancer de la vessie', institution_type='None'
2025-09-12 15:52:14,216 [DEBUG] app.services.data_processing_service: Filtering ranking data - specialty: 'cancer de la vessie', institution_type: 'None'
2025-09-12 15:52:14,216 [DEBUG] app.services.data_processing_service: Specialty type: <class 'str'>, length: 19
2025-09-12 15:52:14,216 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer de la vessie
2025-09-12 15:52:14,218 [DEBUG] app.services.data_processing_service: All normalized specialties in DataFrame: ['ablation des varices' 'accidents vasculaires cerebraux'
 'accouchements a risques' 'accouchements normaux'
 'adenome de la prostate' 'amygdales et vegetations'
 'angioplastie coronaire' 'appendicite' 'arthrose de la main' 'audition'
 'calculs urinaires' "cancer de l'estomac et de l'œsophage"
 "cancer de l'ovaire" "cancer de l'uterus" 'cancer de la prostate'
 'cancer de la thyroide' 'cancer de la vessie'
 "cancer des os de l'enfant et de l'adolescent"
 "cancer du colon ou de l'intestin" 'cancer du foie' 'cancer du pancreas'
 'cancer du poumon' 'cancer du rein' 'cancer du sein' 'cancer orl'
 'cancers de la peau' 'cardiologie interventionnelle' 'cataracte'
 'chirurgie cardiaque adulte' 'chirurgie cardiaque pediatrique'
 "chirurgie de l'epaule" "chirurgie de l'obesite"
 'chirurgie de la cheville' 'chirurgie de la cornee'
 'chirurgie dentaire et orale de l’adulte'
 'chirurgie dentaire et orale de l’enfant et de l’adolescent'
 'chirurgie des arteres' "chirurgie des cancers osseux de l'adulte"
 'chirurgie des carotides' 'chirurgie des sarcomes des tissus mous'
 "chirurgie des testicules de l'adulte"
 "chirurgie des testicules de l'enfant et de l'adolescent"
 'chirurgie du canal carpien' "chirurgie du dos de l'adulte"
 "chirurgie du dos de l'enfant et de l'adolescent"
 'chirurgie du nez et des sinus' 'chirurgie du pied' 'chirurgie du rectum'
 'chirurgie maxillo-faciale' 'depression' "diabete de l'adulte"
 "diabete de l'enfant et de l'adolescent" 'endometriose'
 "epilepsie de l'adulte" "epilepsie de l'enfant et de l'adolescent"
 'fibrome uterin' 'glandes salivaires' 'glaucome' "hernies de l'abdomen"
 'hypertension arterielle' 'infarctus du myocarde'
 'insuffisance cardiaque' "leucemie de l'adulte"
 "leucemie de l'enfant et de l'adolescent" 'ligaments du genou'
 "lymphome-myelome de l'adulte" 'maladie de parkinson'
 "maladies inflammatoires chroniques de l'intestin (mici)"
 'medecine vasculaire' 'pneumologie' 'proctologie' 'prothese de genou'
 'prothese de hanche' 'retine' 'schizophrenie' 'sclerose en plaques'
 'stimulateurs cardiaques' 'strabisme'
 'stress post-traumatique de l’adulte' 'troubles bipolaires'
 "tumeurs du cerveau de l'adulte"
 "tumeurs du cerveau de l'enfant et de l'adolescent" 'urgences de la main'
 'vesicule biliaire']
2025-09-12 15:52:14,218 [DEBUG] app.services.data_processing_service: Normalized specialty from query: 'cancer de la vessie'
2025-09-12 15:52:14,219 [DEBUG] app.services.data_processing_service: Normalized specialty from query: ''cancer de la vessie''
2025-09-12 15:52:14,220 [DEBUG] app.services.data_processing_service: Found 2 rows matching single specialty 'cancer de la vessie' (normalized: 'cancer de la vessie')
2025-09-12 15:52:14,220 [DEBUG] app.services.data_processing_service: Specialties found after specialty filtering: ['Cancer de la vessie']
2025-09-12 15:52:14,220 [INFO] app.services.data_processing_service: generate_response_links called with matching_rows: <class 'pandas.core.frame.DataFrame'>
2025-09-12 15:52:14,220 [INFO] app.services.data_processing_service: Generating ranking links
2025-09-12 15:52:14,220 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer de la vessie
2025-09-12 15:52:14,220 [DEBUG] app.services.data_processing_service: Generating links for 2 matching rows
2025-09-12 15:52:14,221 [DEBUG] app.services.data_processing_service: Mapping institution type for URL: Public
2025-09-12 15:52:14,221 [DEBUG] app.services.data_processing_service: Generating web link for specialty 'Cancer de la vessie' and institution_type 'public'
2025-09-12 15:52:14,221 [DEBUG] app.services.data_processing_service: Mapping institution type for URL: Privé
2025-09-12 15:52:14,221 [DEBUG] app.services.data_processing_service: Generating web link for specialty 'Cancer de la vessie' and institution_type 'prive'
2025-09-12 15:52:14,221 [INFO] app.services.data_processing_service: Generated ranking links: ['https://www.lepoint.fr/hopitaux/classements/cancer-de-la-vessie-public.php', 'https://www.lepoint.fr/hopitaux/classements/cancer-de-la-vessie-prive.php']
2025-09-12 15:52:14,221 [INFO] app.services.data_processing_service: load_excel_sheets called with matching_rows of length: 2
2025-09-12 15:52:14,221 [DEBUG] app.services.data_processing_service: Loading sheet: 'CANCER_VESSIE-Public' for category: 'Public'
2025-09-12 15:52:14,380 [DEBUG] app.services.data_processing_service: Sheet 'CANCER_VESSIE-Public' loaded successfully with 40 rows
2025-09-12 15:52:14,380 [DEBUG] app.services.data_processing_service: Loading sheet: 'CANCER_VESSIE-Privé' for category: 'Privé'
2025-09-12 15:52:14,529 [DEBUG] app.services.data_processing_service: Sheet 'CANCER_VESSIE-Privé' loaded successfully with 20 rows
2025-09-12 15:52:14,529 [DEBUG] app.services.data_processing_service: Concatenating 2 dataframes
2025-09-12 15:52:14,530 [INFO] app.services.data_processing_service: Successfully loaded 2 sheets, total rows: 60
2025-09-12 15:52:14,530 [INFO] app.services.data_processing_service: Loaded specialty DataFrame
2025-09-12 15:52:14,530 [INFO] app.services.pipeline_orchestrator_service: Extracting hospital locations and calculating distances
2025-09-12 15:52:14,530 [INFO] app.services.data_processing_service: extract_local_hospitals called with df: <class 'NoneType'>
2025-09-12 15:52:14,530 [INFO] app.services.data_processing_service: Merging ranking data with hospital location data
2025-09-12 15:52:14,533 [DEBUG] app.services.data_processing_service: Merged DataFrame shape (with cities): (60, 6)
2025-09-12 15:52:14,533 [INFO] app.services.data_processing_service: get_df_with_distances called
2025-09-12 15:52:14,533 [INFO] app.services.data_processing_service: Calculating distances from query city: Paris
2025-09-12 15:52:14,570 [DEBUG] urllib3.util.retry: Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-09-12 15:52:14,588 [DEBUG] urllib3.util.retry: Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-09-12 15:52:14,589 [DEBUG] geopy: Nominatim.geocode: https://nominatim.openstreetmap.org/search?q=Paris&format=json&limit=1
2025-09-12 15:52:14,590 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): nominatim.openstreetmap.org:443
2025-09-12 15:52:15,421 [DEBUG] urllib3.connectionpool: https://nominatim.openstreetmap.org:443 "GET /search?q=Paris&format=json&limit=1 HTTP/1.1" 200 445
2025-09-12 15:52:15,422 [DEBUG] app.services.data_processing_service: Query city coordinates: (48.8588897, 2.320041)
2025-09-12 15:52:15,468 [DEBUG] app.services.data_processing_service: DataFrame with distances shape after filtering: (60, 7)
2025-09-12 15:52:15,469 [DEBUG] app.services.data_processing_service: Distance column values after filtering: [398.70213057522426, 664.1329805968085, 415.6976821108837, 456.3753545488687, 628.5636395855853, 371.53864948697446, 188.04439273291007, 347.38835700895703, 204.84959346013898, 345.4649244848459, 595.5008902204977, 411.1022519634651, 498.30864007464044, 307.11690064797057, 587.9427444030024, 199.5223595902802, 284.075379397104, 112.69616845777115, 263.2951918331629, 579.7853407617778, 15.448518739010675, 587.9427444030024, 439.88315580403156, 400.657053919146, 498.30864007464044, 548.2992970130894, 263.2951918331629, 686.5090545808996, 439.43590560192064, 381.05038822552, 411.1022519634651, 483.6329891583387, 2.1651925416878903, 5.820139852698343, 7.058718567800975, 13.344491221595566, 366.59097743231456, 2.1651925416878903, 284.5159766579497, 287.7829290194155, 2.1651925416878903, 2.1651925416878903, 661.6477361717699, 2.1651925416878903, 2.1651925416878903, 661.6477361717699, 204.84959346013898, 639.5091707240583, 376.32784187895174, 382.45487086736125, 661.6477361717699, 2.1651925416878903, 498.30864007464044, 688.455077598661, 614.0681822359634, 504.2656113212524, 345.4649244848459, 652.2830983962782, 590.2248196222363, 579.7853407617778]
2025-09-12 15:52:15,469 [DEBUG] app.services.pipeline_orchestrator_service: build_ranking_dataframe_with_distances returned DataFrame: <class 'pandas.core.frame.DataFrame'>
2025-09-12 15:52:15,469 [DEBUG] app.services.pipeline_orchestrator_service: Checking if DataFrame is None
2025-09-12 15:52:15,469 [DEBUG] app.services.pipeline_orchestrator_service: Retrieved DataFrame shape: (60, 7)
2025-09-12 15:52:15,469 [DEBUG] app.services.pipeline_orchestrator_service: Checking for geolocation API errors
2025-09-12 15:52:15,469 [DEBUG] app.services.pipeline_orchestrator_service: Getting ranking link for UI
2025-09-12 15:52:15,469 [DEBUG] app.services.pipeline_orchestrator_service: Checking for specialty_ranking_unavailable
2025-09-12 15:52:15,469 [DEBUG] app.services.pipeline_orchestrator_service: Checking if institution is mentioned
2025-09-12 15:52:15,469 [DEBUG] app.services.pipeline_orchestrator_service: Checking if city is detected
2025-09-12 15:52:15,469 [DEBUG] app.services.pipeline_orchestrator_service: [DF COLUMNS] DataFrame columns before city/distance selection: ['Etablissement', 'Ville', 'Latitude', 'Longitude', 'Catégorie', 'Note / 20', 'Distance']
2025-09-12 15:52:15,470 [DEBUG] app.services.pipeline_orchestrator_service: Unique cities in DataFrame before select_hospitals: ['Pierre-Bénite' 'Bayonne' 'Brive-la-Gaillarde' 'Chambéry' 'Dax'
 'La Roche-sur-Yon' 'Valenciennes' 'Clermont-Ferrand' 'Lille' 'Limoges'
 'Montpellier' 'Saint-Etienne' 'Bordeaux' 'Rennes' 'Toulouse' 'Caen'
 'Vandœuvre-lès-Nancy' 'Salouel' 'Angers' 'Nîmes' 'Ermont' 'Royan'
 'Strasbourg' 'Albi' 'Mougins' 'Lorient' 'Saint-Nazaire' 'Grenoble'
 'Paris' 'Le Kremlin-Bicêtre' 'Suresnes' 'Créteil' 'Trévenans' 'Nancy'
 'Vantoux' 'Marseille' 'Aix-en-Provence' 'Plérin' 'Colmar' 'Cabestany'
 'Boujan-sur-Libron' 'Brest' 'Pau' 'Reims']
2025-09-12 15:52:15,470 [INFO] app.services.pipeline_orchestrator_service: City detected, preparing to call select_hospitals.
2025-09-12 15:52:15,470 [DEBUG] app.services.pipeline_orchestrator_service: About to call select_hospitals with df columns: ['Etablissement', 'Ville', 'Latitude', 'Longitude', 'Catégorie', 'Note / 20', 'Distance'], city: Paris, number_institutions: 3
2025-09-12 15:52:15,470 [INFO] app.services.data_processing_service: Selecting hospitals for city: Paris with number_institutions: 3
2025-09-12 15:52:15,470 [INFO] app.services.data_processing_service: Found 7 hospitals in city 'Paris', meeting the requirement of 3.
2025-09-12 15:52:15,474 [DEBUG] app.services.pipeline_orchestrator_service: Formatting response with specialty: base_message='Voici les meilleurs établissements (rayon utilisé : 0 km)', count=3, radius_km=0, city=Paris
2025-09-12 15:52:15,474 [DEBUG] app.services.pipeline_orchestrator_service: Normalizing specialty for display: cancer de la vessie
2025-09-12 15:52:15,474 [INFO] app.services.pipeline_orchestrator_service: Creating response and logging for prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 15:52:15,474 [DEBUG] app.services.pipeline_orchestrator_service: Sanity check results for costs/tokens aggregation: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 15:52:15,474 [DEBUG] app.services.pipeline_orchestrator_service: Query analyst results for costs/tokens aggregation: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.86e-05, 'city_token_usage': 318, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017295, 'institution_names_token_usage': 1108, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.27e-05, 'institution_type_token_usage': 215, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.825e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.71e-05, 'number_institutions_token_usage': 311, 'total_cost': 0.0003996, 'total_token_usage': 1952}
2025-09-12 15:52:15,474 [DEBUG] app.services.pipeline_orchestrator_service: Conversation analyst results for costs/tokens aggregation: None
2025-09-12 15:52:15,474 [INFO] app.services.pipeline_orchestrator_service: Aggregated costs and token usage: {'total_cost_sanity_checks_analyst': 0.00028949999999999994, 'total_cost_query_analyst': 0.0007992, 'total_cost_conversation_analyst': 0.0, 'total_cost': 0.0010887, 'total_token_usage_sanity_checks_analyst': 1924, 'total_token_usage_query_analyst': 0, 'total_token_usage_conversation_analyst': 0, 'total_token_usage': 1924}
2025-09-12 15:52:15,475 [INFO] app.services.pipeline_orchestrator_service: Final cost/token usage aggregation: {'total_cost_sanity_checks_analyst': 0.00028949999999999994, 'total_cost_query_analyst': 0.0007992, 'total_cost_conversation_analyst': 0.0, 'total_cost': 0.0010887, 'total_token_usage_sanity_checks_analyst': 1924, 'total_token_usage_query_analyst': 0, 'total_token_usage_conversation_analyst': 0, 'total_token_usage': 1924}
2025-09-12 15:52:15,475 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 15:52:15,475 [INFO] app.services.data_processing_service: Saving Q&A to CSV: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 15:52:15,475 [DEBUG] app.services.data_processing_service: CSV written to /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/history/results_history_mvp.csv
2025-09-12 15:52:15,476 [DEBUG] app.services.pipeline_orchestrator_service: Formatted response: Voici les meilleurs établissements (rayon utilisé : 0 km)
<br>Aucun établissement privé trouvé.<br>Voici les établissements publics :<br>Institut mutualiste Montsouris, Paris (75): Un établissement Public situé à 2 km. avec une note de 18.63 de 20<br>Hôpital Saint-Louis, Paris (75): Un établissement Public situé à 2 km. avec une note de 18.27 de 20<br>Hôpital européen Georges-Pompidou, Paris (75): Un établissement Public situé à 2 km. avec une note de 18.26 de 20

🔗 Consultez la méthodologie de palmarès hopitaux <a href="https://www.lepoint.fr/sante/la-methodologie-du-palmares-des-hopitaux-et-cliniques-du-point-2024--04-12-2024-2577146_40.php" target="_blank">ici</a>.
2025-09-12 15:52:59,275 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:52:59,276 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:52:59,276 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:52:59,276 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:52:59,278 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:52:59,278 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:52:59,278 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:52:59,384 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:52:59,384 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:52:59,384 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:52:59,388 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:52:59,388 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:52:59,580 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:52:59,580 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:52:59,581 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:52:59,582 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:52:59,582 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:52:59,582 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:52:59,659 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:52:59,659 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:52:59,659 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:52:59,661 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:52:59,661 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:52:59,661 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:52:59,661 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:52:59,661 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:52:59,662 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:52:59,662 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:52:59,662 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:52:59,663 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:52:59,663 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:52:59,663 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:52:59,735 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:52:59,735 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:52:59,735 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:52:59,737 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:52:59,737 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:52:59,766 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:52:59,768 [INFO] main: Creating FastAPI app
2025-09-12 15:52:59,769 [INFO] main: CORS middleware added
2025-09-12 15:52:59,770 [INFO] main: API router included
2025-09-12 15:53:00,795 [INFO] app.services.pipeline_orchestrator_service: Starting pipeline processing - prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?
2025-09-12 15:53:00,795 [INFO] app.services.pipeline_orchestrator_service: Resetting PipelineOrchestrator attributes for new query
2025-09-12 15:53:00,795 [INFO] app.services.pipeline_orchestrator_service: Running sanity checks for prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?, conversation: [], conv_history: 
2025-09-12 15:53:00,795 [DEBUG] app.features.sanity_checks.sanity_checks_analyst: run_checks called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?, conversation=[], conv_history=, checks_to_run=['conversation_limit', 'message_length', 'message_pertinence']
2025-09-12 15:53:00,796 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst running checks: ['conversation_limit', 'message_length', 'message_pertinence'] for user_input: Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?
2025-09-12 15:53:00,796 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check medical pertinence prompt sent to LLM.
2025-09-12 15:53:00,800 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nÉvaluez si le message suivant a un rapport avec la santé humaine ou les services de soins.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur la santé.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes de discussions médicales.\nATTENTION: Toute question sur la méthodologie, la fréquence de mise à jour, les critères, ou le fonctionnement du classement des hôpitaux doit TOUJOURS être considérée comme pertinente, même si elle ne concerne pas directement une maladie ou un service de soins.\n\nRépondez UNIQUEMENT avec 1 si pertinent, 0 si non pertinent ou 2 si la question concerne la méthodologie de calcul du classement.\n\nExemples pour messages standalone (repondre 1): \n- \'J\'ai un cancer à Paris\' → 1\n- \'Cataracte\' → 1  \n- \'J\'ai mal aux pieds\' → 1\n- \'Les hôpitaux privés sont ils meilleurs que les publiques?\' → 1\n- \'Comment le classement est-il calculé ?\' → 1\n- \'Quels sont les critères du classement ?\' → 1\n- "Quels experts participent à l\'élaboration du classement ?"\' → 1\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\' → 1\n- "Comment sont traitées les données manquantes dans le classement ?"\' → 1\n- "Le classement est-il le même pour toutes les spécialités ?"\' → 1\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\' → 1\n- "Quels sont les changements dans la méthodologie cette année ?"\' → 1\n- "Comment puis-je accéder au détail de la méthodologie ?"\' → 1\n\nExemples pour messages standalone (repondre 0):\n- \'Je mange des frites\' → 0\n- \'Comment faire une tarte aux pommes ?\' → 0\n- \'Comment s\'abonner Le Point ?\' → 0\n- \'Quel est le meilleur restaurant à Paris ?\' → 0\n\n\nExemples de questions qui concernent la méthodologie de classement (repondre 2):\n- "Comment le classement est-il calculé ?"\n- "Quels sont les critères du classement ?" \n- "Pourquoi l\'hôpital X est mieux classé que Y ?"\n- "Comment sont choisis les critères du classement ?"\n- "Qui réalise le classement des hôpitaux ?"\n- "Quelle est la source des données utilisées pour le classement ?"\n- "Le classement prend-il en compte la satisfaction des patients ?"\n- "Comment sont pondérés les différents critères ?"\n- "Est-ce que le classement est mis à jour chaque année ?"\n- "Pourquoi certains hôpitaux ne figurent pas dans le classement ?"\n- "Comment puis-je vérifier la fiabilité du classement ?"\n- "Quels experts participent à l\'élaboration du classement ?"\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\n- "Comment sont traitées les données manquantes dans le classement ?"\n- "Le classement est-il le même pour toutes les spécialités ?"\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\n- "Quels sont les changements dans la méthodologie cette année ?"\n- "Comment puis-je accéder au détail de la méthodologie ?"\n\nExemples pour messages avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique montrant une discussion sur les hôpitaux, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur la cardiologie, \'Merci\' → 1 (remerciement dans contexte médical)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n- Même avec contexte médical, \'Parle-moi de football\' → 0 (hors-sujet)\n- Avec historique sur les classements, "Comment sont déterminés les scores ?" → 2 (question sur la méthodologie de classement)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:00,829 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:00,830 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-09-12 15:53:00,868 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11343ba10>
2025-09-12 15:53:00,868 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x1131efda0> server_hostname='api.openai.com' timeout=None
2025-09-12 15:53:00,889 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11346df90>
2025-09-12 15:53:00,889 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:00,889 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:00,889 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:00,889 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:00,890 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:01,904 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'820'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'844'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9988'), (b'x-ratelimit-remaining-tokens', b'198879'), (b'x-ratelimit-reset-requests', b'1m37.644s'), (b'x-ratelimit-reset-tokens', b'336ms'), (b'x-request-id', b'req_6eed826bc6a1498a87d3e8fd9f783878'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=vSz9fxgzDiT5rOxzyYe5LBui45qGXZ4HRViguuTbrME-1757685182-1.0.1.1-omMtbfEghBqHD8SUiYNbAphPDXbCapeJAz1KJY3vUs5IGR3JvY2WR8W0gCmolBY4MI0_SOrmSuu1fPX6PdeY3hX4ssSCVbwldXrpC8707nE; path=/; expires=Fri, 12-Sep-25 14:23:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=T7W3pZO23sBeAKLOOUpA1GLSpEAWmKZr.8vUhTqAtwY-1757685182060-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe37daeb748ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:01,906 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:01,906 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:01,906 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:01,906 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:01,906 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:01,906 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 12 Sep 2025 13:53:02 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'le-point-hv3izr'), ('openai-processing-ms', '820'), ('openai-project', 'proj_auvPnKXq8lce0dksWKRj2pvx'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '844'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9988'), ('x-ratelimit-remaining-tokens', '198879'), ('x-ratelimit-reset-requests', '1m37.644s'), ('x-ratelimit-reset-tokens', '336ms'), ('x-request-id', 'req_6eed826bc6a1498a87d3e8fd9f783878'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=vSz9fxgzDiT5rOxzyYe5LBui45qGXZ4HRViguuTbrME-1757685182-1.0.1.1-omMtbfEghBqHD8SUiYNbAphPDXbCapeJAz1KJY3vUs5IGR3JvY2WR8W0gCmolBY4MI0_SOrmSuu1fPX6PdeY3hX4ssSCVbwldXrpC8707nE; path=/; expires=Fri, 12-Sep-25 14:23:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=T7W3pZO23sBeAKLOOUpA1GLSpEAWmKZr.8vUhTqAtwY-1757685182060-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '97dfe37daeb748ba-MRS'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-12 15:53:01,907 [DEBUG] openai._base_client: request_id: req_6eed826bc6a1498a87d3e8fd9f783878
2025-09-12 15:53:01,914 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_medical_pertinence' successful: {'prompt_tokens': 1111, 'completion_tokens': 1, 'total_tokens': 1112}, cost=0.00016724999999999997
2025-09-12 15:53:01,914 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for medical pertinence:
1
2025-09-12 15:53:01,914 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed medical pertinence value: 1 (type: <class 'int'>)
2025-09-12 15:53:01,914 [DEBUG] app.features.sanity_checks.message_pertinence_check: medical_pertinence_result: {'result': 1, 'cost': 0.00016724999999999997, 'token_usage': 1112}
2025-09-12 15:53:01,914 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check chatbot pertinence prompt sent to LLM.
2025-09-12 15:53:01,918 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nVérifiez si cette question concerne le classement des hôpitaux.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur les classements d\'hôpitaux.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes.\n\nRépondez UNIQUEMENT avec:\n- 1 si la question est pertinente pour le chatbot (classement, recherche d\'établissement, etc.)\n- 0 si la question n\'est pas pertinente\n\nUne question est pertinente si elle concerne au moins un des cas suivants:\n- Une maladie, un symptôme ou une spécialité médicale  \n- Le classement des hôpitaux et cliniques  \n- La recherche d\'un hôpital, d\'une clinique ou d\'un service médical  \n- Une question de suivi sur les secteurs public/privé des hôpitaux\n\nExemples de questions pertinentes pour messages standalone (repondre 1):  \n- Quel est la meilleur clinique de France ?\n- Conseille moi un hôpital à Lyon \n- Je chercher un service de pneumologie\n- Où faire soigner mon glaucome ? \n- Je veux corriger mon audition\n- Il y a fréquemment du sang dans mes urines. Conseille-moi un hôpital. \n- Je veux cherche à faire soigner mes troubles bipôlaires\n- Est-ce que l\'Institut mutualiste Montsouris est bon ?\n- Y a-t-il des hôpitaux privés avec un service de cardiologie interventionnelle ?\n\nExemples de questions non pertinentes pour messages standalone (repondre 0):  \n- Pourquoi les hôpitaux sont-ils en crise ?  #Il s\'agit d\'une demande d\'information qui n\'est pas dans le cadre direct de la recherche d\'un établissement de soin\n- Dois-je prendre du paracétamol pour ma fièvre ? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n- Puis-je perdre la vue si j\'ai un glaucome? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n\n\n\nExemples avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique sur les hôpitaux parisiens, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur les classements, \'Combien coûte une consultation ?\' → 0 (question sur les coûts, pas sur les classements)\n- Avec historique sur la recherche d\'hôpital, \'Merci beaucoup\' → 1 (remerciement dans contexte de recherche d\'hôpital)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:01,919 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:01,920 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:01,920 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:01,920 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:01,920 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:01,920 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:02,378 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'268'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'281'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9987'), (b'x-ratelimit-remaining-tokens', b'199170'), (b'x-ratelimit-reset-requests', b'1m45.24s'), (b'x-ratelimit-reset-tokens', b'249ms'), (b'x-request-id', b'req_851959843f5d40cfbd1e88cca056d033'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe3841d8a48ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:02,378 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:02,378 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:02,379 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:02,379 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:02,379 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:02,379 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:02 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '268', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '281', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9987', 'x-ratelimit-remaining-tokens': '199170', 'x-ratelimit-reset-requests': '1m45.24s', 'x-ratelimit-reset-tokens': '249ms', 'x-request-id': 'req_851959843f5d40cfbd1e88cca056d033', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe3841d8a48ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:02,379 [DEBUG] openai._base_client: request_id: req_851959843f5d40cfbd1e88cca056d033
2025-09-12 15:53:02,380 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_chatbot_pertinence' successful: {'prompt_tokens': 809, 'completion_tokens': 1, 'total_tokens': 810}, cost=0.00012195
2025-09-12 15:53:02,380 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for chatbot pertinence:
1
2025-09-12 15:53:02,380 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed chatbot pertinence value: 1 (type: <class 'int'>)
2025-09-12 15:53:02,380 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst completed checks. All passed: True, Total cost: 0.0002892, Total tokens: 1922
2025-09-12 15:53:02,380 [INFO] app.features.sanity_checks.sanity_checks_analyst: Sanity check results: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.0002892, 'token_usage': 1922}, 'passed': True, 'total_cost': 0.0002892, 'total_tokens': 1922}
2025-09-12 15:53:02,380 [INFO] app.services.pipeline_orchestrator_service: Sanity checks result: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.0002892, 'token_usage': 1922}, 'passed': True, 'total_cost': 0.0002892, 'total_tokens': 1922}
2025-09-12 15:53:02,381 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?', detected_specialty='None', conv_history=''
2025-09-12 15:53:02,381 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 15:53:02,381 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 15:53:02,381 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 15:53:02,381 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 15:53:02,613 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:53:02,614 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?, conv_history: 
2025-09-12 15:53:02,614 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'
2025-09-12 15:53:02,616 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:02,617 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:02,617 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:02,618 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:02,618 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:02,618 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:02,618 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:03,081 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'296'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'337'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9987'), (b'x-ratelimit-remaining-tokens', b'199554'), (b'x-ratelimit-reset-requests', b'1m44.592s'), (b'x-ratelimit-reset-tokens', b'133ms'), (b'x-request-id', b'req_c1289d6715a449338ff5efd49b6135ab'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe3886f4e48ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:03,081 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:03,081 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:03,082 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:03,082 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:03,082 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:03,082 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '296', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '337', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9987', 'x-ratelimit-remaining-tokens': '199554', 'x-ratelimit-reset-requests': '1m44.592s', 'x-ratelimit-reset-tokens': '133ms', 'x-request-id': 'req_c1289d6715a449338ff5efd49b6135ab', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe3886f4e48ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:03,082 [DEBUG] openai._base_client: request_id: req_c1289d6715a449338ff5efd49b6135ab
2025-09-12 15:53:03,083 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 430, 'completion_tokens': 5, 'total_tokens': 435}, cost=6.75e-05
2025-09-12 15:53:03,083 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer de la vessie, method: llm
2025-09-12 15:53:03,083 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer de la vessie', 'detection_method': 'llm', 'cost': 6.75e-05, 'token_usage': 0}
2025-09-12 15:53:03,084 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?', conv_history: ''
2025-09-12 15:53:03,086 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:03,087 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:03,087 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:03,087 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:03,087 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:03,087 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:03,087 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:03,522 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'257'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'274'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9986'), (b'x-ratelimit-remaining-tokens', b'199782'), (b'x-ratelimit-reset-requests', b'1m52.741s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_68ff545e5b4241e1a178060fcf45a765'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe38b5e0748ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:03,522 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:03,523 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:03,529 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:03,529 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:03,529 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:03,529 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '257', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '274', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9986', 'x-ratelimit-remaining-tokens': '199782', 'x-ratelimit-reset-requests': '1m52.741s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_68ff545e5b4241e1a178060fcf45a765', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe38b5e0748ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:03,530 [DEBUG] openai._base_client: request_id: req_68ff545e5b4241e1a178060fcf45a765
2025-09-12 15:53:03,530 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 198, 'completion_tokens': 1, 'total_tokens': 199}, cost=3.03e-05
2025-09-12 15:53:03,533 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:03,533 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:03,533 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:03,534 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:03,534 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:03,534 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:03,534 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:03,949 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'242'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'262'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9987'), (b'x-ratelimit-remaining-tokens', b'199649'), (b'x-ratelimit-reset-requests', b'1m52.295s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_125be88240674b4a8e1f8fb5ec7000cb'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe38e2c1448ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:03,950 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:03,951 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:03,958 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:03,959 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:03,959 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:03,959 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '242', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '262', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9987', 'x-ratelimit-remaining-tokens': '199649', 'x-ratelimit-reset-requests': '1m52.295s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_125be88240674b4a8e1f8fb5ec7000cb', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe38e2c1448ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:03,959 [DEBUG] openai._base_client: request_id: req_125be88240674b4a8e1f8fb5ec7000cb
2025-09-12 15:53:03,960 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}, cost=4.8e-05
2025-09-12 15:53:03,960 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.83e-05, tokens={'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}
2025-09-12 15:53:03,960 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': 'Paris', 'detection_method': 'llm', 'cost': 7.83e-05, 'status_code': 3, 'token_usage': {'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}}
2025-09-12 15:53:03,960 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?, conv_history=
2025-09-12 15:53:03,963 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:03,964 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:03,964 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:03,964 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:03,964 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:03,965 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:03,965 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:04,329 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'172'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'184'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9986'), (b'x-ratelimit-remaining-tokens', b'199782'), (b'x-ratelimit-reset-requests', b'2m0.476s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_37b83dc57f60479ca7f1b93a60ccfb09'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe390da2a48ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:04,330 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:04,330 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:04,332 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:04,332 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:04,333 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:04,333 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '172', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '184', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9986', 'x-ratelimit-remaining-tokens': '199782', 'x-ratelimit-reset-requests': '2m0.476s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_37b83dc57f60479ca7f1b93a60ccfb09', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe390da2a48ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:04,333 [DEBUG] openai._base_client: request_id: req_37b83dc57f60479ca7f1b93a60ccfb09
2025-09-12 15:53:04,334 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 198, 'completion_tokens': 1, 'total_tokens': 199}, cost=3.03e-05
2025-09-12 15:53:04,336 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:04,337 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:04,337 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:04,337 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:04,338 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:04,338 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:04,338 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:04,668 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'176'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'200'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9984'), (b'x-ratelimit-remaining-tokens', b'199649'), (b'x-ratelimit-reset-requests', b'2m17.435s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_e037a7394223494791eb02a6eaba183e'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe3932f9348ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:04,668 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:04,668 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:04,669 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:04,669 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:04,669 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:04,669 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '176', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '200', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9984', 'x-ratelimit-remaining-tokens': '199649', 'x-ratelimit-reset-requests': '2m17.435s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_e037a7394223494791eb02a6eaba183e', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe3932f9348ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:04,669 [DEBUG] openai._base_client: request_id: req_e037a7394223494791eb02a6eaba183e
2025-09-12 15:53:04,670 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}, cost=4.8e-05
2025-09-12 15:53:04,670 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.83e-05, tokens={'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}
2025-09-12 15:53:04,670 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 3, 'city_detected': True, 'city': 'Paris', 'detection_method': 'llm', 'cost': 7.83e-05, 'token_usage': 317}
2025-09-12 15:53:04,670 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?' with conv_history: ''
2025-09-12 15:53:04,672 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:04,674 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:04,674 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:04,674 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:04,674 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:04,674 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:04,674 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:05,352 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'536'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'549'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9982'), (b'x-ratelimit-remaining-tokens', b'198987'), (b'x-ratelimit-reset-requests', b'2m34.373s'), (b'x-ratelimit-reset-tokens', b'303ms'), (b'x-request-id', b'req_b289076749084e92bb836cc057e9952d'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe3954c6848ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:05,352 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:05,352 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:05,357 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:05,357 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:05,357 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:05,357 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '536', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '549', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9982', 'x-ratelimit-remaining-tokens': '198987', 'x-ratelimit-reset-requests': '2m34.373s', 'x-ratelimit-reset-tokens': '303ms', 'x-request-id': 'req_b289076749084e92bb836cc057e9952d', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe3954c6848ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:05,358 [DEBUG] openai._base_client: request_id: req_b289076749084e92bb836cc057e9952d
2025-09-12 15:53:05,358 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1092, 'completion_tokens': 15, 'total_tokens': 1107}, cost=0.0001728
2025-09-12 15:53:05,358 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 15:53:05,359 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 15:53:05,359 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': [], 'intent': 'none'}
2025-09-12 15:53:05,359 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: [], intent: none, cost: 0.0001728, token_usage: {'prompt_tokens': 1092, 'completion_tokens': 15, 'total_tokens': 1107}
2025-09-12 15:53:05,359 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | []
2025-09-12 15:53:05,359 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=[] and institution_list length=553)
2025-09-12 15:53:05,359 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: []
2025-09-12 15:53:05,359 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: none
2025-09-12 15:53:05,359 [INFO] app.features.query_analysis.institution_names.institution_names_validation: No specific institution detected
2025-09-12 15:53:05,359 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': None, 'institution_name_mentioned': False, 'error': 'No institution detected', 'intent': 'none', 'detection_method': 'llm', 'cost': 0.0001728, 'token_usage': 1107}
2025-09-12 15:53:05,362 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:05,362 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:05,363 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:05,363 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:05,363 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:05,363 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:05,363 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:06,308 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'156'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'812'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9981'), (b'x-ratelimit-remaining-tokens', b'199782'), (b'x-ratelimit-reset-requests', b'2m42.321s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_5cdd653910f6452cb6da6d09d69029a8'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe3999e5048ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:06,309 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:06,309 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:06,310 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:06,310 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:06,310 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:06,310 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '156', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '812', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9981', 'x-ratelimit-remaining-tokens': '199782', 'x-ratelimit-reset-requests': '2m42.321s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_5cdd653910f6452cb6da6d09d69029a8', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe3999e5048ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:06,310 [DEBUG] openai._base_client: request_id: req_5cdd653910f6452cb6da6d09d69029a8
2025-09-12 15:53:06,311 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 213, 'completion_tokens': 1, 'total_tokens': 214}, cost=3.255e-05
2025-09-12 15:53:06,311 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.255e-05, {'prompt_tokens': 213, 'completion_tokens': 1, 'total_tokens': 214}
2025-09-12 15:53:06,311 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.255e-05, 'token_usage': 214}
2025-09-12 15:53:06,314 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:06,315 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:06,315 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:06,316 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:06,316 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:06,316 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:06,316 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:06,814 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'280'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'356'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9980'), (b'x-ratelimit-remaining-tokens', b'199679'), (b'x-ratelimit-reset-requests', b'2m50.004s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_4f7a6e390c7f4fef9bcaf021e0118ca1'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe39f8ce348ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:06,815 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:06,815 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:06,818 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:06,818 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:06,818 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:06,819 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '280', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '356', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9980', 'x-ratelimit-remaining-tokens': '199679', 'x-ratelimit-reset-requests': '2m50.004s', 'x-ratelimit-reset-tokens': '96ms', 'x-request-id': 'req_4f7a6e390c7f4fef9bcaf021e0118ca1', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe39f8ce348ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:06,819 [DEBUG] openai._base_client: request_id: req_4f7a6e390c7f4fef9bcaf021e0118ca1
2025-09-12 15:53:06,820 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 309, 'completion_tokens': 1, 'total_tokens': 310}, cost=4.6949999999999996e-05
2025-09-12 15:53:06,820 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.6949999999999996e-05, {'prompt_tokens': 309, 'completion_tokens': 1, 'total_tokens': 310}
2025-09-12 15:53:06,820 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.6949999999999996e-05, 'token_usage': 310}
2025-09-12 15:53:06,820 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer de la vessie, city=Paris, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 15:53:06,820 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.75e-05, city_cost=7.83e-05, institution_names_cost=0.0001728, institution_type_cost=3.255e-05, number_institutions_cost=4.6949999999999996e-05
2025-09-12 15:53:06,820 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=317, institution_names_tokens=1107, institution_type_tokens=214, number_institutions_tokens=310
2025-09-12 15:53:06,820 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.83e-05, 'city_token_usage': 317, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.0001728, 'institution_names_token_usage': 1107, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.255e-05, 'institution_type_token_usage': 214, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.75e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.6949999999999996e-05, 'number_institutions_token_usage': 310, 'total_cost': 0.0003981, 'total_token_usage': 1948}
2025-09-12 15:53:06,820 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer de la vessie', city='Paris', city_detected=True, institution_type='aucune correspondance', number_institutions=3, institution_names=None, institution_name_mentioned=False
2025-09-12 15:53:06,821 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer de la vessie'
2025-09-12 15:53:06,821 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: 'Paris'
2025-09-12 15:53:06,821 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: True
2025-09-12 15:53:06,821 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 15:53:06,821 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 3
2025-09-12 15:53:06,821 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: []
2025-09-12 15:53:06,821 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 15:53:06,821 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'none'
2025-09-12 15:53:06,821 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: False
2025-09-12 15:53:06,851 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:53:06,851 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 15:53:07,068 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 15:53:07,068 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 15:53:07,068 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer de la vessie'
2025-09-12 15:53:07,068 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: 'Paris'
2025-09-12 15:53:07,068 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: True
2025-09-12 15:53:07,068 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 15:53:07,068 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: []
2025-09-12 15:53:07,069 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: False
2025-09-12 15:53:07,069 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 3
2025-09-12 15:53:07,069 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer de la vessie, city: Paris, institution_type: aucune correspondance, institution: [], institution_name_mentioned: False
2025-09-12 15:53:07,069 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 15:53:07,069 [DEBUG] app.services.pipeline_orchestrator_service: [CITY DETECTION] Detected city: 'Paris', city_detected: True, DataProcessor.city: 'Paris', DataProcessor.city_detected: True
2025-09-12 15:53:07,069 [DEBUG] app.services.pipeline_orchestrator_service: Calling build_ranking_dataframe_with_distances
2025-09-12 15:53:07,069 [INFO] app.services.pipeline_orchestrator_service: Building ranking DataFrame with distances: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?', excel_path='/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx', detected_specialty='cancer de la vessie'
2025-09-12 15:53:07,069 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?', detected_specialty='cancer de la vessie', conv_history='None'
2025-09-12 15:53:07,069 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 15:53:07,069 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 15:53:07,069 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 15:53:07,069 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 15:53:07,260 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:53:07,260 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?, conv_history: 
2025-09-12 15:53:07,260 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'
2025-09-12 15:53:07,263 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:07,263 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:07,264 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:07,264 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:07,264 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:07,264 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:07,264 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:07,906 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'467'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'505'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9979'), (b'x-ratelimit-remaining-tokens', b'199554'), (b'x-ratelimit-reset-requests', b'2m57.695s'), (b'x-ratelimit-reset-tokens', b'133ms'), (b'x-request-id', b'req_5398d41d3df84fac84e2022d25d2f828'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe3a57b1348ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:07,907 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:07,907 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:07,922 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:07,922 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:07,923 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:07,923 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '467', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '505', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9979', 'x-ratelimit-remaining-tokens': '199554', 'x-ratelimit-reset-requests': '2m57.695s', 'x-ratelimit-reset-tokens': '133ms', 'x-request-id': 'req_5398d41d3df84fac84e2022d25d2f828', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe3a57b1348ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:07,923 [DEBUG] openai._base_client: request_id: req_5398d41d3df84fac84e2022d25d2f828
2025-09-12 15:53:07,924 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 430, 'completion_tokens': 5, 'total_tokens': 435}, cost=6.75e-05
2025-09-12 15:53:07,924 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer de la vessie, method: llm
2025-09-12 15:53:07,924 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer de la vessie', 'detection_method': 'llm', 'cost': 6.75e-05, 'token_usage': 0}
2025-09-12 15:53:07,924 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?', conv_history: ''
2025-09-12 15:53:07,926 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:07,927 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:07,927 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:07,928 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:07,928 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:07,928 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:07,928 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:08,383 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'269'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'292'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9979'), (b'x-ratelimit-remaining-tokens', b'199782'), (b'x-ratelimit-reset-requests', b'2m57.911s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_1f7544d55ad14be397445734469e9700'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe3a99d3148ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:08,384 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:08,384 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:08,388 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:08,389 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:08,389 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:08,389 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '269', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '292', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9979', 'x-ratelimit-remaining-tokens': '199782', 'x-ratelimit-reset-requests': '2m57.911s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_1f7544d55ad14be397445734469e9700', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe3a99d3148ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:08,389 [DEBUG] openai._base_client: request_id: req_1f7544d55ad14be397445734469e9700
2025-09-12 15:53:08,390 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 198, 'completion_tokens': 1, 'total_tokens': 199}, cost=3.03e-05
2025-09-12 15:53:08,392 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:08,393 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:08,393 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:08,393 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:08,393 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:08,394 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:08,394 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:08,853 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'252'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'280'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9978'), (b'x-ratelimit-remaining-tokens', b'199649'), (b'x-ratelimit-reset-requests', b'3m6.072s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_8cf506d127694137a6074920d5e4b886'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe3ac8c8e48ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:08,853 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:08,853 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:08,858 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:08,858 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:08,858 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:08,858 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '252', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '280', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9978', 'x-ratelimit-remaining-tokens': '199649', 'x-ratelimit-reset-requests': '3m6.072s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_8cf506d127694137a6074920d5e4b886', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe3ac8c8e48ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:08,858 [DEBUG] openai._base_client: request_id: req_8cf506d127694137a6074920d5e4b886
2025-09-12 15:53:08,859 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}, cost=4.8e-05
2025-09-12 15:53:08,859 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.83e-05, tokens={'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}
2025-09-12 15:53:08,859 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': 'Paris', 'detection_method': 'llm', 'cost': 7.83e-05, 'status_code': 3, 'token_usage': {'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}}
2025-09-12 15:53:08,860 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?, conv_history=
2025-09-12 15:53:08,862 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:08,863 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:08,863 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:08,863 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:08,863 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:08,863 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:08,864 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:09,242 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'226'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'243'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9977'), (b'x-ratelimit-remaining-tokens', b'199782'), (b'x-ratelimit-reset-requests', b'3m13.38s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_b533612c0fd84e90801afb63aed6ecdf'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe3af7b4a48ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:09,243 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:09,243 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:09,254 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:09,254 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:09,254 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:09,254 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '226', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '243', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9977', 'x-ratelimit-remaining-tokens': '199782', 'x-ratelimit-reset-requests': '3m13.38s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_b533612c0fd84e90801afb63aed6ecdf', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe3af7b4a48ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:09,254 [DEBUG] openai._base_client: request_id: req_b533612c0fd84e90801afb63aed6ecdf
2025-09-12 15:53:09,255 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 198, 'completion_tokens': 1, 'total_tokens': 199}, cost=3.03e-05
2025-09-12 15:53:09,257 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:09,258 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:09,258 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:09,259 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:09,259 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:09,259 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:09,259 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:09,736 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'264'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'292'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9976'), (b'x-ratelimit-remaining-tokens', b'199649'), (b'x-ratelimit-reset-requests', b'3m22.477s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_235f39be8fe94509a8552193434d48b1'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe3b1f8d348ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:09,737 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:09,737 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:09,740 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:09,741 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:09,741 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:09,741 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '264', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '292', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9976', 'x-ratelimit-remaining-tokens': '199649', 'x-ratelimit-reset-requests': '3m22.477s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_235f39be8fe94509a8552193434d48b1', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe3b1f8d348ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:09,741 [DEBUG] openai._base_client: request_id: req_235f39be8fe94509a8552193434d48b1
2025-09-12 15:53:09,742 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}, cost=4.8e-05
2025-09-12 15:53:09,742 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.83e-05, tokens={'prompt_tokens': 316, 'completion_tokens': 1, 'total_tokens': 317}
2025-09-12 15:53:09,743 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 3, 'city_detected': True, 'city': 'Paris', 'detection_method': 'llm', 'cost': 7.83e-05, 'token_usage': 317}
2025-09-12 15:53:09,743 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?' with conv_history: ''
2025-09-12 15:53:09,745 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:09,746 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:09,747 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:09,747 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:09,747 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:09,747 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:09,747 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:11,360 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'1241'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1445'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9975'), (b'x-ratelimit-remaining-tokens', b'198987'), (b'x-ratelimit-reset-requests', b'3m30.653s'), (b'x-ratelimit-reset-tokens', b'303ms'), (b'x-request-id', b'req_bce4f41585ae458daf18c07740463325'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe3b4f87248ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:11,361 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:11,361 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:11,362 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:11,362 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:11,362 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:11,362 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:11 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '1241', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1445', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9975', 'x-ratelimit-remaining-tokens': '198987', 'x-ratelimit-reset-requests': '3m30.653s', 'x-ratelimit-reset-tokens': '303ms', 'x-request-id': 'req_bce4f41585ae458daf18c07740463325', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe3b4f87248ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:11,362 [DEBUG] openai._base_client: request_id: req_bce4f41585ae458daf18c07740463325
2025-09-12 15:53:11,363 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1092, 'completion_tokens': 15, 'total_tokens': 1107}, cost=0.0001728
2025-09-12 15:53:11,363 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '```json\n{"institutions": [], "intent": "none"}\n```'
2025-09-12 15:53:11,363 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{"institutions": [], "intent": "none"}'
2025-09-12 15:53:11,363 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': [], 'intent': 'none'}
2025-09-12 15:53:11,363 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: [], intent: none, cost: 0.0001728, token_usage: {'prompt_tokens': 1092, 'completion_tokens': 15, 'total_tokens': 1107}
2025-09-12 15:53:11,363 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | []
2025-09-12 15:53:11,364 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=[] and institution_list length=553)
2025-09-12 15:53:11,364 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: []
2025-09-12 15:53:11,364 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: none
2025-09-12 15:53:11,364 [INFO] app.features.query_analysis.institution_names.institution_names_validation: No specific institution detected
2025-09-12 15:53:11,364 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': None, 'institution_name_mentioned': False, 'error': 'No institution detected', 'intent': 'none', 'detection_method': 'llm', 'cost': 0.0001728, 'token_usage': 1107}
2025-09-12 15:53:11,366 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:11,367 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:11,368 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:11,368 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:11,368 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:11,368 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:11,368 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:11,826 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'251'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'269'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9973'), (b'x-ratelimit-remaining-tokens', b'199782'), (b'x-ratelimit-reset-requests', b'3m45.395s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_2202ef40fc4a4fe386327b981d7ff67f'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe3bf18e248ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:11,826 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:11,827 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:11,827 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:11,827 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:11,827 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:11,827 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:11 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '251', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '269', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9973', 'x-ratelimit-remaining-tokens': '199782', 'x-ratelimit-reset-requests': '3m45.395s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_2202ef40fc4a4fe386327b981d7ff67f', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe3bf18e248ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:11,827 [DEBUG] openai._base_client: request_id: req_2202ef40fc4a4fe386327b981d7ff67f
2025-09-12 15:53:11,828 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 213, 'completion_tokens': 1, 'total_tokens': 214}, cost=3.255e-05
2025-09-12 15:53:11,828 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.255e-05, {'prompt_tokens': 213, 'completion_tokens': 1, 'total_tokens': 214}
2025-09-12 15:53:11,828 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.255e-05, 'token_usage': 214}
2025-09-12 15:53:11,830 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:11,831 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:11,831 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:11,832 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:11,832 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:11,832 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:11,832 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:12,226 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'257'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'269'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9972'), (b'x-ratelimit-remaining-tokens', b'199679'), (b'x-ratelimit-reset-requests', b'3m53.618s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_2ceb78c652464d35ba22f3961998514b'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe3c20fe248ba-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:12,226 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:12,226 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:12,229 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:12,229 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:12,229 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:12,229 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '257', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '269', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9972', 'x-ratelimit-remaining-tokens': '199679', 'x-ratelimit-reset-requests': '3m53.618s', 'x-ratelimit-reset-tokens': '96ms', 'x-request-id': 'req_2ceb78c652464d35ba22f3961998514b', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe3c20fe248ba-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:12,229 [DEBUG] openai._base_client: request_id: req_2ceb78c652464d35ba22f3961998514b
2025-09-12 15:53:12,230 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 309, 'completion_tokens': 1, 'total_tokens': 310}, cost=4.6949999999999996e-05
2025-09-12 15:53:12,230 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.6949999999999996e-05, {'prompt_tokens': 309, 'completion_tokens': 1, 'total_tokens': 310}
2025-09-12 15:53:12,230 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.6949999999999996e-05, 'token_usage': 310}
2025-09-12 15:53:12,230 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer de la vessie, city=Paris, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 15:53:12,230 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.75e-05, city_cost=7.83e-05, institution_names_cost=0.0001728, institution_type_cost=3.255e-05, number_institutions_cost=4.6949999999999996e-05
2025-09-12 15:53:12,230 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=317, institution_names_tokens=1107, institution_type_tokens=214, number_institutions_tokens=310
2025-09-12 15:53:12,231 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.83e-05, 'city_token_usage': 317, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.0001728, 'institution_names_token_usage': 1107, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.255e-05, 'institution_type_token_usage': 214, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.75e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.6949999999999996e-05, 'number_institutions_token_usage': 310, 'total_cost': 0.0003981, 'total_token_usage': 1948}
2025-09-12 15:53:12,231 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer de la vessie', city='Paris', city_detected=True, institution_type='aucune correspondance', number_institutions=3, institution_names=None, institution_name_mentioned=False
2025-09-12 15:53:12,231 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer de la vessie'
2025-09-12 15:53:12,231 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: 'Paris'
2025-09-12 15:53:12,231 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: True
2025-09-12 15:53:12,231 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 15:53:12,231 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 3
2025-09-12 15:53:12,231 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: []
2025-09-12 15:53:12,231 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 15:53:12,232 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'none'
2025-09-12 15:53:12,232 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: False
2025-09-12 15:53:12,261 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:53:12,261 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 15:53:12,407 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 15:53:12,408 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 15:53:12,408 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer de la vessie'
2025-09-12 15:53:12,408 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: 'Paris'
2025-09-12 15:53:12,408 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: True
2025-09-12 15:53:12,408 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 15:53:12,408 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: []
2025-09-12 15:53:12,408 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: False
2025-09-12 15:53:12,408 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 3
2025-09-12 15:53:12,408 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer de la vessie, city: Paris, institution_type: aucune correspondance, institution: [], institution_name_mentioned: False
2025-09-12 15:53:12,408 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 15:53:12,408 [INFO] app.services.data_processing_service: generate_data_response called
2025-09-12 15:53:12,408 [DEBUG] app.services.data_processing_service: Extracted values - specialty: 'cancer de la vessie', institution_type: 'aucune correspondance', city: 'Paris'
2025-09-12 15:53:12,409 [DEBUG] app.services.data_processing_service: No institution type match found, loading by specialty only
2025-09-12 15:53:12,409 [INFO] app.services.data_processing_service: Filtering ranking by criteria: specialty='cancer de la vessie', institution_type='None'
2025-09-12 15:53:12,409 [DEBUG] app.services.data_processing_service: Filtering ranking data - specialty: 'cancer de la vessie', institution_type: 'None'
2025-09-12 15:53:12,409 [DEBUG] app.services.data_processing_service: Specialty type: <class 'str'>, length: 19
2025-09-12 15:53:12,409 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer de la vessie
2025-09-12 15:53:12,410 [DEBUG] app.services.data_processing_service: All normalized specialties in DataFrame: ['ablation des varices' 'accidents vasculaires cerebraux'
 'accouchements a risques' 'accouchements normaux'
 'adenome de la prostate' 'amygdales et vegetations'
 'angioplastie coronaire' 'appendicite' 'arthrose de la main' 'audition'
 'calculs urinaires' "cancer de l'estomac et de l'œsophage"
 "cancer de l'ovaire" "cancer de l'uterus" 'cancer de la prostate'
 'cancer de la thyroide' 'cancer de la vessie'
 "cancer des os de l'enfant et de l'adolescent"
 "cancer du colon ou de l'intestin" 'cancer du foie' 'cancer du pancreas'
 'cancer du poumon' 'cancer du rein' 'cancer du sein' 'cancer orl'
 'cancers de la peau' 'cardiologie interventionnelle' 'cataracte'
 'chirurgie cardiaque adulte' 'chirurgie cardiaque pediatrique'
 "chirurgie de l'epaule" "chirurgie de l'obesite"
 'chirurgie de la cheville' 'chirurgie de la cornee'
 'chirurgie dentaire et orale de l’adulte'
 'chirurgie dentaire et orale de l’enfant et de l’adolescent'
 'chirurgie des arteres' "chirurgie des cancers osseux de l'adulte"
 'chirurgie des carotides' 'chirurgie des sarcomes des tissus mous'
 "chirurgie des testicules de l'adulte"
 "chirurgie des testicules de l'enfant et de l'adolescent"
 'chirurgie du canal carpien' "chirurgie du dos de l'adulte"
 "chirurgie du dos de l'enfant et de l'adolescent"
 'chirurgie du nez et des sinus' 'chirurgie du pied' 'chirurgie du rectum'
 'chirurgie maxillo-faciale' 'depression' "diabete de l'adulte"
 "diabete de l'enfant et de l'adolescent" 'endometriose'
 "epilepsie de l'adulte" "epilepsie de l'enfant et de l'adolescent"
 'fibrome uterin' 'glandes salivaires' 'glaucome' "hernies de l'abdomen"
 'hypertension arterielle' 'infarctus du myocarde'
 'insuffisance cardiaque' "leucemie de l'adulte"
 "leucemie de l'enfant et de l'adolescent" 'ligaments du genou'
 "lymphome-myelome de l'adulte" 'maladie de parkinson'
 "maladies inflammatoires chroniques de l'intestin (mici)"
 'medecine vasculaire' 'pneumologie' 'proctologie' 'prothese de genou'
 'prothese de hanche' 'retine' 'schizophrenie' 'sclerose en plaques'
 'stimulateurs cardiaques' 'strabisme'
 'stress post-traumatique de l’adulte' 'troubles bipolaires'
 "tumeurs du cerveau de l'adulte"
 "tumeurs du cerveau de l'enfant et de l'adolescent" 'urgences de la main'
 'vesicule biliaire']
2025-09-12 15:53:12,410 [DEBUG] app.services.data_processing_service: Normalized specialty from query: 'cancer de la vessie'
2025-09-12 15:53:12,411 [DEBUG] app.services.data_processing_service: Normalized specialty from query: ''cancer de la vessie''
2025-09-12 15:53:12,412 [DEBUG] app.services.data_processing_service: Found 2 rows matching single specialty 'cancer de la vessie' (normalized: 'cancer de la vessie')
2025-09-12 15:53:12,412 [DEBUG] app.services.data_processing_service: Specialties found after specialty filtering: ['Cancer de la vessie']
2025-09-12 15:53:12,412 [INFO] app.services.data_processing_service: generate_response_links called with matching_rows: <class 'pandas.core.frame.DataFrame'>
2025-09-12 15:53:12,412 [INFO] app.services.data_processing_service: Generating ranking links
2025-09-12 15:53:12,412 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer de la vessie
2025-09-12 15:53:12,412 [DEBUG] app.services.data_processing_service: Generating links for 2 matching rows
2025-09-12 15:53:12,413 [DEBUG] app.services.data_processing_service: Mapping institution type for URL: Public
2025-09-12 15:53:12,413 [DEBUG] app.services.data_processing_service: Generating web link for specialty 'Cancer de la vessie' and institution_type 'public'
2025-09-12 15:53:12,413 [DEBUG] app.services.data_processing_service: Mapping institution type for URL: Privé
2025-09-12 15:53:12,413 [DEBUG] app.services.data_processing_service: Generating web link for specialty 'Cancer de la vessie' and institution_type 'prive'
2025-09-12 15:53:12,413 [INFO] app.services.data_processing_service: Generated ranking links: ['https://www.lepoint.fr/hopitaux/classements/cancer-de-la-vessie-public.php', 'https://www.lepoint.fr/hopitaux/classements/cancer-de-la-vessie-prive.php']
2025-09-12 15:53:12,413 [INFO] app.services.data_processing_service: load_excel_sheets called with matching_rows of length: 2
2025-09-12 15:53:12,414 [DEBUG] app.services.data_processing_service: Loading sheet: 'CANCER_VESSIE-Public' for category: 'Public'
2025-09-12 15:53:12,560 [DEBUG] app.services.data_processing_service: Sheet 'CANCER_VESSIE-Public' loaded successfully with 40 rows
2025-09-12 15:53:12,561 [DEBUG] app.services.data_processing_service: Loading sheet: 'CANCER_VESSIE-Privé' for category: 'Privé'
2025-09-12 15:53:12,705 [DEBUG] app.services.data_processing_service: Sheet 'CANCER_VESSIE-Privé' loaded successfully with 20 rows
2025-09-12 15:53:12,705 [DEBUG] app.services.data_processing_service: Concatenating 2 dataframes
2025-09-12 15:53:12,706 [INFO] app.services.data_processing_service: Successfully loaded 2 sheets, total rows: 60
2025-09-12 15:53:12,706 [INFO] app.services.data_processing_service: Loaded specialty DataFrame
2025-09-12 15:53:12,706 [INFO] app.services.pipeline_orchestrator_service: Extracting hospital locations and calculating distances
2025-09-12 15:53:12,706 [INFO] app.services.data_processing_service: extract_local_hospitals called with df: <class 'NoneType'>
2025-09-12 15:53:12,706 [INFO] app.services.data_processing_service: Merging ranking data with hospital location data
2025-09-12 15:53:12,709 [DEBUG] app.services.data_processing_service: Merged DataFrame shape (with cities): (60, 6)
2025-09-12 15:53:12,709 [INFO] app.services.data_processing_service: get_df_with_distances called
2025-09-12 15:53:12,709 [INFO] app.services.data_processing_service: Calculating distances from query city: Paris
2025-09-12 15:53:12,745 [DEBUG] urllib3.util.retry: Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-09-12 15:53:12,745 [DEBUG] urllib3.util.retry: Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-09-12 15:53:12,745 [DEBUG] geopy: Nominatim.geocode: https://nominatim.openstreetmap.org/search?q=Paris&format=json&limit=1
2025-09-12 15:53:12,746 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): nominatim.openstreetmap.org:443
2025-09-12 15:53:13,311 [DEBUG] urllib3.connectionpool: https://nominatim.openstreetmap.org:443 "GET /search?q=Paris&format=json&limit=1 HTTP/1.1" 200 445
2025-09-12 15:53:13,314 [DEBUG] app.services.data_processing_service: Query city coordinates: (48.8588897, 2.320041)
2025-09-12 15:53:13,357 [DEBUG] app.services.data_processing_service: DataFrame with distances shape after filtering: (60, 7)
2025-09-12 15:53:13,357 [DEBUG] app.services.data_processing_service: Distance column values after filtering: [398.70213057522426, 664.1329805968085, 415.6976821108837, 456.3753545488687, 628.5636395855853, 371.53864948697446, 188.04439273291007, 347.38835700895703, 204.84959346013898, 345.4649244848459, 595.5008902204977, 411.1022519634651, 498.30864007464044, 307.11690064797057, 587.9427444030024, 199.5223595902802, 284.075379397104, 112.69616845777115, 263.2951918331629, 579.7853407617778, 15.448518739010675, 587.9427444030024, 439.88315580403156, 400.657053919146, 498.30864007464044, 548.2992970130894, 263.2951918331629, 686.5090545808996, 439.43590560192064, 381.05038822552, 411.1022519634651, 483.6329891583387, 2.1651925416878903, 5.820139852698343, 7.058718567800975, 13.344491221595566, 366.59097743231456, 2.1651925416878903, 284.5159766579497, 287.7829290194155, 2.1651925416878903, 2.1651925416878903, 661.6477361717699, 2.1651925416878903, 2.1651925416878903, 661.6477361717699, 204.84959346013898, 639.5091707240583, 376.32784187895174, 382.45487086736125, 661.6477361717699, 2.1651925416878903, 498.30864007464044, 688.455077598661, 614.0681822359634, 504.2656113212524, 345.4649244848459, 652.2830983962782, 590.2248196222363, 579.7853407617778]
2025-09-12 15:53:13,357 [DEBUG] app.services.pipeline_orchestrator_service: build_ranking_dataframe_with_distances returned DataFrame: <class 'pandas.core.frame.DataFrame'>
2025-09-12 15:53:13,357 [DEBUG] app.services.pipeline_orchestrator_service: Checking if DataFrame is None
2025-09-12 15:53:13,358 [DEBUG] app.services.pipeline_orchestrator_service: Retrieved DataFrame shape: (60, 7)
2025-09-12 15:53:13,358 [DEBUG] app.services.pipeline_orchestrator_service: Checking for geolocation API errors
2025-09-12 15:53:13,358 [DEBUG] app.services.pipeline_orchestrator_service: Getting ranking link for UI
2025-09-12 15:53:13,358 [DEBUG] app.services.pipeline_orchestrator_service: Checking for specialty_ranking_unavailable
2025-09-12 15:53:13,358 [DEBUG] app.services.pipeline_orchestrator_service: Checking if institution is mentioned
2025-09-12 15:53:13,358 [DEBUG] app.services.pipeline_orchestrator_service: Checking if city is detected
2025-09-12 15:53:13,358 [DEBUG] app.services.pipeline_orchestrator_service: [DF COLUMNS] DataFrame columns before city/distance selection: ['Etablissement', 'Ville', 'Latitude', 'Longitude', 'Catégorie', 'Note / 20', 'Distance']
2025-09-12 15:53:13,358 [DEBUG] app.services.pipeline_orchestrator_service: Unique cities in DataFrame before select_hospitals: ['Pierre-Bénite' 'Bayonne' 'Brive-la-Gaillarde' 'Chambéry' 'Dax'
 'La Roche-sur-Yon' 'Valenciennes' 'Clermont-Ferrand' 'Lille' 'Limoges'
 'Montpellier' 'Saint-Etienne' 'Bordeaux' 'Rennes' 'Toulouse' 'Caen'
 'Vandœuvre-lès-Nancy' 'Salouel' 'Angers' 'Nîmes' 'Ermont' 'Royan'
 'Strasbourg' 'Albi' 'Mougins' 'Lorient' 'Saint-Nazaire' 'Grenoble'
 'Paris' 'Le Kremlin-Bicêtre' 'Suresnes' 'Créteil' 'Trévenans' 'Nancy'
 'Vantoux' 'Marseille' 'Aix-en-Provence' 'Plérin' 'Colmar' 'Cabestany'
 'Boujan-sur-Libron' 'Brest' 'Pau' 'Reims']
2025-09-12 15:53:13,358 [INFO] app.services.pipeline_orchestrator_service: City detected, preparing to call select_hospitals.
2025-09-12 15:53:13,359 [DEBUG] app.services.pipeline_orchestrator_service: About to call select_hospitals with df columns: ['Etablissement', 'Ville', 'Latitude', 'Longitude', 'Catégorie', 'Note / 20', 'Distance'], city: Paris, number_institutions: 3
2025-09-12 15:53:13,359 [INFO] app.services.data_processing_service: Selecting hospitals for city: Paris with number_institutions: 3
2025-09-12 15:53:13,359 [INFO] app.services.data_processing_service: Found 7 hospitals in city 'Paris', meeting the requirement of 3.
2025-09-12 15:53:13,363 [DEBUG] app.services.pipeline_orchestrator_service: Formatting response with specialty: base_message='Voici les meilleurs établissements (rayon utilisé : 0 km)', count=3, radius_km=0, city=Paris
2025-09-12 15:53:13,363 [DEBUG] app.services.pipeline_orchestrator_service: Normalizing specialty for display: cancer de la vessie
2025-09-12 15:53:13,363 [INFO] app.services.pipeline_orchestrator_service: Creating response and logging for prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?
2025-09-12 15:53:13,363 [DEBUG] app.services.pipeline_orchestrator_service: Sanity check results for costs/tokens aggregation: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.0002892, 'token_usage': 1922}, 'passed': True, 'total_cost': 0.0002892, 'total_tokens': 1922}
2025-09-12 15:53:13,363 [DEBUG] app.services.pipeline_orchestrator_service: Query analyst results for costs/tokens aggregation: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.83e-05, 'city_token_usage': 317, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.0001728, 'institution_names_token_usage': 1107, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.255e-05, 'institution_type_token_usage': 214, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.75e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.6949999999999996e-05, 'number_institutions_token_usage': 310, 'total_cost': 0.0003981, 'total_token_usage': 1948}
2025-09-12 15:53:13,364 [DEBUG] app.services.pipeline_orchestrator_service: Conversation analyst results for costs/tokens aggregation: None
2025-09-12 15:53:13,364 [INFO] app.services.pipeline_orchestrator_service: Aggregated costs and token usage: {'total_cost_sanity_checks_analyst': 0.0002892, 'total_cost_query_analyst': 0.0007962, 'total_cost_conversation_analyst': 0.0, 'total_cost': 0.0010853999999999998, 'total_token_usage_sanity_checks_analyst': 1922, 'total_token_usage_query_analyst': 0, 'total_token_usage_conversation_analyst': 0, 'total_token_usage': 1922}
2025-09-12 15:53:13,364 [INFO] app.services.pipeline_orchestrator_service: Final cost/token usage aggregation: {'total_cost_sanity_checks_analyst': 0.0002892, 'total_cost_query_analyst': 0.0007962, 'total_cost_conversation_analyst': 0.0, 'total_cost': 0.0010853999999999998, 'total_token_usage_sanity_checks_analyst': 1922, 'total_token_usage_query_analyst': 0, 'total_token_usage_conversation_analyst': 0, 'total_token_usage': 1922}
2025-09-12 15:53:13,364 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 15:53:13,364 [INFO] app.services.data_processing_service: Saving Q&A to CSV: Quels sont les meilleurs hôpitaux à Paris pour la cancer du vessie ?
2025-09-12 15:53:13,367 [DEBUG] app.services.data_processing_service: CSV written to /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/history/results_history_mvp.csv
2025-09-12 15:53:13,367 [DEBUG] app.services.pipeline_orchestrator_service: Formatted response: Voici les meilleurs établissements (rayon utilisé : 0 km)
<br>Aucun établissement privé trouvé.<br>Voici les établissements publics :<br>Institut mutualiste Montsouris, Paris (75): Un établissement Public situé à 2 km. avec une note de 18.63 de 20<br>Hôpital Saint-Louis, Paris (75): Un établissement Public situé à 2 km. avec une note de 18.27 de 20<br>Hôpital européen Georges-Pompidou, Paris (75): Un établissement Public situé à 2 km. avec une note de 18.26 de 20

🔗 Consultez la méthodologie de palmarès hopitaux <a href="https://www.lepoint.fr/sante/la-methodologie-du-palmares-des-hopitaux-et-cliniques-du-point-2024--04-12-2024-2577146_40.php" target="_blank">ici</a>.
2025-09-12 15:53:35,641 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:53:35,641 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:53:35,641 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:53:35,641 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:53:35,642 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:53:35,642 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:53:35,642 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:53:35,732 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:53:35,732 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:53:35,732 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:53:35,735 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:53:35,735 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:53:35,891 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:53:35,891 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:53:35,891 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:53:35,892 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:53:35,892 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:53:35,892 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:53:35,964 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:53:35,964 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:53:35,964 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:53:35,966 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:53:35,966 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:53:35,966 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:53:35,966 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:53:35,966 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:53:35,966 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:53:35,966 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:53:35,966 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:53:35,967 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:53:35,967 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:53:35,967 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:53:36,039 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:53:36,040 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:53:36,040 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:53:36,041 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:53:36,042 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:53:36,072 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:53:36,074 [INFO] main: Creating FastAPI app
2025-09-12 15:53:36,074 [INFO] main: CORS middleware added
2025-09-12 15:53:36,075 [INFO] main: API router included
2025-09-12 15:53:36,081 [INFO] app.services.pipeline_orchestrator_service: Starting pipeline processing - prompt: Quel est le classement de CH de Vannes pour la cancer au sein ?
2025-09-12 15:53:36,081 [INFO] app.services.pipeline_orchestrator_service: Resetting PipelineOrchestrator attributes for new query
2025-09-12 15:53:36,081 [INFO] app.services.pipeline_orchestrator_service: Running sanity checks for prompt: Quel est le classement de CH de Vannes pour la cancer au sein ?, conversation: [], conv_history: 
2025-09-12 15:53:36,081 [DEBUG] app.features.sanity_checks.sanity_checks_analyst: run_checks called: user_input=Quel est le classement de CH de Vannes pour la cancer au sein ?, conversation=[], conv_history=, checks_to_run=['conversation_limit', 'message_length', 'message_pertinence']
2025-09-12 15:53:36,081 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst running checks: ['conversation_limit', 'message_length', 'message_pertinence'] for user_input: Quel est le classement de CH de Vannes pour la cancer au sein ?
2025-09-12 15:53:36,081 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check medical pertinence prompt sent to LLM.
2025-09-12 15:53:36,085 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nÉvaluez si le message suivant a un rapport avec la santé humaine ou les services de soins.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quel est le classement de CH de Vannes pour la cancer au sein ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur la santé.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes de discussions médicales.\nATTENTION: Toute question sur la méthodologie, la fréquence de mise à jour, les critères, ou le fonctionnement du classement des hôpitaux doit TOUJOURS être considérée comme pertinente, même si elle ne concerne pas directement une maladie ou un service de soins.\n\nRépondez UNIQUEMENT avec 1 si pertinent, 0 si non pertinent ou 2 si la question concerne la méthodologie de calcul du classement.\n\nExemples pour messages standalone (repondre 1): \n- \'J\'ai un cancer à Paris\' → 1\n- \'Cataracte\' → 1  \n- \'J\'ai mal aux pieds\' → 1\n- \'Les hôpitaux privés sont ils meilleurs que les publiques?\' → 1\n- \'Comment le classement est-il calculé ?\' → 1\n- \'Quels sont les critères du classement ?\' → 1\n- "Quels experts participent à l\'élaboration du classement ?"\' → 1\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\' → 1\n- "Comment sont traitées les données manquantes dans le classement ?"\' → 1\n- "Le classement est-il le même pour toutes les spécialités ?"\' → 1\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\' → 1\n- "Quels sont les changements dans la méthodologie cette année ?"\' → 1\n- "Comment puis-je accéder au détail de la méthodologie ?"\' → 1\n\nExemples pour messages standalone (repondre 0):\n- \'Je mange des frites\' → 0\n- \'Comment faire une tarte aux pommes ?\' → 0\n- \'Comment s\'abonner Le Point ?\' → 0\n- \'Quel est le meilleur restaurant à Paris ?\' → 0\n\n\nExemples de questions qui concernent la méthodologie de classement (repondre 2):\n- "Comment le classement est-il calculé ?"\n- "Quels sont les critères du classement ?" \n- "Pourquoi l\'hôpital X est mieux classé que Y ?"\n- "Comment sont choisis les critères du classement ?"\n- "Qui réalise le classement des hôpitaux ?"\n- "Quelle est la source des données utilisées pour le classement ?"\n- "Le classement prend-il en compte la satisfaction des patients ?"\n- "Comment sont pondérés les différents critères ?"\n- "Est-ce que le classement est mis à jour chaque année ?"\n- "Pourquoi certains hôpitaux ne figurent pas dans le classement ?"\n- "Comment puis-je vérifier la fiabilité du classement ?"\n- "Quels experts participent à l\'élaboration du classement ?"\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\n- "Comment sont traitées les données manquantes dans le classement ?"\n- "Le classement est-il le même pour toutes les spécialités ?"\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\n- "Quels sont les changements dans la méthodologie cette année ?"\n- "Comment puis-je accéder au détail de la méthodologie ?"\n\nExemples pour messages avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique montrant une discussion sur les hôpitaux, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur la cardiologie, \'Merci\' → 1 (remerciement dans contexte médical)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n- Même avec contexte médical, \'Parle-moi de football\' → 0 (hors-sujet)\n- Avec historique sur les classements, "Comment sont déterminés les scores ?" → 2 (question sur la méthodologie de classement)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:36,109 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:36,110 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-09-12 15:53:36,126 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11a343a10>
2025-09-12 15:53:36,126 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x11a0f7da0> server_hostname='api.openai.com' timeout=None
2025-09-12 15:53:36,146 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11a379f90>
2025-09-12 15:53:36,146 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:36,147 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:36,147 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:36,147 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:36,147 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:36,616 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'272'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'296'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9974'), (b'x-ratelimit-remaining-tokens', b'198881'), (b'x-ratelimit-reset-requests', b'3m37.914s'), (b'x-ratelimit-reset-tokens', b'335ms'), (b'x-request-id', b'req_74f55744d9fe477a87196f069bb8d791'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=3RfDAYthUg7tDzbV3lknRvFhrnVOszIfYLa0f2OAvpc-1757685216-1.0.1.1-8UG99sGVT5jxwP5AeBqzAscpRknVhKv2AP4Jm5FQ9NKgEJrcwvlB55mLOhwvdtooXFag.EOkEdGAUQhymie9Hm21T1VlcW_SaHlJaEO.Rnw; path=/; expires=Fri, 12-Sep-25 14:23:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=bZ5G3xJsViBSvDLVeE.jm2dR7ZIGv9Y1sOllbF4DdQg-1757685216776-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe45a0dfc5014-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:36,618 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:36,618 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:36,622 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:36,622 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:36,622 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:36,622 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 12 Sep 2025 13:53:36 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'le-point-hv3izr'), ('openai-processing-ms', '272'), ('openai-project', 'proj_auvPnKXq8lce0dksWKRj2pvx'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '296'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9974'), ('x-ratelimit-remaining-tokens', '198881'), ('x-ratelimit-reset-requests', '3m37.914s'), ('x-ratelimit-reset-tokens', '335ms'), ('x-request-id', 'req_74f55744d9fe477a87196f069bb8d791'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=3RfDAYthUg7tDzbV3lknRvFhrnVOszIfYLa0f2OAvpc-1757685216-1.0.1.1-8UG99sGVT5jxwP5AeBqzAscpRknVhKv2AP4Jm5FQ9NKgEJrcwvlB55mLOhwvdtooXFag.EOkEdGAUQhymie9Hm21T1VlcW_SaHlJaEO.Rnw; path=/; expires=Fri, 12-Sep-25 14:23:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=bZ5G3xJsViBSvDLVeE.jm2dR7ZIGv9Y1sOllbF4DdQg-1757685216776-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '97dfe45a0dfc5014-MRS'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-12 15:53:36,623 [DEBUG] openai._base_client: request_id: req_74f55744d9fe477a87196f069bb8d791
2025-09-12 15:53:36,630 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_medical_pertinence' successful: {'prompt_tokens': 1109, 'completion_tokens': 1, 'total_tokens': 1110}, cost=0.00016695
2025-09-12 15:53:36,630 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for medical pertinence:
1
2025-09-12 15:53:36,630 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed medical pertinence value: 1 (type: <class 'int'>)
2025-09-12 15:53:36,631 [DEBUG] app.features.sanity_checks.message_pertinence_check: medical_pertinence_result: {'result': 1, 'cost': 0.00016695, 'token_usage': 1110}
2025-09-12 15:53:36,631 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check chatbot pertinence prompt sent to LLM.
2025-09-12 15:53:36,634 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nVérifiez si cette question concerne le classement des hôpitaux.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quel est le classement de CH de Vannes pour la cancer au sein ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur les classements d\'hôpitaux.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes.\n\nRépondez UNIQUEMENT avec:\n- 1 si la question est pertinente pour le chatbot (classement, recherche d\'établissement, etc.)\n- 0 si la question n\'est pas pertinente\n\nUne question est pertinente si elle concerne au moins un des cas suivants:\n- Une maladie, un symptôme ou une spécialité médicale  \n- Le classement des hôpitaux et cliniques  \n- La recherche d\'un hôpital, d\'une clinique ou d\'un service médical  \n- Une question de suivi sur les secteurs public/privé des hôpitaux\n\nExemples de questions pertinentes pour messages standalone (repondre 1):  \n- Quel est la meilleur clinique de France ?\n- Conseille moi un hôpital à Lyon \n- Je chercher un service de pneumologie\n- Où faire soigner mon glaucome ? \n- Je veux corriger mon audition\n- Il y a fréquemment du sang dans mes urines. Conseille-moi un hôpital. \n- Je veux cherche à faire soigner mes troubles bipôlaires\n- Est-ce que l\'Institut mutualiste Montsouris est bon ?\n- Y a-t-il des hôpitaux privés avec un service de cardiologie interventionnelle ?\n\nExemples de questions non pertinentes pour messages standalone (repondre 0):  \n- Pourquoi les hôpitaux sont-ils en crise ?  #Il s\'agit d\'une demande d\'information qui n\'est pas dans le cadre direct de la recherche d\'un établissement de soin\n- Dois-je prendre du paracétamol pour ma fièvre ? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n- Puis-je perdre la vue si j\'ai un glaucome? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n\n\n\nExemples avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique sur les hôpitaux parisiens, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur les classements, \'Combien coûte une consultation ?\' → 0 (question sur les coûts, pas sur les classements)\n- Avec historique sur la recherche d\'hôpital, \'Merci beaucoup\' → 1 (remerciement dans contexte de recherche d\'hôpital)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:36,635 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:36,635 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:36,636 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:36,636 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:36,636 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:36,636 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:36,939 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'163'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'178'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9974'), (b'x-ratelimit-remaining-tokens', b'199172'), (b'x-ratelimit-reset-requests', b'3m37.452s'), (b'x-ratelimit-reset-tokens', b'248ms'), (b'x-request-id', b'req_f9ba8a1701d54ec5ac0b9cf21b5fad30'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe45d0ca25014-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:36,940 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:36,940 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:36,941 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:36,941 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:36,941 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:36,941 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '163', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '178', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9974', 'x-ratelimit-remaining-tokens': '199172', 'x-ratelimit-reset-requests': '3m37.452s', 'x-ratelimit-reset-tokens': '248ms', 'x-request-id': 'req_f9ba8a1701d54ec5ac0b9cf21b5fad30', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe45d0ca25014-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:36,941 [DEBUG] openai._base_client: request_id: req_f9ba8a1701d54ec5ac0b9cf21b5fad30
2025-09-12 15:53:36,942 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_chatbot_pertinence' successful: {'prompt_tokens': 807, 'completion_tokens': 1, 'total_tokens': 808}, cost=0.00012164999999999999
2025-09-12 15:53:36,942 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for chatbot pertinence:
1
2025-09-12 15:53:36,942 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed chatbot pertinence value: 1 (type: <class 'int'>)
2025-09-12 15:53:36,942 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst completed checks. All passed: True, Total cost: 0.00028859999999999997, Total tokens: 1918
2025-09-12 15:53:36,943 [INFO] app.features.sanity_checks.sanity_checks_analyst: Sanity check results: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028859999999999997, 'token_usage': 1918}, 'passed': True, 'total_cost': 0.00028859999999999997, 'total_tokens': 1918}
2025-09-12 15:53:36,943 [INFO] app.services.pipeline_orchestrator_service: Sanity checks result: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028859999999999997, 'token_usage': 1918}, 'passed': True, 'total_cost': 0.00028859999999999997, 'total_tokens': 1918}
2025-09-12 15:53:36,943 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quel est le classement de CH de Vannes pour la cancer au sein ?', detected_specialty='None', conv_history=''
2025-09-12 15:53:36,943 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 15:53:36,943 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 15:53:36,943 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 15:53:36,943 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 15:53:37,133 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:53:37,134 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quel est le classement de CH de Vannes pour la cancer au sein ?, conv_history: 
2025-09-12 15:53:37,134 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quel est le classement de CH de Vannes pour la cancer au sein ?'
2025-09-12 15:53:37,136 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quel est le classement de CH de Vannes pour la cancer au sein ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:37,137 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:37,137 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:37,138 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:37,138 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:37,138 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:37,138 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:37,486 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'204'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'218'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9973'), (b'x-ratelimit-remaining-tokens', b'199555'), (b'x-ratelimit-reset-requests', b'3m45.591s'), (b'x-ratelimit-reset-tokens', b'133ms'), (b'x-request-id', b'req_7e25eb14b1b44fa2a95c90845f84079d'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe4603c805014-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:37,486 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:37,487 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:37,489 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:37,489 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:37,489 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:37,489 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '204', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '218', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9973', 'x-ratelimit-remaining-tokens': '199555', 'x-ratelimit-reset-requests': '3m45.591s', 'x-ratelimit-reset-tokens': '133ms', 'x-request-id': 'req_7e25eb14b1b44fa2a95c90845f84079d', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe4603c805014-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:37,490 [DEBUG] openai._base_client: request_id: req_7e25eb14b1b44fa2a95c90845f84079d
2025-09-12 15:53:37,490 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 428, 'completion_tokens': 3, 'total_tokens': 431}, cost=6.6e-05
2025-09-12 15:53:37,490 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer du sein, method: llm
2025-09-12 15:53:37,491 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer du sein', 'detection_method': 'llm', 'cost': 6.6e-05, 'token_usage': 0}
2025-09-12 15:53:37,491 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quel est le classement de CH de Vannes pour la cancer au sein ?', conv_history: ''
2025-09-12 15:53:37,494 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quel est le classement de CH de Vannes pour la cancer au sein ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:37,494 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:37,495 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:37,495 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:37,495 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:37,495 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:37,495 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:38,558 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'913'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'935'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9971'), (b'x-ratelimit-remaining-tokens', b'199447'), (b'x-ratelimit-reset-requests', b'4m2.512s'), (b'x-ratelimit-reset-tokens', b'165ms'), (b'x-request-id', b'req_42ec3b77a79941cbb5a70eb416248b3a'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe46269a25014-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:38,558 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:38,559 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:38,562 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:38,562 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:38,562 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:38,562 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:38 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '913', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '935', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9971', 'x-ratelimit-remaining-tokens': '199447', 'x-ratelimit-reset-requests': '4m2.512s', 'x-ratelimit-reset-tokens': '165ms', 'x-request-id': 'req_42ec3b77a79941cbb5a70eb416248b3a', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe46269a25014-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:38,563 [DEBUG] openai._base_client: request_id: req_42ec3b77a79941cbb5a70eb416248b3a
2025-09-12 15:53:38,563 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 196, 'completion_tokens': 43, 'total_tokens': 239}, cost=5.52e-05
2025-09-12 15:53:38,563 [WARNING] app.features.query_analysis.city.city_detection: Invalid city status: Dans le message à analyser, "Quel est le classement de CH de Vannes pour la cancer au sein ?", la ville de Vannes est explicitement mentionnée. 

Donc, la réponse est : 3., defaulting to CITY_NO_CITY_MENTIONED
2025-09-12 15:53:38,564 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=None, status=0, method=status, cost=5.52e-05, tokens={'prompt_tokens': 196, 'completion_tokens': 43, 'total_tokens': 239}
2025-09-12 15:53:38,564 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': None, 'detection_method': 'status', 'cost': 5.52e-05, 'status_code': 0, 'token_usage': {'prompt_tokens': 196, 'completion_tokens': 43, 'total_tokens': 239}}
2025-09-12 15:53:38,564 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quel est le classement de CH de Vannes pour la cancer au sein ?, conv_history=
2025-09-12 15:53:38,566 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quel est le classement de CH de Vannes pour la cancer au sein ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:38,567 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:38,567 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:38,567 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:38,567 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:38,568 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:38,568 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:40,003 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'1301'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1313'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9971'), (b'x-ratelimit-remaining-tokens', b'199783'), (b'x-ratelimit-reset-requests', b'4m10.082s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_661d6c03d8dd427e9357ac267ec3359d'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe4692ab45014-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:40,004 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:40,004 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:40,007 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:40,007 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:40,007 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:40,008 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '1301', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1313', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9971', 'x-ratelimit-remaining-tokens': '199783', 'x-ratelimit-reset-requests': '4m10.082s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_661d6c03d8dd427e9357ac267ec3359d', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe4692ab45014-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:40,008 [DEBUG] openai._base_client: request_id: req_661d6c03d8dd427e9357ac267ec3359d
2025-09-12 15:53:40,009 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 196, 'completion_tokens': 65, 'total_tokens': 261}, cost=6.84e-05
2025-09-12 15:53:40,009 [WARNING] app.features.query_analysis.city.city_detection: Invalid city status: Dans le message à analyser, "Quel est le classement de CH de Vannes pour la cancer au sein ?", la ville de Vannes est clairement mentionnée. Il n'y a pas de confusion avec d'autres villes, et le contexte ne suggère pas de localisation étrangère. 

Par conséquent, la réponse est :

3, defaulting to CITY_NO_CITY_MENTIONED
2025-09-12 15:53:40,009 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=None, status=0, method=status, cost=6.84e-05, tokens={'prompt_tokens': 196, 'completion_tokens': 65, 'total_tokens': 261}
2025-09-12 15:53:40,009 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 0, 'city_detected': False, 'city': None, 'detection_method': 'status', 'cost': 5.52e-05, 'token_usage': 239}
2025-09-12 15:53:40,010 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quel est le classement de CH de Vannes pour la cancer au sein ?' with conv_history: ''
2025-09-12 15:53:40,012 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quel est le classement de CH de Vannes pour la cancer au sein ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:40,013 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:40,013 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:40,014 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:40,014 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:40,014 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:40,014 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:40,702 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'511'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'524'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9970'), (b'x-ratelimit-remaining-tokens', b'198989'), (b'x-ratelimit-reset-requests', b'4m17.253s'), (b'x-ratelimit-reset-tokens', b'303ms'), (b'x-request-id', b'req_d382f8893e674cb58920568502da0c94'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe47228745014-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:40,702 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:40,703 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:40,703 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:40,703 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:40,703 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:40,704 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '511', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '524', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9970', 'x-ratelimit-remaining-tokens': '198989', 'x-ratelimit-reset-requests': '4m17.253s', 'x-ratelimit-reset-tokens': '303ms', 'x-request-id': 'req_d382f8893e674cb58920568502da0c94', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe47228745014-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:40,704 [DEBUG] openai._base_client: request_id: req_d382f8893e674cb58920568502da0c94
2025-09-12 15:53:40,705 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1090, 'completion_tokens': 20, 'total_tokens': 1110}, cost=0.00017549999999999998
2025-09-12 15:53:40,705 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{\n  "institutions": ["CH de Vannes"],\n  "intent": "single"\n}'
2025-09-12 15:53:40,705 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{\n  "institutions": ["CH de Vannes"],\n  "intent": "single"\n}'
2025-09-12 15:53:40,705 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': ['CH de Vannes'], 'intent': 'single'}
2025-09-12 15:53:40,705 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: ['CH de Vannes'], intent: single, cost: 0.00017549999999999998, token_usage: {'prompt_tokens': 1090, 'completion_tokens': 20, 'total_tokens': 1110}
2025-09-12 15:53:40,705 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | ['CH de Vannes']
2025-09-12 15:53:40,706 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=['CH de Vannes'] and institution_list length=553)
2025-09-12 15:53:40,706 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Processing detected name: 'CH de Vannes'
2025-09-12 15:53:40,742 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validated 'CH de Vannes' -> 'CH, Vannes (56)' with type 'public'
2025-09-12 15:53:40,742 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: [HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)]
2025-09-12 15:53:40,742 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: single
2025-09-12 15:53:40,743 [INFO] app.features.query_analysis.institution_names.institution_names_validation: Specific institutions mentioned: CH, Vannes (56)
2025-09-12 15:53:40,743 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': [HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)], 'institution_name_mentioned': True, 'intent': 'single', 'detection_method': 'llm', 'cost': 0.00017549999999999998, 'token_usage': 1110}
2025-09-12 15:53:40,745 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quel est le classement de CH de Vannes pour la cancer au sein ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:40,746 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:40,746 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:40,747 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:40,747 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:40,747 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:40,747 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:41,312 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'256'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'392'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9969'), (b'x-ratelimit-remaining-tokens', b'199783'), (b'x-ratelimit-reset-requests', b'4m25.035s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_6626c254a3bf4edaadd5a1a32a029e80'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe476cbc85014-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:41,313 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:41,313 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:41,318 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:41,318 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:41,318 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:41,318 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '256', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '392', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9969', 'x-ratelimit-remaining-tokens': '199783', 'x-ratelimit-reset-requests': '4m25.035s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_6626c254a3bf4edaadd5a1a32a029e80', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe476cbc85014-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:41,318 [DEBUG] openai._base_client: request_id: req_6626c254a3bf4edaadd5a1a32a029e80
2025-09-12 15:53:41,319 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 211, 'completion_tokens': 1, 'total_tokens': 212}, cost=3.225e-05
2025-09-12 15:53:41,319 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: public, 3.225e-05, {'prompt_tokens': 211, 'completion_tokens': 1, 'total_tokens': 212}
2025-09-12 15:53:41,319 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'Public', 'detection_method': 'llm', 'cost': 3.225e-05, 'token_usage': 212}
2025-09-12 15:53:41,322 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quel est le classement de CH de Vannes pour la cancer au sein ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:41,322 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:41,323 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:41,323 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:41,323 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:41,323 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:41,323 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:41,969 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'320'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'477'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9968'), (b'x-ratelimit-remaining-tokens', b'199681'), (b'x-ratelimit-reset-requests', b'4m33.082s'), (b'x-ratelimit-reset-tokens', b'95ms'), (b'x-request-id', b'req_cbcde6928b8949178b869533aff57785'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe47a5d1f5014-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:41,969 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:41,969 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:41,974 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:41,974 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:41,974 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:41,974 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '320', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '477', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9968', 'x-ratelimit-remaining-tokens': '199681', 'x-ratelimit-reset-requests': '4m33.082s', 'x-ratelimit-reset-tokens': '95ms', 'x-request-id': 'req_cbcde6928b8949178b869533aff57785', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe47a5d1f5014-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:41,975 [DEBUG] openai._base_client: request_id: req_cbcde6928b8949178b869533aff57785
2025-09-12 15:53:41,976 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 307, 'completion_tokens': 1, 'total_tokens': 308}, cost=4.665e-05
2025-09-12 15:53:41,976 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.665e-05, {'prompt_tokens': 307, 'completion_tokens': 1, 'total_tokens': 308}
2025-09-12 15:53:41,976 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.665e-05, 'token_usage': 308}
2025-09-12 15:53:41,976 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer du sein, city=None, institution_names=None, institution_type=Public, number_institutions=3
2025-09-12 15:53:41,976 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.6e-05, city_cost=5.52e-05, institution_names_cost=0.00017549999999999998, institution_type_cost=3.225e-05, number_institutions_cost=4.665e-05
2025-09-12 15:53:41,976 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=239, institution_names_tokens=1110, institution_type_tokens=212, number_institutions_tokens=308
2025-09-12 15:53:41,976 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': None, 'city_detected': False, 'city_detection_method': 'status', 'city_cost': 5.52e-05, 'city_token_usage': 239, 'institution_name_mentioned': True, 'institution_names': [HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)], 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017549999999999998, 'institution_names_token_usage': 1110, 'institution_names_intent': 'single', 'institution_type': 'Public', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.225e-05, 'institution_type_token_usage': 212, 'specialty': 'cancer du sein', 'specialty_detection_method': 'llm', 'specialty_cost': 6.6e-05, 'specialty_token_usage': 0, 'number_institutions': 1, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.665e-05, 'number_institutions_token_usage': 308, 'total_cost': 0.00037559999999999997, 'total_token_usage': 1869}
2025-09-12 15:53:41,977 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer du sein', city=None, city_detected=False, institution_type='Public', number_institutions=1, institution_names=[HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)], institution_name_mentioned=True
2025-09-12 15:53:41,977 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer du sein'
2025-09-12 15:53:41,977 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: None
2025-09-12 15:53:41,977 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: False
2025-09-12 15:53:41,977 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'Public'
2025-09-12 15:53:41,977 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 1
2025-09-12 15:53:41,977 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: [HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)]
2025-09-12 15:53:41,977 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 15:53:41,977 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'single'
2025-09-12 15:53:41,977 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: True
2025-09-12 15:53:42,008 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:53:42,008 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 15:53:42,222 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 15:53:42,222 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 15:53:42,222 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer du sein'
2025-09-12 15:53:42,222 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: None
2025-09-12 15:53:42,222 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: False
2025-09-12 15:53:42,222 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'Public'
2025-09-12 15:53:42,223 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: [HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)]
2025-09-12 15:53:42,223 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: True
2025-09-12 15:53:42,223 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 1
2025-09-12 15:53:42,223 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer du sein, city: None, institution_type: Public, institution: [HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)], institution_name_mentioned: True
2025-09-12 15:53:42,223 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer du sein, city=None, institution_type=Public, institution_names=[HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)], number_institutions=1
2025-09-12 15:53:42,223 [DEBUG] app.services.pipeline_orchestrator_service: [CITY DETECTION] Detected city: 'None', city_detected: False, DataProcessor.city: 'None', DataProcessor.city_detected: False
2025-09-12 15:53:42,223 [INFO] app.services.pipeline_orchestrator_service: Institution(s) detected with intent=single: [HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)]
2025-09-12 15:53:42,223 [DEBUG] app.services.pipeline_orchestrator_service: Fetching ranking for single institution: CH, Vannes (56)
2025-09-12 15:53:42,223 [INFO] app.services.pipeline_orchestrator_service: Building ranking DataFrame with distances: prompt='Quel est le classement de CH de Vannes pour la cancer au sein ?', excel_path='/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx', detected_specialty='cancer du sein'
2025-09-12 15:53:42,223 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quel est le classement de CH de Vannes pour la cancer au sein ?', detected_specialty='cancer du sein', conv_history='None'
2025-09-12 15:53:42,223 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 15:53:42,223 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 15:53:42,223 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 15:53:42,224 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 15:53:42,410 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:53:42,411 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quel est le classement de CH de Vannes pour la cancer au sein ?, conv_history: 
2025-09-12 15:53:42,411 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quel est le classement de CH de Vannes pour la cancer au sein ?'
2025-09-12 15:53:42,413 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quel est le classement de CH de Vannes pour la cancer au sein ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:42,414 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:42,414 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:42,415 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:42,415 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:42,415 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:42,415 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:42,762 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'197'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'210'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9968'), (b'x-ratelimit-remaining-tokens', b'199555'), (b'x-ratelimit-reset-requests', b'4m32.143s'), (b'x-ratelimit-reset-tokens', b'133ms'), (b'x-request-id', b'req_010a4ec59f704b318a0eb9010ee74527'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe4812cbd5014-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:42,763 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:42,763 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:42,766 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:42,766 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:42,766 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:42,767 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '197', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '210', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9968', 'x-ratelimit-remaining-tokens': '199555', 'x-ratelimit-reset-requests': '4m32.143s', 'x-ratelimit-reset-tokens': '133ms', 'x-request-id': 'req_010a4ec59f704b318a0eb9010ee74527', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe4812cbd5014-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:42,767 [DEBUG] openai._base_client: request_id: req_010a4ec59f704b318a0eb9010ee74527
2025-09-12 15:53:42,768 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 428, 'completion_tokens': 4, 'total_tokens': 432}, cost=6.66e-05
2025-09-12 15:53:42,768 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer du sein., method: llm
2025-09-12 15:53:42,768 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer du sein', 'detection_method': 'llm', 'cost': 6.66e-05, 'token_usage': 0}
2025-09-12 15:53:42,768 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quel est le classement de CH de Vannes pour la cancer au sein ?', conv_history: ''
2025-09-12 15:53:42,771 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quel est le classement de CH de Vannes pour la cancer au sein ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:42,772 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:42,772 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:42,772 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:42,772 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:42,773 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:42,773 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:43,600 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'666'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'680'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9967'), (b'x-ratelimit-remaining-tokens', b'199783'), (b'x-ratelimit-reset-requests', b'4m40.414s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_c997638f6d164e9fa2cfc6ea75070b53'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe4836a4e5014-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:43,601 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:43,601 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:43,604 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:43,604 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:43,604 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:43,604 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '666', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '680', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9967', 'x-ratelimit-remaining-tokens': '199783', 'x-ratelimit-reset-requests': '4m40.414s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_c997638f6d164e9fa2cfc6ea75070b53', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe4836a4e5014-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:43,605 [DEBUG] openai._base_client: request_id: req_c997638f6d164e9fa2cfc6ea75070b53
2025-09-12 15:53:43,605 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 196, 'completion_tokens': 32, 'total_tokens': 228}, cost=4.86e-05
2025-09-12 15:53:43,606 [WARNING] app.features.query_analysis.city.city_detection: Invalid city status: La phrase à analyser mentionne "Vannes", qui est une ville française. Donc, en tenant compte du contexte de la conversation, la réponse est :

3, defaulting to CITY_NO_CITY_MENTIONED
2025-09-12 15:53:43,606 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=None, status=0, method=status, cost=4.86e-05, tokens={'prompt_tokens': 196, 'completion_tokens': 32, 'total_tokens': 228}
2025-09-12 15:53:43,606 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': None, 'detection_method': 'status', 'cost': 4.86e-05, 'status_code': 0, 'token_usage': {'prompt_tokens': 196, 'completion_tokens': 32, 'total_tokens': 228}}
2025-09-12 15:53:43,606 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quel est le classement de CH de Vannes pour la cancer au sein ?, conv_history=
2025-09-12 15:53:43,609 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quel est le classement de CH de Vannes pour la cancer au sein ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:43,609 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:43,610 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:43,610 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:43,610 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:43,610 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:43,610 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:45,232 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'1452'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1467'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9966'), (b'x-ratelimit-remaining-tokens', b'199783'), (b'x-ratelimit-reset-requests', b'4m48.214s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_c422369e3e054994ad5d0ac476784b37'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe488ae625014-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:45,233 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:45,233 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:45,233 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:45,233 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:45,233 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:45,233 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '1452', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1467', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9966', 'x-ratelimit-remaining-tokens': '199783', 'x-ratelimit-reset-requests': '4m48.214s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_c422369e3e054994ad5d0ac476784b37', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe488ae625014-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:45,234 [DEBUG] openai._base_client: request_id: req_c422369e3e054994ad5d0ac476784b37
2025-09-12 15:53:45,234 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 196, 'completion_tokens': 66, 'total_tokens': 262}, cost=6.9e-05
2025-09-12 15:53:45,235 [WARNING] app.features.query_analysis.city.city_detection: Invalid city status: Dans le message à analyser, "Quel est le classement de CH de Vannes pour la cancer au sein ?", la ville "Vannes" est clairement mentionnée. 

En tenant compte du contexte conversationnel, il n'y a pas de confusion et la localisation française est explicite.

La réponse est donc : **3**., defaulting to CITY_NO_CITY_MENTIONED
2025-09-12 15:53:45,235 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=None, status=0, method=status, cost=6.9e-05, tokens={'prompt_tokens': 196, 'completion_tokens': 66, 'total_tokens': 262}
2025-09-12 15:53:45,235 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 0, 'city_detected': False, 'city': None, 'detection_method': 'status', 'cost': 4.86e-05, 'token_usage': 228}
2025-09-12 15:53:45,235 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quel est le classement de CH de Vannes pour la cancer au sein ?' with conv_history: ''
2025-09-12 15:53:45,237 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quel est le classement de CH de Vannes pour la cancer au sein ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:45,238 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:45,238 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:45,238 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:45,239 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:45,239 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:45,239 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:46,029 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'637'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'655'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9964'), (b'x-ratelimit-remaining-tokens', b'198989'), (b'x-ratelimit-reset-requests', b'5m3.881s'), (b'x-ratelimit-reset-tokens', b'303ms'), (b'x-request-id', b'req_6eea8b10a0b140d09f5a0f1dc263653d'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe492dfa85014-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:46,029 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:46,030 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:46,033 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:46,033 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:46,033 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:46,033 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '637', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '655', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9964', 'x-ratelimit-remaining-tokens': '198989', 'x-ratelimit-reset-requests': '5m3.881s', 'x-ratelimit-reset-tokens': '303ms', 'x-request-id': 'req_6eea8b10a0b140d09f5a0f1dc263653d', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe492dfa85014-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:46,033 [DEBUG] openai._base_client: request_id: req_6eea8b10a0b140d09f5a0f1dc263653d
2025-09-12 15:53:46,034 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1090, 'completion_tokens': 20, 'total_tokens': 1110}, cost=0.00017549999999999998
2025-09-12 15:53:46,034 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{\n  "institutions": ["CH de Vannes"],\n  "intent": "single"\n}'
2025-09-12 15:53:46,034 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{\n  "institutions": ["CH de Vannes"],\n  "intent": "single"\n}'
2025-09-12 15:53:46,035 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': ['CH de Vannes'], 'intent': 'single'}
2025-09-12 15:53:46,035 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: ['CH de Vannes'], intent: single, cost: 0.00017549999999999998, token_usage: {'prompt_tokens': 1090, 'completion_tokens': 20, 'total_tokens': 1110}
2025-09-12 15:53:46,035 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | ['CH de Vannes']
2025-09-12 15:53:46,035 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=['CH de Vannes'] and institution_list length=553)
2025-09-12 15:53:46,035 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Processing detected name: 'CH de Vannes'
2025-09-12 15:53:46,071 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validated 'CH de Vannes' -> 'CH, Vannes (56)' with type 'public'
2025-09-12 15:53:46,071 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: [HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)]
2025-09-12 15:53:46,071 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: single
2025-09-12 15:53:46,071 [INFO] app.features.query_analysis.institution_names.institution_names_validation: Specific institutions mentioned: CH, Vannes (56)
2025-09-12 15:53:46,071 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': [HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)], 'institution_name_mentioned': True, 'intent': 'single', 'detection_method': 'llm', 'cost': 0.00017549999999999998, 'token_usage': 1110}
2025-09-12 15:53:46,073 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quel est le classement de CH de Vannes pour la cancer au sein ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:46,074 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:46,074 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:46,074 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:46,075 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:46,075 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:46,075 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:53:46,399 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:53:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'181'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'193'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9963'), (b'x-ratelimit-remaining-tokens', b'199783'), (b'x-ratelimit-reset-requests', b'5m11.69s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_3426363f47364b6cb94111ce0b4088f8'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe4980c635014-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:53:46,399 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:53:46,399 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:53:46,400 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:53:46,400 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:53:46,400 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:53:46,400 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:53:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '181', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '193', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9963', 'x-ratelimit-remaining-tokens': '199783', 'x-ratelimit-reset-requests': '5m11.69s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_3426363f47364b6cb94111ce0b4088f8', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe4980c635014-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:53:46,400 [DEBUG] openai._base_client: request_id: req_3426363f47364b6cb94111ce0b4088f8
2025-09-12 15:53:46,401 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 211, 'completion_tokens': 1, 'total_tokens': 212}, cost=3.225e-05
2025-09-12 15:53:46,401 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.225e-05, {'prompt_tokens': 211, 'completion_tokens': 1, 'total_tokens': 212}
2025-09-12 15:53:46,401 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.225e-05, 'token_usage': 212}
2025-09-12 15:53:46,403 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quel est le classement de CH de Vannes pour la cancer au sein ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:53:46,404 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:53:46,404 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:53:46,405 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:53:46,405 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:53:46,405 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:53:46,405 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:54:17,992 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:54:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'227'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'31434'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9964'), (b'x-ratelimit-remaining-tokens', b'199681'), (b'x-ratelimit-reset-requests', b'5m2.72s'), (b'x-ratelimit-reset-tokens', b'95ms'), (b'x-request-id', b'req_ae7f8fa3dea64ea99b1d2c9941ac3113'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe49a19a85014-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:54:17,994 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:54:17,994 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:54:17,995 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:54:17,995 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:54:17,995 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:54:17,995 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:54:18 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '227', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '31434', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9964', 'x-ratelimit-remaining-tokens': '199681', 'x-ratelimit-reset-requests': '5m2.72s', 'x-ratelimit-reset-tokens': '95ms', 'x-request-id': 'req_ae7f8fa3dea64ea99b1d2c9941ac3113', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe49a19a85014-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:54:17,995 [DEBUG] openai._base_client: request_id: req_ae7f8fa3dea64ea99b1d2c9941ac3113
2025-09-12 15:54:17,996 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 307, 'completion_tokens': 1, 'total_tokens': 308}, cost=4.665e-05
2025-09-12 15:54:17,996 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.665e-05, {'prompt_tokens': 307, 'completion_tokens': 1, 'total_tokens': 308}
2025-09-12 15:54:17,996 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.665e-05, 'token_usage': 308}
2025-09-12 15:54:17,997 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer du sein, city=None, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 15:54:17,997 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.66e-05, city_cost=4.86e-05, institution_names_cost=0.00017549999999999998, institution_type_cost=3.225e-05, number_institutions_cost=4.665e-05
2025-09-12 15:54:17,998 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=228, institution_names_tokens=1110, institution_type_tokens=212, number_institutions_tokens=308
2025-09-12 15:54:17,999 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': None, 'city_detected': False, 'city_detection_method': 'status', 'city_cost': 4.86e-05, 'city_token_usage': 228, 'institution_name_mentioned': True, 'institution_names': [HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)], 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017549999999999998, 'institution_names_token_usage': 1110, 'institution_names_intent': 'single', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.225e-05, 'institution_type_token_usage': 212, 'specialty': 'cancer du sein', 'specialty_detection_method': 'llm', 'specialty_cost': 6.66e-05, 'specialty_token_usage': 0, 'number_institutions': 1, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.665e-05, 'number_institutions_token_usage': 308, 'total_cost': 0.0003696, 'total_token_usage': 1858}
2025-09-12 15:54:18,001 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer du sein', city=None, city_detected=False, institution_type='aucune correspondance', number_institutions=1, institution_names=[HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)], institution_name_mentioned=True
2025-09-12 15:54:18,001 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer du sein'
2025-09-12 15:54:18,002 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: None
2025-09-12 15:54:18,002 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: False
2025-09-12 15:54:18,002 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 15:54:18,002 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 1
2025-09-12 15:54:18,002 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: [HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)]
2025-09-12 15:54:18,002 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 15:54:18,002 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'single'
2025-09-12 15:54:18,005 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: True
2025-09-12 15:54:18,073 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:54:18,075 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 15:54:18,264 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 15:54:18,264 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 15:54:18,264 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer du sein'
2025-09-12 15:54:18,264 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: None
2025-09-12 15:54:18,265 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: False
2025-09-12 15:54:18,265 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 15:54:18,265 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: [HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)]
2025-09-12 15:54:18,265 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: True
2025-09-12 15:54:18,265 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 1
2025-09-12 15:54:18,265 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer du sein, city: None, institution_type: aucune correspondance, institution: [HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)], institution_name_mentioned: True
2025-09-12 15:54:18,265 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer du sein, city=None, institution_type=aucune correspondance, institution_names=[HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)], number_institutions=1
2025-09-12 15:54:18,265 [INFO] app.services.data_processing_service: generate_data_response called
2025-09-12 15:54:18,265 [DEBUG] app.services.data_processing_service: Extracted values - specialty: 'cancer du sein', institution_type: 'aucune correspondance', city: 'None'
2025-09-12 15:54:18,265 [DEBUG] app.services.data_processing_service: No institution type match found, loading by specialty only
2025-09-12 15:54:18,265 [INFO] app.services.data_processing_service: Filtering ranking by criteria: specialty='cancer du sein', institution_type='None'
2025-09-12 15:54:18,265 [DEBUG] app.services.data_processing_service: Filtering ranking data - specialty: 'cancer du sein', institution_type: 'None'
2025-09-12 15:54:18,266 [DEBUG] app.services.data_processing_service: Specialty type: <class 'str'>, length: 14
2025-09-12 15:54:18,266 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer du sein
2025-09-12 15:54:18,267 [DEBUG] app.services.data_processing_service: All normalized specialties in DataFrame: ['ablation des varices' 'accidents vasculaires cerebraux'
 'accouchements a risques' 'accouchements normaux'
 'adenome de la prostate' 'amygdales et vegetations'
 'angioplastie coronaire' 'appendicite' 'arthrose de la main' 'audition'
 'calculs urinaires' "cancer de l'estomac et de l'œsophage"
 "cancer de l'ovaire" "cancer de l'uterus" 'cancer de la prostate'
 'cancer de la thyroide' 'cancer de la vessie'
 "cancer des os de l'enfant et de l'adolescent"
 "cancer du colon ou de l'intestin" 'cancer du foie' 'cancer du pancreas'
 'cancer du poumon' 'cancer du rein' 'cancer du sein' 'cancer orl'
 'cancers de la peau' 'cardiologie interventionnelle' 'cataracte'
 'chirurgie cardiaque adulte' 'chirurgie cardiaque pediatrique'
 "chirurgie de l'epaule" "chirurgie de l'obesite"
 'chirurgie de la cheville' 'chirurgie de la cornee'
 'chirurgie dentaire et orale de l’adulte'
 'chirurgie dentaire et orale de l’enfant et de l’adolescent'
 'chirurgie des arteres' "chirurgie des cancers osseux de l'adulte"
 'chirurgie des carotides' 'chirurgie des sarcomes des tissus mous'
 "chirurgie des testicules de l'adulte"
 "chirurgie des testicules de l'enfant et de l'adolescent"
 'chirurgie du canal carpien' "chirurgie du dos de l'adulte"
 "chirurgie du dos de l'enfant et de l'adolescent"
 'chirurgie du nez et des sinus' 'chirurgie du pied' 'chirurgie du rectum'
 'chirurgie maxillo-faciale' 'depression' "diabete de l'adulte"
 "diabete de l'enfant et de l'adolescent" 'endometriose'
 "epilepsie de l'adulte" "epilepsie de l'enfant et de l'adolescent"
 'fibrome uterin' 'glandes salivaires' 'glaucome' "hernies de l'abdomen"
 'hypertension arterielle' 'infarctus du myocarde'
 'insuffisance cardiaque' "leucemie de l'adulte"
 "leucemie de l'enfant et de l'adolescent" 'ligaments du genou'
 "lymphome-myelome de l'adulte" 'maladie de parkinson'
 "maladies inflammatoires chroniques de l'intestin (mici)"
 'medecine vasculaire' 'pneumologie' 'proctologie' 'prothese de genou'
 'prothese de hanche' 'retine' 'schizophrenie' 'sclerose en plaques'
 'stimulateurs cardiaques' 'strabisme'
 'stress post-traumatique de l’adulte' 'troubles bipolaires'
 "tumeurs du cerveau de l'adulte"
 "tumeurs du cerveau de l'enfant et de l'adolescent" 'urgences de la main'
 'vesicule biliaire']
2025-09-12 15:54:18,267 [DEBUG] app.services.data_processing_service: Normalized specialty from query: 'cancer du sein'
2025-09-12 15:54:18,268 [DEBUG] app.services.data_processing_service: Normalized specialty from query: ''cancer du sein''
2025-09-12 15:54:18,268 [DEBUG] app.services.data_processing_service: Found 2 rows matching single specialty 'cancer du sein' (normalized: 'cancer du sein')
2025-09-12 15:54:18,269 [DEBUG] app.services.data_processing_service: Specialties found after specialty filtering: ['Cancer du sein']
2025-09-12 15:54:18,269 [INFO] app.services.data_processing_service: generate_response_links called with matching_rows: <class 'pandas.core.frame.DataFrame'>
2025-09-12 15:54:18,269 [INFO] app.services.data_processing_service: Generating ranking links
2025-09-12 15:54:18,269 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer du sein
2025-09-12 15:54:18,269 [DEBUG] app.services.data_processing_service: Generating links for 2 matching rows
2025-09-12 15:54:18,270 [DEBUG] app.services.data_processing_service: Mapping institution type for URL: Public
2025-09-12 15:54:18,270 [DEBUG] app.services.data_processing_service: Generating web link for specialty 'Cancer du sein' and institution_type 'public'
2025-09-12 15:54:18,270 [DEBUG] app.services.data_processing_service: Mapping institution type for URL: Privé
2025-09-12 15:54:18,270 [DEBUG] app.services.data_processing_service: Generating web link for specialty 'Cancer du sein' and institution_type 'prive'
2025-09-12 15:54:18,270 [INFO] app.services.data_processing_service: Generated ranking links: ['https://www.lepoint.fr/hopitaux/classements/cancer-du-sein-public.php', 'https://www.lepoint.fr/hopitaux/classements/cancer-du-sein-prive.php']
2025-09-12 15:54:18,270 [INFO] app.services.data_processing_service: load_excel_sheets called with matching_rows of length: 2
2025-09-12 15:54:18,271 [DEBUG] app.services.data_processing_service: Loading sheet: 'CANCER_SEIN-Public' for category: 'Public'
2025-09-12 15:54:18,431 [DEBUG] app.services.data_processing_service: Sheet 'CANCER_SEIN-Public' loaded successfully with 50 rows
2025-09-12 15:54:18,431 [DEBUG] app.services.data_processing_service: Loading sheet: 'CANCER_SEIN-Privé' for category: 'Privé'
2025-09-12 15:54:18,615 [DEBUG] app.services.data_processing_service: Sheet 'CANCER_SEIN-Privé' loaded successfully with 30 rows
2025-09-12 15:54:18,615 [DEBUG] app.services.data_processing_service: Concatenating 2 dataframes
2025-09-12 15:54:18,616 [INFO] app.services.data_processing_service: Successfully loaded 2 sheets, total rows: 80
2025-09-12 15:54:18,616 [INFO] app.services.data_processing_service: Loaded specialty DataFrame
2025-09-12 15:54:18,616 [INFO] app.services.pipeline_orchestrator_service: No city detected, returning general ranking DataFrame
2025-09-12 15:54:18,616 [INFO] app.services.pipeline_orchestrator_service: Filtering and sorting DataFrame with max_radius_km=5, number_institutions=1, prompt=Quel est le classement de CH de Vannes pour la cancer au sein ?
2025-09-12 15:54:18,617 [INFO] app.services.pipeline_orchestrator_service: Institution mentioned in query: [HospitalInfo(name='CH, Vannes (56)', specialty=None, type='public', ranking=None)]
2025-09-12 15:54:18,618 [DEBUG] app.services.pipeline_orchestrator_service: Normalizing specialty for display: cancer du sein
2025-09-12 15:54:35,068 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:54:35,068 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:54:35,068 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:54:35,068 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:54:35,070 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:54:35,070 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:54:35,070 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:54:35,169 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:54:35,169 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:54:35,170 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:54:35,173 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:54:35,174 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:54:35,369 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:54:35,370 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:54:35,370 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:54:35,371 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:54:35,371 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:54:35,371 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:54:35,443 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:54:35,443 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:54:35,443 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:54:35,445 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:54:35,445 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:54:35,445 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:54:35,445 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:54:35,445 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 15:54:35,445 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 15:54:35,445 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 15:54:35,445 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 15:54:35,446 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 15:54:35,446 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 15:54:35,446 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 15:54:35,519 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 15:54:35,519 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 15:54:35,519 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 15:54:35,521 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 15:54:35,521 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 15:54:35,552 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 15:54:35,554 [INFO] main: Creating FastAPI app
2025-09-12 15:54:35,554 [INFO] main: CORS middleware added
2025-09-12 15:54:35,555 [INFO] main: API router included
2025-09-12 15:54:35,562 [INFO] app.services.pipeline_orchestrator_service: Starting pipeline processing - prompt: Quel est le meilleur hôpital entre Clinique Belledonne et Nouvelle clinique de Tours ? 
2025-09-12 15:54:35,562 [INFO] app.services.pipeline_orchestrator_service: Resetting PipelineOrchestrator attributes for new query
2025-09-12 15:54:35,562 [INFO] app.services.pipeline_orchestrator_service: Running sanity checks for prompt: Quel est le meilleur hôpital entre Clinique Belledonne et Nouvelle clinique de Tours ? , conversation: [], conv_history: 
2025-09-12 15:54:35,562 [DEBUG] app.features.sanity_checks.sanity_checks_analyst: run_checks called: user_input=Quel est le meilleur hôpital entre Clinique Belledonne et Nouvelle clinique de Tours ? , conversation=[], conv_history=, checks_to_run=['conversation_limit', 'message_length', 'message_pertinence']
2025-09-12 15:54:35,562 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst running checks: ['conversation_limit', 'message_length', 'message_pertinence'] for user_input: Quel est le meilleur hôpital entre Clinique Belledonne et Nouvelle clinique de Tours ? 
2025-09-12 15:54:35,562 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check medical pertinence prompt sent to LLM.
2025-09-12 15:54:35,567 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nÉvaluez si le message suivant a un rapport avec la santé humaine ou les services de soins.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quel est le meilleur hôpital entre Clinique Belledonne et Nouvelle clinique de Tours ? \'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur la santé.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes de discussions médicales.\nATTENTION: Toute question sur la méthodologie, la fréquence de mise à jour, les critères, ou le fonctionnement du classement des hôpitaux doit TOUJOURS être considérée comme pertinente, même si elle ne concerne pas directement une maladie ou un service de soins.\n\nRépondez UNIQUEMENT avec 1 si pertinent, 0 si non pertinent ou 2 si la question concerne la méthodologie de calcul du classement.\n\nExemples pour messages standalone (repondre 1): \n- \'J\'ai un cancer à Paris\' → 1\n- \'Cataracte\' → 1  \n- \'J\'ai mal aux pieds\' → 1\n- \'Les hôpitaux privés sont ils meilleurs que les publiques?\' → 1\n- \'Comment le classement est-il calculé ?\' → 1\n- \'Quels sont les critères du classement ?\' → 1\n- "Quels experts participent à l\'élaboration du classement ?"\' → 1\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\' → 1\n- "Comment sont traitées les données manquantes dans le classement ?"\' → 1\n- "Le classement est-il le même pour toutes les spécialités ?"\' → 1\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\' → 1\n- "Quels sont les changements dans la méthodologie cette année ?"\' → 1\n- "Comment puis-je accéder au détail de la méthodologie ?"\' → 1\n\nExemples pour messages standalone (repondre 0):\n- \'Je mange des frites\' → 0\n- \'Comment faire une tarte aux pommes ?\' → 0\n- \'Comment s\'abonner Le Point ?\' → 0\n- \'Quel est le meilleur restaurant à Paris ?\' → 0\n\n\nExemples de questions qui concernent la méthodologie de classement (repondre 2):\n- "Comment le classement est-il calculé ?"\n- "Quels sont les critères du classement ?" \n- "Pourquoi l\'hôpital X est mieux classé que Y ?"\n- "Comment sont choisis les critères du classement ?"\n- "Qui réalise le classement des hôpitaux ?"\n- "Quelle est la source des données utilisées pour le classement ?"\n- "Le classement prend-il en compte la satisfaction des patients ?"\n- "Comment sont pondérés les différents critères ?"\n- "Est-ce que le classement est mis à jour chaque année ?"\n- "Pourquoi certains hôpitaux ne figurent pas dans le classement ?"\n- "Comment puis-je vérifier la fiabilité du classement ?"\n- "Quels experts participent à l\'élaboration du classement ?"\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\n- "Comment sont traitées les données manquantes dans le classement ?"\n- "Le classement est-il le même pour toutes les spécialités ?"\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\n- "Quels sont les changements dans la méthodologie cette année ?"\n- "Comment puis-je accéder au détail de la méthodologie ?"\n\nExemples pour messages avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique montrant une discussion sur les hôpitaux, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur la cardiologie, \'Merci\' → 1 (remerciement dans contexte médical)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n- Même avec contexte médical, \'Parle-moi de football\' → 0 (hors-sujet)\n- Avec historique sur les classements, "Comment sont déterminés les scores ?" → 2 (question sur la méthodologie de classement)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:54:35,598 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:54:35,599 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-09-12 15:54:35,634 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x113c1ba10>
2025-09-12 15:54:35,635 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x11399fda0> server_hostname='api.openai.com' timeout=None
2025-09-12 15:54:35,654 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x113be9f90>
2025-09-12 15:54:35,654 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:54:35,655 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:54:35,655 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:54:35,655 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:54:35,655 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:54:35,987 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:54:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'180'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'195'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9967'), (b'x-ratelimit-remaining-tokens', b'198874'), (b'x-ratelimit-reset-requests', b'4m39.378s'), (b'x-ratelimit-reset-tokens', b'337ms'), (b'x-request-id', b'req_1546e31d4b744e2cb0a9802fb05a8ce7'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=XW3AOVln6qa4rAIdeRgJar80EFZcAGbIOIzEs9Libd8-1757685276-1.0.1.1-U.sskcVWVirA9O3zcRJehXL2tJwNGHlwvRUt1jjLAe1R6EP658gmmC.me60uZrych00IfupbKJUo69CkyGbGnX7uIHg_i9mLQ3jA48pwNM4; path=/; expires=Fri, 12-Sep-25 14:24:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=wYn6L88_3gG72L_2g3azgO.rLX.lTrWSSKQheI7xFy8-1757685276150-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe5cdff81e229-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:54:35,988 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:54:35,989 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:54:35,992 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:54:35,992 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:54:35,992 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:54:35,993 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 12 Sep 2025 13:54:36 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'le-point-hv3izr'), ('openai-processing-ms', '180'), ('openai-project', 'proj_auvPnKXq8lce0dksWKRj2pvx'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '195'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9967'), ('x-ratelimit-remaining-tokens', '198874'), ('x-ratelimit-reset-requests', '4m39.378s'), ('x-ratelimit-reset-tokens', '337ms'), ('x-request-id', 'req_1546e31d4b744e2cb0a9802fb05a8ce7'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=XW3AOVln6qa4rAIdeRgJar80EFZcAGbIOIzEs9Libd8-1757685276-1.0.1.1-U.sskcVWVirA9O3zcRJehXL2tJwNGHlwvRUt1jjLAe1R6EP658gmmC.me60uZrych00IfupbKJUo69CkyGbGnX7uIHg_i9mLQ3jA48pwNM4; path=/; expires=Fri, 12-Sep-25 14:24:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=wYn6L88_3gG72L_2g3azgO.rLX.lTrWSSKQheI7xFy8-1757685276150-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '97dfe5cdff81e229-MRS'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-12 15:54:35,993 [DEBUG] openai._base_client: request_id: req_1546e31d4b744e2cb0a9802fb05a8ce7
2025-09-12 15:54:36,001 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_medical_pertinence' successful: {'prompt_tokens': 1112, 'completion_tokens': 1, 'total_tokens': 1113}, cost=0.00016739999999999998
2025-09-12 15:54:36,001 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for medical pertinence:
1
2025-09-12 15:54:36,001 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed medical pertinence value: 1 (type: <class 'int'>)
2025-09-12 15:54:36,001 [DEBUG] app.features.sanity_checks.message_pertinence_check: medical_pertinence_result: {'result': 1, 'cost': 0.00016739999999999998, 'token_usage': 1113}
2025-09-12 15:54:36,001 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check chatbot pertinence prompt sent to LLM.
2025-09-12 15:54:36,005 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nVérifiez si cette question concerne le classement des hôpitaux.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quel est le meilleur hôpital entre Clinique Belledonne et Nouvelle clinique de Tours ? \'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur les classements d\'hôpitaux.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes.\n\nRépondez UNIQUEMENT avec:\n- 1 si la question est pertinente pour le chatbot (classement, recherche d\'établissement, etc.)\n- 0 si la question n\'est pas pertinente\n\nUne question est pertinente si elle concerne au moins un des cas suivants:\n- Une maladie, un symptôme ou une spécialité médicale  \n- Le classement des hôpitaux et cliniques  \n- La recherche d\'un hôpital, d\'une clinique ou d\'un service médical  \n- Une question de suivi sur les secteurs public/privé des hôpitaux\n\nExemples de questions pertinentes pour messages standalone (repondre 1):  \n- Quel est la meilleur clinique de France ?\n- Conseille moi un hôpital à Lyon \n- Je chercher un service de pneumologie\n- Où faire soigner mon glaucome ? \n- Je veux corriger mon audition\n- Il y a fréquemment du sang dans mes urines. Conseille-moi un hôpital. \n- Je veux cherche à faire soigner mes troubles bipôlaires\n- Est-ce que l\'Institut mutualiste Montsouris est bon ?\n- Y a-t-il des hôpitaux privés avec un service de cardiologie interventionnelle ?\n\nExemples de questions non pertinentes pour messages standalone (repondre 0):  \n- Pourquoi les hôpitaux sont-ils en crise ?  #Il s\'agit d\'une demande d\'information qui n\'est pas dans le cadre direct de la recherche d\'un établissement de soin\n- Dois-je prendre du paracétamol pour ma fièvre ? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n- Puis-je perdre la vue si j\'ai un glaucome? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n\n\n\nExemples avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique sur les hôpitaux parisiens, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur les classements, \'Combien coûte une consultation ?\' → 0 (question sur les coûts, pas sur les classements)\n- Avec historique sur la recherche d\'hôpital, \'Merci beaucoup\' → 1 (remerciement dans contexte de recherche d\'hôpital)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:54:36,006 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:54:36,007 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:54:36,007 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:54:36,007 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:54:36,008 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:54:36,008 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:54:36,503 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:54:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'352'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'370'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9966'), (b'x-ratelimit-remaining-tokens', b'199166'), (b'x-ratelimit-reset-requests', b'4m47.675s'), (b'x-ratelimit-reset-tokens', b'250ms'), (b'x-request-id', b'req_4be7140829e6402fa924f1570b5bfc24'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe5d02c57e229-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:54:36,503 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:54:36,503 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:54:36,506 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:54:36,507 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:54:36,507 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:54:36,507 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:54:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '352', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '370', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9966', 'x-ratelimit-remaining-tokens': '199166', 'x-ratelimit-reset-requests': '4m47.675s', 'x-ratelimit-reset-tokens': '250ms', 'x-request-id': 'req_4be7140829e6402fa924f1570b5bfc24', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe5d02c57e229-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:54:36,507 [DEBUG] openai._base_client: request_id: req_4be7140829e6402fa924f1570b5bfc24
2025-09-12 15:54:36,508 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_chatbot_pertinence' successful: {'prompt_tokens': 810, 'completion_tokens': 1, 'total_tokens': 811}, cost=0.00012209999999999999
2025-09-12 15:54:36,508 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for chatbot pertinence:
1
2025-09-12 15:54:36,508 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed chatbot pertinence value: 1 (type: <class 'int'>)
2025-09-12 15:54:36,508 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst completed checks. All passed: True, Total cost: 0.00028949999999999994, Total tokens: 1924
2025-09-12 15:54:36,508 [INFO] app.features.sanity_checks.sanity_checks_analyst: Sanity check results: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 15:54:36,508 [INFO] app.services.pipeline_orchestrator_service: Sanity checks result: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 15:54:36,508 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quel est le meilleur hôpital entre Clinique Belledonne et Nouvelle clinique de Tours ? ', detected_specialty='None', conv_history=''
2025-09-12 15:54:36,509 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 15:54:36,509 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 15:54:36,509 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 15:54:36,509 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 15:54:36,706 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 15:54:36,707 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quel est le meilleur hôpital entre Clinique Belledonne et Nouvelle clinique de Tours ? , conv_history: 
2025-09-12 15:54:36,707 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quel est le meilleur hôpital entre Clinique Belledonne et Nouvelle clinique de Tours ? '
2025-09-12 15:54:36,709 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quel est le meilleur hôpital entre Clinique Belledonne et Nouvelle clinique de Tours ? '\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 15:54:36,710 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 15:54:36,710 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 15:54:36,710 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 15:54:36,710 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 15:54:36,711 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 15:54:36,711 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 15:54:37,244 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 13:54:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'363'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'380'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9966'), (b'x-ratelimit-remaining-tokens', b'199548'), (b'x-ratelimit-reset-requests', b'4m47.853s'), (b'x-ratelimit-reset-tokens', b'135ms'), (b'x-request-id', b'req_a2df8fc6c440468a8fda8be9bcaa1060'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97dfe5d48dd2e229-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 15:54:37,245 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 15:54:37,246 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 15:54:37,247 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 15:54:37,248 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 15:54:37,248 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 15:54:37,248 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 13:54:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '363', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '380', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9966', 'x-ratelimit-remaining-tokens': '199548', 'x-ratelimit-reset-requests': '4m47.853s', 'x-ratelimit-reset-tokens': '135ms', 'x-request-id': 'req_a2df8fc6c440468a8fda8be9bcaa1060', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97dfe5d48dd2e229-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 15:54:37,249 [DEBUG] openai._base_client: request_id: req_a2df8fc6c440468a8fda8be9bcaa1060
2025-09-12 15:54:37,250 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 431, 'completion_tokens': 4, 'total_tokens': 435}, cost=6.705e-05
2025-09-12 15:54:37,250 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: aucune correspondance, method: llm
2025-09-12 15:54:37,250 [ERROR] app.api.routes: Error processing /ask request: La spécialité que vous avez indiquée n'a pas été évaluée dans le classement des hôpitaux. Merci de reformuler votre question.
2025-09-12 16:04:10,164 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:04:10,164 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:04:10,164 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:04:10,164 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:04:10,166 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:04:10,166 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:04:10,166 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:04:10,278 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:04:10,278 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:04:10,279 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:04:10,282 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:04:10,282 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:04:10,505 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:04:10,505 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:04:10,506 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:04:10,506 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:04:10,507 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:04:10,507 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:04:10,588 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:04:10,588 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:04:10,588 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:04:10,591 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:04:10,591 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:04:10,591 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:04:10,591 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:04:10,591 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:04:10,591 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:04:10,592 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:04:10,592 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:04:10,592 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:04:10,593 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:04:10,593 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:04:10,673 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:04:10,674 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:04:10,674 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:04:10,676 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:04:10,677 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:04:10,712 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:04:10,714 [INFO] main: Creating FastAPI app
2025-09-12 16:04:10,714 [INFO] main: CORS middleware added
2025-09-12 16:04:10,715 [INFO] main: API router included
2025-09-12 16:08:06,810 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:08:06,810 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:08:06,810 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:08:06,811 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:08:06,812 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:08:06,813 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:08:06,813 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:08:06,913 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:08:06,913 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:08:06,913 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:08:06,917 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:08:06,917 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:08:07,112 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:08:07,112 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:08:07,112 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:08:07,113 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:08:07,113 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:08:07,113 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:08:07,186 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:08:07,186 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:08:07,186 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:08:07,188 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:08:07,188 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:08:07,188 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:08:07,188 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:08:07,188 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:08:07,188 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:08:07,189 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:08:07,189 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:08:07,189 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:08:07,190 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:08:07,190 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:08:07,273 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:08:07,287 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:08:07,287 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:08:07,289 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:08:07,309 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:08:07,348 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:08:07,351 [INFO] main: Creating FastAPI app
2025-09-12 16:08:07,352 [INFO] main: CORS middleware added
2025-09-12 16:08:07,353 [INFO] main: API router included
2025-09-12 16:12:04,703 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:12:04,703 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:12:04,703 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:12:04,703 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:12:04,705 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:12:04,705 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:12:04,705 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:12:04,807 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:12:04,808 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:12:04,808 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:12:04,811 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:12:04,812 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:12:05,012 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:12:05,012 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:12:05,012 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:12:05,013 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:12:05,013 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:12:05,013 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:12:05,089 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:12:05,089 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:12:05,089 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:12:05,091 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:12:05,091 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:12:05,091 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:12:05,091 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:12:05,092 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:12:05,092 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:12:05,092 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:12:05,092 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:12:05,093 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:12:05,093 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:12:05,093 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:12:05,165 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:12:05,165 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:12:05,165 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:12:05,167 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:12:05,167 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:12:05,196 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:12:05,198 [INFO] main: Creating FastAPI app
2025-09-12 16:12:05,199 [INFO] main: CORS middleware added
2025-09-12 16:12:05,200 [INFO] main: API router included
2025-09-12 16:13:35,513 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:13:35,513 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:13:35,513 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:13:35,514 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:13:35,515 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:13:35,515 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:13:35,515 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:13:35,629 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:13:35,629 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:13:35,630 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:13:35,634 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:13:35,635 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:13:35,856 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:13:35,856 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:13:35,856 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:13:35,857 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:13:35,857 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:13:35,857 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:13:35,935 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:13:35,935 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:13:35,935 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:13:35,937 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:13:35,937 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:13:35,937 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:13:35,937 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:13:35,938 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:13:35,938 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:13:35,938 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:13:35,938 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:13:35,939 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:13:35,939 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:13:35,939 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:13:36,018 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:13:36,019 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:13:36,019 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:13:36,021 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:13:36,021 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:13:36,054 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:13:36,057 [INFO] main: Creating FastAPI app
2025-09-12 16:13:36,057 [INFO] main: CORS middleware added
2025-09-12 16:13:36,058 [INFO] main: API router included
2025-09-12 16:14:24,524 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:14:24,524 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:14:24,524 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:14:24,524 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:14:24,527 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:14:24,527 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:14:24,527 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:14:24,720 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:14:24,720 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:14:24,720 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:14:24,724 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:14:24,724 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:14:24,952 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:14:24,952 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:14:24,952 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:14:24,953 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:14:24,953 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:14:24,953 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:14:25,041 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:14:25,041 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:14:25,042 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:14:25,044 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:14:25,044 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:14:25,044 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:14:25,044 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:14:25,045 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:14:25,045 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:14:25,045 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:14:25,045 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:14:25,047 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:14:25,047 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:14:25,047 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:14:25,140 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:14:25,140 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:14:25,140 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:14:25,142 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:14:25,142 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:14:25,172 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:14:25,174 [INFO] main: Creating FastAPI app
2025-09-12 16:14:25,174 [INFO] main: CORS middleware added
2025-09-12 16:14:25,175 [INFO] main: API router included
2025-09-12 16:14:36,739 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:14:36,739 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:14:36,739 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:14:36,739 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:14:36,740 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:14:36,741 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:14:36,741 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:14:36,865 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:14:36,866 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:14:36,866 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:14:36,869 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:14:36,870 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:14:37,105 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:14:37,105 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:14:37,105 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:14:37,106 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:14:37,106 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:14:37,106 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:14:37,185 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:14:37,185 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:14:37,185 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:14:37,187 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:14:37,187 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:14:37,187 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:14:37,187 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:14:37,187 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:14:37,187 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:14:37,188 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:14:37,188 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:14:37,188 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:14:37,189 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:14:37,189 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:14:37,267 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:14:37,267 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:14:37,267 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:14:37,270 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:14:37,270 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:14:37,302 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:14:37,304 [INFO] main: Creating FastAPI app
2025-09-12 16:14:37,305 [INFO] main: CORS middleware added
2025-09-12 16:14:37,306 [INFO] main: API router included
2025-09-12 16:14:44,240 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:14:44,240 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:14:44,240 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:14:44,240 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:14:44,241 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:14:44,241 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:14:44,242 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:14:44,340 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:14:44,340 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:14:44,340 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:14:44,343 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:14:44,343 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:14:44,522 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:14:44,522 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:14:44,522 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:14:44,523 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:14:44,523 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:14:44,523 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:14:44,595 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:14:44,595 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:14:44,596 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:14:44,597 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:14:44,598 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:14:44,598 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:14:44,598 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:14:44,598 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:14:44,598 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:14:44,598 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:14:44,598 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:14:44,599 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:14:44,599 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:14:44,599 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:14:44,671 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:14:44,671 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:14:44,671 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:14:44,673 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:14:44,674 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:14:44,705 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:14:44,707 [INFO] main: Creating FastAPI app
2025-09-12 16:14:44,707 [INFO] main: CORS middleware added
2025-09-12 16:14:44,709 [INFO] main: API router included
2025-09-12 16:14:58,653 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:14:58,653 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:14:58,653 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:14:58,653 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:14:58,654 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:14:58,654 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:14:58,654 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:14:58,747 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:14:58,747 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:14:58,748 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:14:58,750 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:14:58,751 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:14:58,922 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:14:58,922 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:14:58,923 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:14:58,923 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:14:58,923 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:14:58,924 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:14:58,995 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:14:58,996 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:14:58,996 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:14:58,998 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:14:58,998 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:14:58,998 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:14:58,998 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:14:58,998 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:14:58,998 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:14:58,998 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:14:58,998 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:14:58,999 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:14:58,999 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:14:58,999 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:14:59,072 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:14:59,072 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:14:59,073 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:14:59,074 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:14:59,075 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:14:59,104 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:14:59,106 [INFO] main: Creating FastAPI app
2025-09-12 16:14:59,106 [INFO] main: CORS middleware added
2025-09-12 16:14:59,107 [INFO] main: API router included
2025-09-12 16:15:00,178 [INFO] app.services.pipeline_orchestrator_service: Starting pipeline processing - prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 16:15:00,178 [INFO] app.services.pipeline_orchestrator_service: Resetting PipelineOrchestrator attributes for new query
2025-09-12 16:15:00,179 [INFO] app.services.pipeline_orchestrator_service: Running sanity checks for prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conversation: [], conv_history: 
2025-09-12 16:15:00,179 [DEBUG] app.features.sanity_checks.sanity_checks_analyst: run_checks called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conversation=[], conv_history=, checks_to_run=['conversation_limit', 'message_length', 'message_pertinence']
2025-09-12 16:15:00,179 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst running checks: ['conversation_limit', 'message_length', 'message_pertinence'] for user_input: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 16:15:00,179 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check medical pertinence prompt sent to LLM.
2025-09-12 16:15:00,183 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nÉvaluez si le message suivant a un rapport avec la santé humaine ou les services de soins.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur la santé.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes de discussions médicales.\nATTENTION: Toute question sur la méthodologie, la fréquence de mise à jour, les critères, ou le fonctionnement du classement des hôpitaux doit TOUJOURS être considérée comme pertinente, même si elle ne concerne pas directement une maladie ou un service de soins.\n\nRépondez UNIQUEMENT avec 1 si pertinent, 0 si non pertinent ou 2 si la question concerne la méthodologie de calcul du classement.\n\nExemples pour messages standalone (repondre 1): \n- \'J\'ai un cancer à Paris\' → 1\n- \'Cataracte\' → 1  \n- \'J\'ai mal aux pieds\' → 1\n- \'Les hôpitaux privés sont ils meilleurs que les publiques?\' → 1\n- \'Comment le classement est-il calculé ?\' → 1\n- \'Quels sont les critères du classement ?\' → 1\n- "Quels experts participent à l\'élaboration du classement ?"\' → 1\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\' → 1\n- "Comment sont traitées les données manquantes dans le classement ?"\' → 1\n- "Le classement est-il le même pour toutes les spécialités ?"\' → 1\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\' → 1\n- "Quels sont les changements dans la méthodologie cette année ?"\' → 1\n- "Comment puis-je accéder au détail de la méthodologie ?"\' → 1\n\nExemples pour messages standalone (repondre 0):\n- \'Je mange des frites\' → 0\n- \'Comment faire une tarte aux pommes ?\' → 0\n- \'Comment s\'abonner Le Point ?\' → 0\n- \'Quel est le meilleur restaurant à Paris ?\' → 0\n\n\nExemples de questions qui concernent la méthodologie de classement (repondre 2):\n- "Comment le classement est-il calculé ?"\n- "Quels sont les critères du classement ?" \n- "Pourquoi l\'hôpital X est mieux classé que Y ?"\n- "Comment sont choisis les critères du classement ?"\n- "Qui réalise le classement des hôpitaux ?"\n- "Quelle est la source des données utilisées pour le classement ?"\n- "Le classement prend-il en compte la satisfaction des patients ?"\n- "Comment sont pondérés les différents critères ?"\n- "Est-ce que le classement est mis à jour chaque année ?"\n- "Pourquoi certains hôpitaux ne figurent pas dans le classement ?"\n- "Comment puis-je vérifier la fiabilité du classement ?"\n- "Quels experts participent à l\'élaboration du classement ?"\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\n- "Comment sont traitées les données manquantes dans le classement ?"\n- "Le classement est-il le même pour toutes les spécialités ?"\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\n- "Quels sont les changements dans la méthodologie cette année ?"\n- "Comment puis-je accéder au détail de la méthodologie ?"\n\nExemples pour messages avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique montrant une discussion sur les hôpitaux, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur la cardiologie, \'Merci\' → 1 (remerciement dans contexte médical)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n- Même avec contexte médical, \'Parle-moi de football\' → 0 (hors-sujet)\n- Avec historique sur les classements, "Comment sont déterminés les scores ?" → 2 (question sur la méthodologie de classement)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:00,211 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:00,212 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-09-12 16:15:00,251 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x112e2fa10>
2025-09-12 16:15:00,252 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x112bebda0> server_hostname='api.openai.com' timeout=None
2025-09-12 16:15:00,274 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x112e61f90>
2025-09-12 16:15:00,274 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:00,275 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:00,275 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:00,275 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:00,275 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:00,952 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'398'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'541'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'198878'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'336ms'), (b'x-request-id', b'req_d7b993f818804d06a7bfffe237da0b73'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=FK2lCvv1l7fcYaCwjoglmCIpKs0B0wMjrRlz6ipODp0-1757686501-1.0.1.1-F5n7tif_ti9CocT8d0zkAeLiKjS3t4gG9ANzrrtITOITCgF7M4N6YFP5SdZmyQhk1PWyjvuHM9V8kW5aF4cvuYBsmJT34Hl7r_aS4nVzCqM; path=/; expires=Fri, 12-Sep-25 14:45:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=vR1F3DobcLZYFcfUqRysqvTVGh6d7v5f2fB6fonrvGY-1757686501054-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003b37c58e280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:00,953 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:00,953 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:00,957 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:00,957 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:00,957 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:00,958 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 12 Sep 2025 14:15:01 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'le-point-hv3izr'), ('openai-processing-ms', '398'), ('openai-project', 'proj_auvPnKXq8lce0dksWKRj2pvx'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '541'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '198878'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '336ms'), ('x-request-id', 'req_d7b993f818804d06a7bfffe237da0b73'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=FK2lCvv1l7fcYaCwjoglmCIpKs0B0wMjrRlz6ipODp0-1757686501-1.0.1.1-F5n7tif_ti9CocT8d0zkAeLiKjS3t4gG9ANzrrtITOITCgF7M4N6YFP5SdZmyQhk1PWyjvuHM9V8kW5aF4cvuYBsmJT34Hl7r_aS4nVzCqM; path=/; expires=Fri, 12-Sep-25 14:45:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=vR1F3DobcLZYFcfUqRysqvTVGh6d7v5f2fB6fonrvGY-1757686501054-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '97e003b37c58e280-MRS'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-12 16:15:00,958 [DEBUG] openai._base_client: request_id: req_d7b993f818804d06a7bfffe237da0b73
2025-09-12 16:15:00,965 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_medical_pertinence' successful: {'prompt_tokens': 1112, 'completion_tokens': 1, 'total_tokens': 1113}, cost=0.00016739999999999998
2025-09-12 16:15:00,966 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for medical pertinence:
1
2025-09-12 16:15:00,966 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed medical pertinence value: 1 (type: <class 'int'>)
2025-09-12 16:15:00,966 [DEBUG] app.features.sanity_checks.message_pertinence_check: medical_pertinence_result: {'result': 1, 'cost': 0.00016739999999999998, 'token_usage': 1113}
2025-09-12 16:15:00,966 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check chatbot pertinence prompt sent to LLM.
2025-09-12 16:15:00,969 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nVérifiez si cette question concerne le classement des hôpitaux.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur les classements d\'hôpitaux.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes.\n\nRépondez UNIQUEMENT avec:\n- 1 si la question est pertinente pour le chatbot (classement, recherche d\'établissement, etc.)\n- 0 si la question n\'est pas pertinente\n\nUne question est pertinente si elle concerne au moins un des cas suivants:\n- Une maladie, un symptôme ou une spécialité médicale  \n- Le classement des hôpitaux et cliniques  \n- La recherche d\'un hôpital, d\'une clinique ou d\'un service médical  \n- Une question de suivi sur les secteurs public/privé des hôpitaux\n\nExemples de questions pertinentes pour messages standalone (repondre 1):  \n- Quel est la meilleur clinique de France ?\n- Conseille moi un hôpital à Lyon \n- Je chercher un service de pneumologie\n- Où faire soigner mon glaucome ? \n- Je veux corriger mon audition\n- Il y a fréquemment du sang dans mes urines. Conseille-moi un hôpital. \n- Je veux cherche à faire soigner mes troubles bipôlaires\n- Est-ce que l\'Institut mutualiste Montsouris est bon ?\n- Y a-t-il des hôpitaux privés avec un service de cardiologie interventionnelle ?\n\nExemples de questions non pertinentes pour messages standalone (repondre 0):  \n- Pourquoi les hôpitaux sont-ils en crise ?  #Il s\'agit d\'une demande d\'information qui n\'est pas dans le cadre direct de la recherche d\'un établissement de soin\n- Dois-je prendre du paracétamol pour ma fièvre ? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n- Puis-je perdre la vue si j\'ai un glaucome? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n\n\n\nExemples avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique sur les hôpitaux parisiens, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur les classements, \'Combien coûte une consultation ?\' → 0 (question sur les coûts, pas sur les classements)\n- Avec historique sur la recherche d\'hôpital, \'Merci beaucoup\' → 1 (remerciement dans contexte de recherche d\'hôpital)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:00,970 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:00,971 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:00,971 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:00,971 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:00,971 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:00,971 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:01,719 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'381'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'589'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199168'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'249ms'), (b'x-request-id', b'req_5c0f03475edd4acda2402832c23f460b'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003b7ce75e280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:01,719 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:01,720 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:01,720 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:01,720 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:01,720 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:01,720 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:15:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '381', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '589', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199168', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '249ms', 'x-request-id': 'req_5c0f03475edd4acda2402832c23f460b', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e003b7ce75e280-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:15:01,720 [DEBUG] openai._base_client: request_id: req_5c0f03475edd4acda2402832c23f460b
2025-09-12 16:15:01,721 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_chatbot_pertinence' successful: {'prompt_tokens': 810, 'completion_tokens': 1, 'total_tokens': 811}, cost=0.00012209999999999999
2025-09-12 16:15:01,721 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for chatbot pertinence:
1
2025-09-12 16:15:01,721 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed chatbot pertinence value: 1 (type: <class 'int'>)
2025-09-12 16:15:01,721 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst completed checks. All passed: True, Total cost: 0.00028949999999999994, Total tokens: 1924
2025-09-12 16:15:01,722 [INFO] app.features.sanity_checks.sanity_checks_analyst: Sanity check results: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 16:15:01,722 [INFO] app.services.pipeline_orchestrator_service: Sanity checks result: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 16:15:01,722 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', detected_specialty='None', conv_history=''
2025-09-12 16:15:01,722 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 16:15:01,722 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 16:15:01,722 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 16:15:01,722 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 16:15:01,931 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 16:15:01,932 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history: 
2025-09-12 16:15:01,932 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'
2025-09-12 16:15:01,935 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:01,936 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:01,936 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:01,937 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:01,937 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:01,937 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:01,937 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:02,554 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'331'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'465'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199553'), (b'x-ratelimit-reset-requests', b'24.259s'), (b'x-ratelimit-reset-tokens', b'134ms'), (b'x-request-id', b'req_4edbcc2f04df4b969a3a688db944698d'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003bddc38e280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:02,554 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:02,555 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:02,559 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:02,559 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:02,559 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:02,560 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:15:02 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '331', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '465', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '199553', 'x-ratelimit-reset-requests': '24.259s', 'x-ratelimit-reset-tokens': '134ms', 'x-request-id': 'req_4edbcc2f04df4b969a3a688db944698d', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e003bddc38e280-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:15:02,560 [DEBUG] openai._base_client: request_id: req_4edbcc2f04df4b969a3a688db944698d
2025-09-12 16:15:02,561 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 431, 'completion_tokens': 6, 'total_tokens': 437}, cost=6.825e-05
2025-09-12 16:15:02,561 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer de la vessie., method: llm
2025-09-12 16:15:02,561 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer de la vessie', 'detection_method': 'llm', 'cost': 6.825e-05, 'token_usage': 0}
2025-09-12 16:15:02,562 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', conv_history: ''
2025-09-12 16:15:02,564 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:02,565 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:02,565 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:02,565 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:02,565 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:02,566 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:02,566 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:03,065 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'340'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'370'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'23.761s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_618017de3c1a4edaa0900275d5d8c71b'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003c1cda0e280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:03,066 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:03,066 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:03,073 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:03,073 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:03,073 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:03,073 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:15:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '340', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '370', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '23.761s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_618017de3c1a4edaa0900275d5d8c71b', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e003c1cda0e280-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:15:03,073 [DEBUG] openai._base_client: request_id: req_618017de3c1a4edaa0900275d5d8c71b
2025-09-12 16:15:03,074 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 16:15:03,076 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:03,077 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:03,077 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:03,078 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:03,078 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:03,078 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:03,078 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:03,592 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'250'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'387'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9995'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'40.406s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_6daf39e049524e158e8d7af1038d0456'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003c4fd32e280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:03,592 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:03,592 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:03,595 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:03,596 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:03,596 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:03,596 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:15:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '250', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '387', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9995', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '40.406s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_6daf39e049524e158e8d7af1038d0456', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e003c4fd32e280-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:15:03,596 [DEBUG] openai._base_client: request_id: req_6daf39e049524e158e8d7af1038d0456
2025-09-12 16:15:03,597 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 16:15:03,597 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 16:15:03,597 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'status_code': 3, 'token_usage': {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}}
2025-09-12 16:15:03,597 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history=
2025-09-12 16:15:03,599 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:03,600 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:03,600 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:03,600 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:03,601 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:03,601 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:03,601 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:04,245 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'498'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'514'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'48.643s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_12ec5151359b4c51bcbf2b380705c0d6'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003c83c8be280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:04,245 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:04,245 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:04,251 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:04,251 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:04,251 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:04,251 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:15:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '498', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '514', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9994', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '48.643s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_12ec5151359b4c51bcbf2b380705c0d6', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e003c83c8be280-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:15:04,251 [DEBUG] openai._base_client: request_id: req_12ec5151359b4c51bcbf2b380705c0d6
2025-09-12 16:15:04,252 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 17, 'total_tokens': 216}, cost=4.005e-05
2025-09-12 16:15:04,252 [WARNING] app.features.query_analysis.city.city_detection: Invalid city status: La phrase à analyser mentionne clairement "Paris". Donc, la réponse est :

3, defaulting to CITY_NO_CITY_MENTIONED
2025-09-12 16:15:04,252 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=None, status=0, method=status, cost=4.005e-05, tokens={'prompt_tokens': 199, 'completion_tokens': 17, 'total_tokens': 216}
2025-09-12 16:15:04,252 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 3, 'city_detected': True, 'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'token_usage': 318}
2025-09-12 16:15:04,252 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?' with conv_history: ''
2025-09-12 16:15:04,255 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:04,256 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:04,256 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:04,257 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:04,257 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:04,257 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:04,257 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:05,193 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'604'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'782'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'198986'), (b'x-ratelimit-reset-requests', b'47.824s'), (b'x-ratelimit-reset-tokens', b'304ms'), (b'x-request-id', b'req_04f13e60e7d9491b9b3b4c7945b05ed0'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003cc5d88e280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:05,193 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:05,193 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:05,198 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:05,198 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:05,198 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:05,199 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:15:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '604', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '782', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9994', 'x-ratelimit-remaining-tokens': '198986', 'x-ratelimit-reset-requests': '47.824s', 'x-ratelimit-reset-tokens': '304ms', 'x-request-id': 'req_04f13e60e7d9491b9b3b4c7945b05ed0', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e003cc5d88e280-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:15:05,199 [DEBUG] openai._base_client: request_id: req_04f13e60e7d9491b9b3b4c7945b05ed0
2025-09-12 16:15:05,199 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}, cost=0.00017295
2025-09-12 16:15:05,200 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 16:15:05,200 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 16:15:05,200 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': [], 'intent': 'none'}
2025-09-12 16:15:05,200 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: [], intent: none, cost: 0.00017295, token_usage: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}
2025-09-12 16:15:05,200 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | []
2025-09-12 16:15:05,200 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=[] and institution_list length=553)
2025-09-12 16:15:05,200 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: []
2025-09-12 16:15:05,200 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: none
2025-09-12 16:15:05,200 [INFO] app.features.query_analysis.institution_names.institution_names_validation: No specific institution detected
2025-09-12 16:15:05,200 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': None, 'institution_name_mentioned': False, 'error': 'No institution detected', 'intent': 'none', 'detection_method': 'llm', 'cost': 0.00017295, 'token_usage': 1108}
2025-09-12 16:15:05,203 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:05,203 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:05,203 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:05,204 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:05,204 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:05,204 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:05,204 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:05,559 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'193'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'207'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'55.674s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_48d3da0f59ed472e997d6bcd0383a291'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003d24b52e280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:05,560 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:05,560 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:05,564 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:05,564 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:05,564 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:05,564 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:15:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '193', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '207', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9993', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '55.674s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_48d3da0f59ed472e997d6bcd0383a291', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e003d24b52e280-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:15:05,565 [DEBUG] openai._base_client: request_id: req_48d3da0f59ed472e997d6bcd0383a291
2025-09-12 16:15:05,565 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}, cost=3.27e-05
2025-09-12 16:15:05,565 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.27e-05, {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}
2025-09-12 16:15:05,566 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.27e-05, 'token_usage': 215}
2025-09-12 16:15:05,568 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:05,568 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:05,569 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:05,569 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:05,569 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:05,569 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:05,569 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:06,044 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'318'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'345'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'55.313s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_9db6379d6fc54ee4a1e06f30b8d158e5'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003d48893e280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:06,045 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:06,045 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:06,050 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:06,050 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:06,050 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:06,051 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:15:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '318', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '345', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9993', 'x-ratelimit-remaining-tokens': '199678', 'x-ratelimit-reset-requests': '55.313s', 'x-ratelimit-reset-tokens': '96ms', 'x-request-id': 'req_9db6379d6fc54ee4a1e06f30b8d158e5', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e003d48893e280-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:15:06,051 [DEBUG] openai._base_client: request_id: req_9db6379d6fc54ee4a1e06f30b8d158e5
2025-09-12 16:15:06,052 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}, cost=4.71e-05
2025-09-12 16:15:06,052 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.71e-05, {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}
2025-09-12 16:15:06,052 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.71e-05, 'token_usage': 311}
2025-09-12 16:15:06,053 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer de la vessie, city=Paris, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 16:15:06,053 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.825e-05, city_cost=7.86e-05, institution_names_cost=0.00017295, institution_type_cost=3.27e-05, number_institutions_cost=4.71e-05
2025-09-12 16:15:06,053 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=318, institution_names_tokens=1108, institution_type_tokens=215, number_institutions_tokens=311
2025-09-12 16:15:06,053 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.86e-05, 'city_token_usage': 318, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017295, 'institution_names_token_usage': 1108, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.27e-05, 'institution_type_token_usage': 215, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.825e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.71e-05, 'number_institutions_token_usage': 311, 'total_cost': 0.0003996, 'total_token_usage': 1952}
2025-09-12 16:15:06,053 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer de la vessie', city='Paris', city_detected=True, institution_type='aucune correspondance', number_institutions=3, institution_names=None, institution_name_mentioned=False
2025-09-12 16:15:06,053 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer de la vessie'
2025-09-12 16:15:06,053 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: 'Paris'
2025-09-12 16:15:06,053 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: True
2025-09-12 16:15:06,053 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 16:15:06,054 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 3
2025-09-12 16:15:06,054 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: []
2025-09-12 16:15:06,054 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 16:15:06,054 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'none'
2025-09-12 16:15:06,054 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: False
2025-09-12 16:15:06,084 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 16:15:06,084 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 16:15:06,308 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 16:15:06,308 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 16:15:06,308 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer de la vessie'
2025-09-12 16:15:06,308 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: 'Paris'
2025-09-12 16:15:06,308 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: True
2025-09-12 16:15:06,308 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 16:15:06,308 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: []
2025-09-12 16:15:06,308 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: False
2025-09-12 16:15:06,308 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 3
2025-09-12 16:15:06,308 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer de la vessie, city: Paris, institution_type: aucune correspondance, institution: [], institution_name_mentioned: False
2025-09-12 16:15:06,308 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 16:15:06,309 [DEBUG] app.services.pipeline_orchestrator_service: [CITY DETECTION] Detected city: 'Paris', city_detected: True, DataProcessor.city: 'Paris', DataProcessor.city_detected: True
2025-09-12 16:15:06,309 [DEBUG] app.services.pipeline_orchestrator_service: Calling build_ranking_dataframe_with_distances
2025-09-12 16:15:06,309 [INFO] app.services.pipeline_orchestrator_service: Building ranking DataFrame with distances: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', excel_path='/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx', detected_specialty='cancer de la vessie'
2025-09-12 16:15:06,309 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', detected_specialty='cancer de la vessie', conv_history='None'
2025-09-12 16:15:06,309 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 16:15:06,309 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 16:15:06,309 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 16:15:06,309 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 16:15:06,501 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 16:15:06,502 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history: 
2025-09-12 16:15:06,502 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'
2025-09-12 16:15:06,504 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:06,505 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:06,506 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:06,506 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:06,506 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:06,506 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:06,506 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:07,173 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'398'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'536'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9990'), (b'x-ratelimit-remaining-tokens', b'199553'), (b'x-ratelimit-reset-requests', b'1m20.171s'), (b'x-ratelimit-reset-tokens', b'134ms'), (b'x-request-id', b'req_367cef1163de430b8ae6d85014d247e4'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003da6ef4e280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:07,174 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:07,174 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:07,175 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:07,176 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:07,176 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:07,176 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:15:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '398', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '536', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9990', 'x-ratelimit-remaining-tokens': '199553', 'x-ratelimit-reset-requests': '1m20.171s', 'x-ratelimit-reset-tokens': '134ms', 'x-request-id': 'req_367cef1163de430b8ae6d85014d247e4', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e003da6ef4e280-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:15:07,176 [DEBUG] openai._base_client: request_id: req_367cef1163de430b8ae6d85014d247e4
2025-09-12 16:15:07,177 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 431, 'completion_tokens': 6, 'total_tokens': 437}, cost=6.825e-05
2025-09-12 16:15:07,177 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer de la vessie., method: llm
2025-09-12 16:15:07,178 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer de la vessie', 'detection_method': 'llm', 'cost': 6.825e-05, 'token_usage': 0}
2025-09-12 16:15:07,178 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', conv_history: ''
2025-09-12 16:15:07,180 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:07,181 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:07,181 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:07,182 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:07,182 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:07,182 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:07,182 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:07,627 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'162'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'307'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9990'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m19.612s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_fe807d6438c040d7ad1f8cef43826f11'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003de9fcde280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:07,627 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:07,628 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:07,633 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:07,633 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:07,633 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:07,634 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:15:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '162', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '307', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9990', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m19.612s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_fe807d6438c040d7ad1f8cef43826f11', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e003de9fcde280-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:15:07,634 [DEBUG] openai._base_client: request_id: req_fe807d6438c040d7ad1f8cef43826f11
2025-09-12 16:15:07,635 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 16:15:07,637 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:07,637 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:07,638 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:07,638 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:07,638 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:07,638 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:07,638 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:08,106 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'282'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'297'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'1m27.767s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_b5bd654b8eee451cadc69ad6b20cbb76'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003e17db7e280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:08,107 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:08,107 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:08,109 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:08,110 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:08,110 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:08,110 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:15:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '282', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '297', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9989', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '1m27.767s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_b5bd654b8eee451cadc69ad6b20cbb76', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e003e17db7e280-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:15:08,110 [DEBUG] openai._base_client: request_id: req_b5bd654b8eee451cadc69ad6b20cbb76
2025-09-12 16:15:08,111 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 16:15:08,111 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 16:15:08,111 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'status_code': 3, 'token_usage': {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}}
2025-09-12 16:15:08,111 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history=
2025-09-12 16:15:08,113 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:08,114 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:08,114 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:08,114 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:08,114 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:08,115 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:08,115 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:08,470 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'199'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'221'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m27.32s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_eb092038354b4e2ab3d4a491e1f58f14'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003e47c60e280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:08,470 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:08,471 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:08,481 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:08,481 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:08,481 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:08,481 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:15:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '199', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '221', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9989', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m27.32s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_eb092038354b4e2ab3d4a491e1f58f14', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e003e47c60e280-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:15:08,482 [DEBUG] openai._base_client: request_id: req_eb092038354b4e2ab3d4a491e1f58f14
2025-09-12 16:15:08,482 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 16:15:08,485 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:08,486 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:08,486 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:08,486 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:08,486 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:08,486 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:08,486 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:09,060 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'279'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'449'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9987'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'1m44.109s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_8d295f617aa94664892874449642f650'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003e6c959e280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:09,060 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:09,060 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:09,065 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:09,065 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:09,065 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:09,065 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:15:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '279', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '449', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9987', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '1m44.109s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_8d295f617aa94664892874449642f650', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e003e6c959e280-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:15:09,066 [DEBUG] openai._base_client: request_id: req_8d295f617aa94664892874449642f650
2025-09-12 16:15:09,066 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 16:15:09,067 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 16:15:09,067 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 3, 'city_detected': True, 'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'token_usage': 318}
2025-09-12 16:15:09,067 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?' with conv_history: ''
2025-09-12 16:15:09,069 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:09,070 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:09,070 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:09,070 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:09,071 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:09,071 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:09,071 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:09,823 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'465'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'604'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9987'), (b'x-ratelimit-remaining-tokens', b'198986'), (b'x-ratelimit-reset-requests', b'1m52.291s'), (b'x-ratelimit-reset-tokens', b'304ms'), (b'x-request-id', b'req_5f23eb7b45b0465591d97e995aa9151b'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003ea695de280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:09,823 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:09,823 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:09,823 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:09,824 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:09,824 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:09,824 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:15:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '465', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '604', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9987', 'x-ratelimit-remaining-tokens': '198986', 'x-ratelimit-reset-requests': '1m52.291s', 'x-ratelimit-reset-tokens': '304ms', 'x-request-id': 'req_5f23eb7b45b0465591d97e995aa9151b', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e003ea695de280-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:15:09,824 [DEBUG] openai._base_client: request_id: req_5f23eb7b45b0465591d97e995aa9151b
2025-09-12 16:15:09,825 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}, cost=0.00017295
2025-09-12 16:15:09,825 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 16:15:09,825 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 16:15:09,825 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': [], 'intent': 'none'}
2025-09-12 16:15:09,825 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: [], intent: none, cost: 0.00017295, token_usage: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}
2025-09-12 16:15:09,825 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | []
2025-09-12 16:15:09,825 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=[] and institution_list length=553)
2025-09-12 16:15:09,825 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: []
2025-09-12 16:15:09,825 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: none
2025-09-12 16:15:09,825 [INFO] app.features.query_analysis.institution_names.institution_names_validation: No specific institution detected
2025-09-12 16:15:09,825 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': None, 'institution_name_mentioned': False, 'error': 'No institution detected', 'intent': 'none', 'detection_method': 'llm', 'cost': 0.00017295, 'token_usage': 1108}
2025-09-12 16:15:09,828 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:09,828 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:09,829 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:09,829 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:09,829 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:09,829 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:09,829 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:10,190 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'197'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'217'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9986'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'2m0.167s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_3bb84ad7a3ba4c9d86823852f7ee00b6'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003ef2c92e280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:10,191 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:10,191 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:10,192 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:10,192 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:10,192 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:10,192 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:15:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '197', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '217', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9986', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '2m0.167s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_3bb84ad7a3ba4c9d86823852f7ee00b6', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e003ef2c92e280-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:15:10,193 [DEBUG] openai._base_client: request_id: req_3bb84ad7a3ba4c9d86823852f7ee00b6
2025-09-12 16:15:10,193 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}, cost=3.27e-05
2025-09-12 16:15:10,193 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.27e-05, {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}
2025-09-12 16:15:10,193 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.27e-05, 'token_usage': 215}
2025-09-12 16:15:10,196 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:15:10,196 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:15:10,197 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:15:10,197 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:15:10,197 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:15:10,197 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:15:10,197 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:15:10,789 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:15:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'296'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'385'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9986'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'1m59.679s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_8148a98d4f804184a0e7c9f049c7bddf'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e003f179a7e280-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:15:10,790 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:15:10,790 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:15:10,802 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:15:10,802 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:15:10,802 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:15:10,803 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:15:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '296', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '385', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9986', 'x-ratelimit-remaining-tokens': '199678', 'x-ratelimit-reset-requests': '1m59.679s', 'x-ratelimit-reset-tokens': '96ms', 'x-request-id': 'req_8148a98d4f804184a0e7c9f049c7bddf', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e003f179a7e280-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:15:10,803 [DEBUG] openai._base_client: request_id: req_8148a98d4f804184a0e7c9f049c7bddf
2025-09-12 16:15:10,803 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}, cost=4.71e-05
2025-09-12 16:15:10,804 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.71e-05, {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}
2025-09-12 16:15:10,804 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.71e-05, 'token_usage': 311}
2025-09-12 16:15:10,804 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer de la vessie, city=Paris, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 16:15:10,804 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.825e-05, city_cost=7.86e-05, institution_names_cost=0.00017295, institution_type_cost=3.27e-05, number_institutions_cost=4.71e-05
2025-09-12 16:15:10,804 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=318, institution_names_tokens=1108, institution_type_tokens=215, number_institutions_tokens=311
2025-09-12 16:15:10,804 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.86e-05, 'city_token_usage': 318, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017295, 'institution_names_token_usage': 1108, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.27e-05, 'institution_type_token_usage': 215, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.825e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.71e-05, 'number_institutions_token_usage': 311, 'total_cost': 0.0003996, 'total_token_usage': 1952}
2025-09-12 16:15:10,804 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer de la vessie', city='Paris', city_detected=True, institution_type='aucune correspondance', number_institutions=3, institution_names=None, institution_name_mentioned=False
2025-09-12 16:15:10,804 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer de la vessie'
2025-09-12 16:15:10,804 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: 'Paris'
2025-09-12 16:15:10,804 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: True
2025-09-12 16:15:10,804 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 16:15:10,805 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 3
2025-09-12 16:15:10,805 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: []
2025-09-12 16:15:10,805 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 16:15:10,805 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'none'
2025-09-12 16:15:10,805 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: False
2025-09-12 16:15:10,836 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 16:15:10,836 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 16:15:10,992 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 16:15:10,992 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 16:15:10,992 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer de la vessie'
2025-09-12 16:15:10,992 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: 'Paris'
2025-09-12 16:15:10,993 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: True
2025-09-12 16:15:10,993 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 16:15:10,993 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: []
2025-09-12 16:15:10,993 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: False
2025-09-12 16:15:10,993 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 3
2025-09-12 16:15:10,993 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer de la vessie, city: Paris, institution_type: aucune correspondance, institution: [], institution_name_mentioned: False
2025-09-12 16:15:10,993 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 16:15:10,993 [INFO] app.services.data_processing_service: generate_data_response called
2025-09-12 16:15:10,993 [DEBUG] app.services.data_processing_service: Extracted values - specialty: 'cancer de la vessie', institution_type: 'aucune correspondance', city: 'Paris'
2025-09-12 16:15:10,993 [DEBUG] app.services.data_processing_service: No institution type match found, loading by specialty only
2025-09-12 16:15:10,993 [INFO] app.services.data_processing_service: Filtering ranking by criteria: specialty='cancer de la vessie', institution_type='None'
2025-09-12 16:15:10,993 [DEBUG] app.services.data_processing_service: Filtering ranking data - specialty: 'cancer de la vessie', institution_type: 'None'
2025-09-12 16:15:10,994 [DEBUG] app.services.data_processing_service: Specialty type: <class 'str'>, length: 19
2025-09-12 16:15:10,994 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer de la vessie
2025-09-12 16:15:10,995 [DEBUG] app.services.data_processing_service: All normalized specialties in DataFrame: ['ablation des varices' 'accidents vasculaires cerebraux'
 'accouchements a risques' 'accouchements normaux'
 'adenome de la prostate' 'amygdales et vegetations'
 'angioplastie coronaire' 'appendicite' 'arthrose de la main' 'audition'
 'calculs urinaires' "cancer de l'estomac et de l'œsophage"
 "cancer de l'ovaire" "cancer de l'uterus" 'cancer de la prostate'
 'cancer de la thyroide' 'cancer de la vessie'
 "cancer des os de l'enfant et de l'adolescent"
 "cancer du colon ou de l'intestin" 'cancer du foie' 'cancer du pancreas'
 'cancer du poumon' 'cancer du rein' 'cancer du sein' 'cancer orl'
 'cancers de la peau' 'cardiologie interventionnelle' 'cataracte'
 'chirurgie cardiaque adulte' 'chirurgie cardiaque pediatrique'
 "chirurgie de l'epaule" "chirurgie de l'obesite"
 'chirurgie de la cheville' 'chirurgie de la cornee'
 'chirurgie dentaire et orale de l’adulte'
 'chirurgie dentaire et orale de l’enfant et de l’adolescent'
 'chirurgie des arteres' "chirurgie des cancers osseux de l'adulte"
 'chirurgie des carotides' 'chirurgie des sarcomes des tissus mous'
 "chirurgie des testicules de l'adulte"
 "chirurgie des testicules de l'enfant et de l'adolescent"
 'chirurgie du canal carpien' "chirurgie du dos de l'adulte"
 "chirurgie du dos de l'enfant et de l'adolescent"
 'chirurgie du nez et des sinus' 'chirurgie du pied' 'chirurgie du rectum'
 'chirurgie maxillo-faciale' 'depression' "diabete de l'adulte"
 "diabete de l'enfant et de l'adolescent" 'endometriose'
 "epilepsie de l'adulte" "epilepsie de l'enfant et de l'adolescent"
 'fibrome uterin' 'glandes salivaires' 'glaucome' "hernies de l'abdomen"
 'hypertension arterielle' 'infarctus du myocarde'
 'insuffisance cardiaque' "leucemie de l'adulte"
 "leucemie de l'enfant et de l'adolescent" 'ligaments du genou'
 "lymphome-myelome de l'adulte" 'maladie de parkinson'
 "maladies inflammatoires chroniques de l'intestin (mici)"
 'medecine vasculaire' 'pneumologie' 'proctologie' 'prothese de genou'
 'prothese de hanche' 'retine' 'schizophrenie' 'sclerose en plaques'
 'stimulateurs cardiaques' 'strabisme'
 'stress post-traumatique de l’adulte' 'troubles bipolaires'
 "tumeurs du cerveau de l'adulte"
 "tumeurs du cerveau de l'enfant et de l'adolescent" 'urgences de la main'
 'vesicule biliaire']
2025-09-12 16:15:10,995 [DEBUG] app.services.data_processing_service: Normalized specialty from query: 'cancer de la vessie'
2025-09-12 16:15:10,996 [DEBUG] app.services.data_processing_service: Normalized specialty from query: ''cancer de la vessie''
2025-09-12 16:15:10,997 [DEBUG] app.services.data_processing_service: Found 2 rows matching single specialty 'cancer de la vessie' (normalized: 'cancer de la vessie')
2025-09-12 16:15:10,997 [DEBUG] app.services.data_processing_service: Specialties found after specialty filtering: ['Cancer de la vessie']
2025-09-12 16:15:10,997 [INFO] app.services.data_processing_service: generate_response_links called with matching_rows: <class 'pandas.core.frame.DataFrame'>
2025-09-12 16:15:10,997 [INFO] app.services.data_processing_service: Generating ranking links
2025-09-12 16:15:10,997 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer de la vessie
2025-09-12 16:15:10,997 [DEBUG] app.services.data_processing_service: Generating links for 2 matching rows
2025-09-12 16:15:10,997 [DEBUG] app.services.data_processing_service: Mapping institution type for URL: Public
2025-09-12 16:15:10,998 [DEBUG] app.services.data_processing_service: Generating web link for specialty 'Cancer de la vessie' and institution_type 'public'
2025-09-12 16:15:10,998 [DEBUG] app.services.data_processing_service: Mapping institution type for URL: Privé
2025-09-12 16:15:10,998 [DEBUG] app.services.data_processing_service: Generating web link for specialty 'Cancer de la vessie' and institution_type 'prive'
2025-09-12 16:15:10,998 [INFO] app.services.data_processing_service: Generated ranking links: ['https://www.lepoint.fr/hopitaux/classements/cancer-de-la-vessie-public.php', 'https://www.lepoint.fr/hopitaux/classements/cancer-de-la-vessie-prive.php']
2025-09-12 16:15:10,998 [INFO] app.services.data_processing_service: load_excel_sheets called with matching_rows of length: 2
2025-09-12 16:15:10,998 [DEBUG] app.services.data_processing_service: Loading sheet: 'CANCER_VESSIE-Public' for category: 'Public'
2025-09-12 16:15:11,151 [DEBUG] app.services.data_processing_service: Sheet 'CANCER_VESSIE-Public' loaded successfully with 40 rows
2025-09-12 16:15:11,151 [DEBUG] app.services.data_processing_service: Loading sheet: 'CANCER_VESSIE-Privé' for category: 'Privé'
2025-09-12 16:15:11,300 [DEBUG] app.services.data_processing_service: Sheet 'CANCER_VESSIE-Privé' loaded successfully with 20 rows
2025-09-12 16:15:11,300 [DEBUG] app.services.data_processing_service: Concatenating 2 dataframes
2025-09-12 16:15:11,300 [INFO] app.services.data_processing_service: Successfully loaded 2 sheets, total rows: 60
2025-09-12 16:15:11,300 [INFO] app.services.data_processing_service: Loaded specialty DataFrame
2025-09-12 16:15:11,301 [INFO] app.services.pipeline_orchestrator_service: Extracting hospital locations and calculating distances
2025-09-12 16:15:11,301 [INFO] app.services.data_processing_service: extract_local_hospitals called with df: <class 'NoneType'>
2025-09-12 16:15:11,301 [INFO] app.services.data_processing_service: Merging ranking data with hospital location data
2025-09-12 16:15:11,303 [DEBUG] app.services.data_processing_service: Merged DataFrame shape (with cities): (60, 6)
2025-09-12 16:15:11,304 [INFO] app.services.data_processing_service: get_df_with_distances called
2025-09-12 16:15:11,304 [INFO] app.services.data_processing_service: Calculating distances from query city: Paris
2025-09-12 16:15:11,339 [DEBUG] urllib3.util.retry: Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-09-12 16:15:11,339 [DEBUG] urllib3.util.retry: Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-09-12 16:15:11,340 [DEBUG] geopy: Nominatim.geocode: https://nominatim.openstreetmap.org/search?q=Paris&format=json&limit=1
2025-09-12 16:15:11,340 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): nominatim.openstreetmap.org:443
2025-09-12 16:15:11,802 [DEBUG] urllib3.connectionpool: https://nominatim.openstreetmap.org:443 "GET /search?q=Paris&format=json&limit=1 HTTP/1.1" 200 444
2025-09-12 16:15:11,805 [DEBUG] app.services.data_processing_service: Query city coordinates: (48.8534951, 2.3483915)
2025-09-12 16:15:11,851 [DEBUG] app.services.data_processing_service: DataFrame with distances shape after filtering: (60, 7)
2025-09-12 16:15:11,851 [DEBUG] app.services.data_processing_service: Distance column values after filtering: [397.16421568228793, 664.5671165057212, 415.42021849676877, 454.6232692587221, 628.9272762614704, 372.76695725398446, 187.64257370100052, 346.44804063177855, 204.9061679313438, 345.3834222363833, 594.4783082353262, 409.73559161431035, 498.73884900510325, 308.98876258531186, 587.6020165018895, 201.6803175167258, 281.9666122654773, 113.41737487155112, 264.6693413955004, 578.6238060003169, 16.726792716267678, 587.6020165018895, 440.6409364823054, 398.5542834873119, 498.73884900510325, 547.7564737199306, 264.6693413955004, 684.864748960447, 441.30736307891743, 382.66401151108664, 409.73559161431035, 481.9811724587299, 0.0, 4.592712151579527, 9.217278413662884, 11.453781374536742, 364.4347650853049, 0.0, 282.41401459727837, 285.7997399851394, 0.0, 0.0, 660.3147713621365, 0.0, 0.0, 660.3147713621365, 204.9061679313438, 638.1373345264166, 378.3676161619013, 380.29745819875353, 660.3147713621365, 0.0, 498.73884900510325, 687.7062403382804, 613.2211062491715, 506.307887243086, 345.3834222363833, 652.4186260952922, 588.3439902102477, 578.6238060003169]
2025-09-12 16:15:11,852 [DEBUG] app.services.pipeline_orchestrator_service: build_ranking_dataframe_with_distances returned DataFrame: <class 'pandas.core.frame.DataFrame'>
2025-09-12 16:15:11,852 [DEBUG] app.services.pipeline_orchestrator_service: Checking if DataFrame is None
2025-09-12 16:15:11,852 [DEBUG] app.services.pipeline_orchestrator_service: Retrieved DataFrame shape: (60, 7)
2025-09-12 16:15:11,852 [DEBUG] app.services.pipeline_orchestrator_service: Checking for geolocation API errors
2025-09-12 16:15:11,852 [DEBUG] app.services.pipeline_orchestrator_service: Getting ranking link for UI
2025-09-12 16:15:11,852 [DEBUG] app.services.pipeline_orchestrator_service: Checking for specialty_ranking_unavailable
2025-09-12 16:15:11,852 [DEBUG] app.services.pipeline_orchestrator_service: Checking if institution is mentioned
2025-09-12 16:15:11,853 [DEBUG] app.services.pipeline_orchestrator_service: Checking if city is detected
2025-09-12 16:15:11,853 [DEBUG] app.services.pipeline_orchestrator_service: [DF COLUMNS] DataFrame columns before city/distance selection: ['Etablissement', 'Ville', 'Latitude', 'Longitude', 'Catégorie', 'Note / 20', 'Distance']
2025-09-12 16:15:11,853 [DEBUG] app.services.pipeline_orchestrator_service: Unique cities in DataFrame before select_hospitals: ['Pierre-Bénite' 'Bayonne' 'Brive-la-Gaillarde' 'Chambéry' 'Dax'
 'La Roche-sur-Yon' 'Valenciennes' 'Clermont-Ferrand' 'Lille' 'Limoges'
 'Montpellier' 'Saint-Etienne' 'Bordeaux' 'Rennes' 'Toulouse' 'Caen'
 'Vandœuvre-lès-Nancy' 'Salouel' 'Angers' 'Nîmes' 'Ermont' 'Royan'
 'Strasbourg' 'Albi' 'Mougins' 'Lorient' 'Saint-Nazaire' 'Grenoble'
 'Paris' 'Le Kremlin-Bicêtre' 'Suresnes' 'Créteil' 'Trévenans' 'Nancy'
 'Vantoux' 'Marseille' 'Aix-en-Provence' 'Plérin' 'Colmar' 'Cabestany'
 'Boujan-sur-Libron' 'Brest' 'Pau' 'Reims']
2025-09-12 16:15:11,853 [INFO] app.services.pipeline_orchestrator_service: City detected, preparing to call select_hospitals.
2025-09-12 16:15:11,853 [DEBUG] app.services.pipeline_orchestrator_service: About to call select_hospitals with df columns: ['Etablissement', 'Ville', 'Latitude', 'Longitude', 'Catégorie', 'Note / 20', 'Distance'], city: Paris, number_institutions: 3
2025-09-12 16:15:11,853 [INFO] app.services.data_processing_service: Selecting hospitals for city: Paris with number_institutions: 3
2025-09-12 16:15:11,854 [INFO] app.services.data_processing_service: Found 7 hospitals in city 'Paris', meeting the requirement of 3.
2025-09-12 16:15:11,857 [DEBUG] app.services.pipeline_orchestrator_service: Formatting response with specialty: base_message='Voici les meilleurs établissements (rayon utilisé : 0 km)', count=3, radius_km=0, city=Paris
2025-09-12 16:15:11,857 [DEBUG] app.services.pipeline_orchestrator_service: Normalizing specialty for display: cancer de la vessie
2025-09-12 16:15:11,858 [INFO] app.services.pipeline_orchestrator_service: Creating response and logging for prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 16:15:11,858 [DEBUG] app.services.pipeline_orchestrator_service: Sanity check results for costs/tokens aggregation: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 16:15:11,858 [DEBUG] app.services.pipeline_orchestrator_service: Query analyst results for costs/tokens aggregation: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.86e-05, 'city_token_usage': 318, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017295, 'institution_names_token_usage': 1108, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.27e-05, 'institution_type_token_usage': 215, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.825e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.71e-05, 'number_institutions_token_usage': 311, 'total_cost': 0.0003996, 'total_token_usage': 1952}
2025-09-12 16:15:11,858 [DEBUG] app.services.pipeline_orchestrator_service: Conversation analyst results for costs/tokens aggregation: None
2025-09-12 16:15:11,858 [INFO] app.services.pipeline_orchestrator_service: Aggregated costs and token usage: {'total_cost_sanity_checks_analyst': 0.00028949999999999994, 'total_cost_query_analyst': 0.0007992, 'total_cost_conversation_analyst': 0.0, 'total_cost': 0.0010887, 'total_token_usage_sanity_checks_analyst': 1924, 'total_token_usage_query_analyst': 0, 'total_token_usage_conversation_analyst': 0, 'total_token_usage': 1924}
2025-09-12 16:15:11,858 [INFO] app.services.pipeline_orchestrator_service: Final cost/token usage aggregation: {'total_cost_sanity_checks_analyst': 0.00028949999999999994, 'total_cost_query_analyst': 0.0007992, 'total_cost_conversation_analyst': 0.0, 'total_cost': 0.0010887, 'total_token_usage_sanity_checks_analyst': 1924, 'total_token_usage_query_analyst': 0, 'total_token_usage_conversation_analyst': 0, 'total_token_usage': 1924}
2025-09-12 16:15:11,858 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 16:15:11,858 [INFO] app.services.data_processing_service: Saving Q&A to CSV: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 16:15:11,860 [DEBUG] app.services.data_processing_service: CSV written to /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/history/results_history_mvp.csv
2025-09-12 16:15:11,860 [DEBUG] app.services.pipeline_orchestrator_service: Formatted response: Voici les meilleurs établissements (rayon utilisé : 0 km)
<br>Aucun établissement privé trouvé.<br>Voici les établissements publics :<br>Institut mutualiste Montsouris, Paris (75): Un établissement Public situé à 0 km. avec une note de 18.63 de 20<br>Hôpital Saint-Louis, Paris (75): Un établissement Public situé à 0 km. avec une note de 18.27 de 20<br>Hôpital européen Georges-Pompidou, Paris (75): Un établissement Public situé à 0 km. avec une note de 18.26 de 20

🔗 Consultez la méthodologie de palmarès hopitaux <a href="https://www.lepoint.fr/sante/la-methodologie-du-palmares-des-hopitaux-et-cliniques-du-point-2024--04-12-2024-2577146_40.php" target="_blank">ici</a>.
2025-09-12 16:15:11,860 [ERROR] app.api.routes: Error processing /ask request: 1 validation error for AskResponse
result
  Input should be a valid string [type=string_type, input_value=('Voici les meilleurs ét...-2024-2577146_40.php"']), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.11/v/string_type
2025-09-12 16:16:30,509 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:16:30,510 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:16:30,510 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:16:30,510 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:16:30,512 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:16:30,512 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:16:30,512 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:16:30,624 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:16:30,624 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:16:30,624 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:16:30,629 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:16:30,629 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:16:30,845 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:16:30,845 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:16:30,845 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:16:30,846 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:16:30,846 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:16:30,846 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:16:30,935 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:16:30,935 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:16:30,936 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:16:30,937 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:16:30,937 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:16:30,938 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:16:30,938 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:16:30,938 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:16:30,938 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:16:30,938 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:16:30,938 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:16:30,939 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:16:30,939 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:16:30,939 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:16:31,016 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:16:31,016 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:16:31,016 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:16:31,018 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:16:31,018 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:16:31,048 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:16:31,050 [INFO] main: Creating FastAPI app
2025-09-12 16:16:31,051 [INFO] main: CORS middleware added
2025-09-12 16:16:31,052 [INFO] main: API router included
2025-09-12 16:16:32,706 [INFO] app.services.pipeline_orchestrator_service: Starting pipeline processing - prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 16:16:32,707 [INFO] app.services.pipeline_orchestrator_service: Resetting PipelineOrchestrator attributes for new query
2025-09-12 16:16:32,707 [INFO] app.services.pipeline_orchestrator_service: Running sanity checks for prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conversation: [], conv_history: 
2025-09-12 16:16:32,707 [DEBUG] app.features.sanity_checks.sanity_checks_analyst: run_checks called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conversation=[], conv_history=, checks_to_run=['conversation_limit', 'message_length', 'message_pertinence']
2025-09-12 16:16:32,707 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst running checks: ['conversation_limit', 'message_length', 'message_pertinence'] for user_input: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 16:16:32,707 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check medical pertinence prompt sent to LLM.
2025-09-12 16:16:32,711 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nÉvaluez si le message suivant a un rapport avec la santé humaine ou les services de soins.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur la santé.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes de discussions médicales.\nATTENTION: Toute question sur la méthodologie, la fréquence de mise à jour, les critères, ou le fonctionnement du classement des hôpitaux doit TOUJOURS être considérée comme pertinente, même si elle ne concerne pas directement une maladie ou un service de soins.\n\nRépondez UNIQUEMENT avec 1 si pertinent, 0 si non pertinent ou 2 si la question concerne la méthodologie de calcul du classement.\n\nExemples pour messages standalone (repondre 1): \n- \'J\'ai un cancer à Paris\' → 1\n- \'Cataracte\' → 1  \n- \'J\'ai mal aux pieds\' → 1\n- \'Les hôpitaux privés sont ils meilleurs que les publiques?\' → 1\n- \'Comment le classement est-il calculé ?\' → 1\n- \'Quels sont les critères du classement ?\' → 1\n- "Quels experts participent à l\'élaboration du classement ?"\' → 1\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\' → 1\n- "Comment sont traitées les données manquantes dans le classement ?"\' → 1\n- "Le classement est-il le même pour toutes les spécialités ?"\' → 1\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\' → 1\n- "Quels sont les changements dans la méthodologie cette année ?"\' → 1\n- "Comment puis-je accéder au détail de la méthodologie ?"\' → 1\n\nExemples pour messages standalone (repondre 0):\n- \'Je mange des frites\' → 0\n- \'Comment faire une tarte aux pommes ?\' → 0\n- \'Comment s\'abonner Le Point ?\' → 0\n- \'Quel est le meilleur restaurant à Paris ?\' → 0\n\n\nExemples de questions qui concernent la méthodologie de classement (repondre 2):\n- "Comment le classement est-il calculé ?"\n- "Quels sont les critères du classement ?" \n- "Pourquoi l\'hôpital X est mieux classé que Y ?"\n- "Comment sont choisis les critères du classement ?"\n- "Qui réalise le classement des hôpitaux ?"\n- "Quelle est la source des données utilisées pour le classement ?"\n- "Le classement prend-il en compte la satisfaction des patients ?"\n- "Comment sont pondérés les différents critères ?"\n- "Est-ce que le classement est mis à jour chaque année ?"\n- "Pourquoi certains hôpitaux ne figurent pas dans le classement ?"\n- "Comment puis-je vérifier la fiabilité du classement ?"\n- "Quels experts participent à l\'élaboration du classement ?"\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\n- "Comment sont traitées les données manquantes dans le classement ?"\n- "Le classement est-il le même pour toutes les spécialités ?"\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\n- "Quels sont les changements dans la méthodologie cette année ?"\n- "Comment puis-je accéder au détail de la méthodologie ?"\n\nExemples pour messages avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique montrant une discussion sur les hôpitaux, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur la cardiologie, \'Merci\' → 1 (remerciement dans contexte médical)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n- Même avec contexte médical, \'Parle-moi de football\' → 0 (hors-sujet)\n- Avec historique sur les classements, "Comment sont déterminés les scores ?" → 2 (question sur la méthodologie de classement)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:32,741 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:32,742 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-09-12 16:16:32,781 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x117ad7a10>
2025-09-12 16:16:32,781 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x11788fd10> server_hostname='api.openai.com' timeout=None
2025-09-12 16:16:32,804 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x117b0df90>
2025-09-12 16:16:32,804 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:32,804 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:32,804 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:32,805 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:32,805 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:33,417 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'429'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'443'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9992'), (b'x-ratelimit-remaining-tokens', b'198878'), (b'x-ratelimit-reset-requests', b'1m3.09s'), (b'x-ratelimit-reset-tokens', b'336ms'), (b'x-request-id', b'req_d33b22887f3643e185c4015415a1b8f1'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=rE3f84h0ffBn.ES4vhWB2eG8EBh42bZ8Sa6F6JPF0tg-1757686593-1.0.1.1-n7yH8B4IU.FsOkRQRbNWelVRa.7S8TLRDtQphQtP9.7lKeX9rxZKGCCVPUdsRrmcDNwa4A1dcZQDvYdXfSnuZYvC4Ap_jfEzVDqk1AkIFts; path=/; expires=Fri, 12-Sep-25 14:46:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=.w.6gxgZPDWHTTx_8vjWcIsOszXE6D_4H0cbE6o_49o-1757686593526-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e005f5cf5870e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:33,418 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:33,419 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:33,422 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:33,422 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:33,422 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:33,422 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 12 Sep 2025 14:16:33 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'le-point-hv3izr'), ('openai-processing-ms', '429'), ('openai-project', 'proj_auvPnKXq8lce0dksWKRj2pvx'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '443'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9992'), ('x-ratelimit-remaining-tokens', '198878'), ('x-ratelimit-reset-requests', '1m3.09s'), ('x-ratelimit-reset-tokens', '336ms'), ('x-request-id', 'req_d33b22887f3643e185c4015415a1b8f1'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=rE3f84h0ffBn.ES4vhWB2eG8EBh42bZ8Sa6F6JPF0tg-1757686593-1.0.1.1-n7yH8B4IU.FsOkRQRbNWelVRa.7S8TLRDtQphQtP9.7lKeX9rxZKGCCVPUdsRrmcDNwa4A1dcZQDvYdXfSnuZYvC4Ap_jfEzVDqk1AkIFts; path=/; expires=Fri, 12-Sep-25 14:46:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=.w.6gxgZPDWHTTx_8vjWcIsOszXE6D_4H0cbE6o_49o-1757686593526-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '97e005f5cf5870e7-MRS'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-12 16:16:33,422 [DEBUG] openai._base_client: request_id: req_d33b22887f3643e185c4015415a1b8f1
2025-09-12 16:16:33,429 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_medical_pertinence' successful: {'prompt_tokens': 1112, 'completion_tokens': 1, 'total_tokens': 1113}, cost=0.00016739999999999998
2025-09-12 16:16:33,429 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for medical pertinence:
1
2025-09-12 16:16:33,429 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed medical pertinence value: 1 (type: <class 'int'>)
2025-09-12 16:16:33,429 [DEBUG] app.features.sanity_checks.message_pertinence_check: medical_pertinence_result: {'result': 1, 'cost': 0.00016739999999999998, 'token_usage': 1113}
2025-09-12 16:16:33,430 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check chatbot pertinence prompt sent to LLM.
2025-09-12 16:16:33,433 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nVérifiez si cette question concerne le classement des hôpitaux.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur les classements d\'hôpitaux.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes.\n\nRépondez UNIQUEMENT avec:\n- 1 si la question est pertinente pour le chatbot (classement, recherche d\'établissement, etc.)\n- 0 si la question n\'est pas pertinente\n\nUne question est pertinente si elle concerne au moins un des cas suivants:\n- Une maladie, un symptôme ou une spécialité médicale  \n- Le classement des hôpitaux et cliniques  \n- La recherche d\'un hôpital, d\'une clinique ou d\'un service médical  \n- Une question de suivi sur les secteurs public/privé des hôpitaux\n\nExemples de questions pertinentes pour messages standalone (repondre 1):  \n- Quel est la meilleur clinique de France ?\n- Conseille moi un hôpital à Lyon \n- Je chercher un service de pneumologie\n- Où faire soigner mon glaucome ? \n- Je veux corriger mon audition\n- Il y a fréquemment du sang dans mes urines. Conseille-moi un hôpital. \n- Je veux cherche à faire soigner mes troubles bipôlaires\n- Est-ce que l\'Institut mutualiste Montsouris est bon ?\n- Y a-t-il des hôpitaux privés avec un service de cardiologie interventionnelle ?\n\nExemples de questions non pertinentes pour messages standalone (repondre 0):  \n- Pourquoi les hôpitaux sont-ils en crise ?  #Il s\'agit d\'une demande d\'information qui n\'est pas dans le cadre direct de la recherche d\'un établissement de soin\n- Dois-je prendre du paracétamol pour ma fièvre ? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n- Puis-je perdre la vue si j\'ai un glaucome? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n\n\n\nExemples avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique sur les hôpitaux parisiens, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur les classements, \'Combien coûte une consultation ?\' → 0 (question sur les coûts, pas sur les classements)\n- Avec historique sur la recherche d\'hôpital, \'Merci beaucoup\' → 1 (remerciement dans contexte de recherche d\'hôpital)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:33,434 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:33,434 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:33,435 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:33,435 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:33,435 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:33,435 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:34,327 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'702'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'720'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9991'), (b'x-ratelimit-remaining-tokens', b'199169'), (b'x-ratelimit-reset-requests', b'1m11.097s'), (b'x-ratelimit-reset-tokens', b'249ms'), (b'x-request-id', b'req_d28774819a1446b4bbad9543228ae175'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e005f9ba8b70e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:34,327 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:34,328 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:34,332 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:34,332 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:34,332 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:34,332 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:34 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '702', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '720', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9991', 'x-ratelimit-remaining-tokens': '199169', 'x-ratelimit-reset-requests': '1m11.097s', 'x-ratelimit-reset-tokens': '249ms', 'x-request-id': 'req_d28774819a1446b4bbad9543228ae175', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e005f9ba8b70e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:34,332 [DEBUG] openai._base_client: request_id: req_d28774819a1446b4bbad9543228ae175
2025-09-12 16:16:34,333 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_chatbot_pertinence' successful: {'prompt_tokens': 810, 'completion_tokens': 1, 'total_tokens': 811}, cost=0.00012209999999999999
2025-09-12 16:16:34,333 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for chatbot pertinence:
1
2025-09-12 16:16:34,333 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed chatbot pertinence value: 1 (type: <class 'int'>)
2025-09-12 16:16:34,334 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst completed checks. All passed: True, Total cost: 0.00028949999999999994, Total tokens: 1924
2025-09-12 16:16:34,334 [INFO] app.features.sanity_checks.sanity_checks_analyst: Sanity check results: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 16:16:34,334 [INFO] app.services.pipeline_orchestrator_service: Sanity checks result: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 16:16:34,334 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', detected_specialty='None', conv_history=''
2025-09-12 16:16:34,334 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 16:16:34,334 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 16:16:34,334 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 16:16:34,334 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 16:16:34,552 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 16:16:34,552 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history: 
2025-09-12 16:16:34,552 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'
2025-09-12 16:16:34,555 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:34,556 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:34,556 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:34,556 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:34,557 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:34,557 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:34,557 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:35,074 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'365'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'382'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9991'), (b'x-ratelimit-remaining-tokens', b'199553'), (b'x-ratelimit-reset-requests', b'1m9.995s'), (b'x-ratelimit-reset-tokens', b'134ms'), (b'x-request-id', b'req_b66ee65a65d547d49f7e7fbeb796ea9b'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e00600b85b70e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:35,075 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:35,075 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:35,085 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:35,085 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:35,086 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:35,086 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '365', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '382', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9991', 'x-ratelimit-remaining-tokens': '199553', 'x-ratelimit-reset-requests': '1m9.995s', 'x-ratelimit-reset-tokens': '134ms', 'x-request-id': 'req_b66ee65a65d547d49f7e7fbeb796ea9b', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e00600b85b70e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:35,086 [DEBUG] openai._base_client: request_id: req_b66ee65a65d547d49f7e7fbeb796ea9b
2025-09-12 16:16:35,087 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 431, 'completion_tokens': 5, 'total_tokens': 436}, cost=6.765e-05
2025-09-12 16:16:35,087 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer de la vessie, method: llm
2025-09-12 16:16:35,088 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer de la vessie', 'detection_method': 'llm', 'cost': 6.765e-05, 'token_usage': 0}
2025-09-12 16:16:35,088 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', conv_history: ''
2025-09-12 16:16:35,090 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:35,091 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:35,091 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:35,092 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:35,092 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:35,092 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:35,092 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:35,402 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'156'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'167'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9990'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m18.096s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_a05dedf8c259423190aa026e26c83905'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e006041bc870e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:35,402 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:35,402 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:35,405 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:35,405 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:35,405 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:35,405 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '156', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '167', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9990', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m18.096s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_a05dedf8c259423190aa026e26c83905', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e006041bc870e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:35,405 [DEBUG] openai._base_client: request_id: req_a05dedf8c259423190aa026e26c83905
2025-09-12 16:16:35,406 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 16:16:35,408 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:35,409 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:35,409 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:35,410 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:35,410 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:35,410 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:35,410 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:35,955 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'349'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'369'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'1m26.404s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_e0b8f7a715504cb6a895d2cc01364d97'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e006061da470e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:35,956 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:35,956 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:35,956 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:35,957 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:35,957 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:35,957 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '349', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '369', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9989', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '1m26.404s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_e0b8f7a715504cb6a895d2cc01364d97', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e006061da470e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:35,957 [DEBUG] openai._base_client: request_id: req_e0b8f7a715504cb6a895d2cc01364d97
2025-09-12 16:16:35,958 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 16:16:35,958 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 16:16:35,958 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'status_code': 3, 'token_usage': {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}}
2025-09-12 16:16:35,958 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history=
2025-09-12 16:16:35,963 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:35,963 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:35,964 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:35,964 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:35,964 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:35,965 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:35,965 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:36,306 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'159'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'173'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m34.483s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_e5b9cc83a75d4263835cb3cba61bd4b7'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e00609887670e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:36,307 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:36,307 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:36,310 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:36,311 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:36,311 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:36,312 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '159', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '173', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9989', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m34.483s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_e5b9cc83a75d4263835cb3cba61bd4b7', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e00609887670e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:36,314 [DEBUG] openai._base_client: request_id: req_e5b9cc83a75d4263835cb3cba61bd4b7
2025-09-12 16:16:36,314 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 16:16:36,318 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:36,319 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:36,320 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:36,320 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:36,320 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:36,320 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:36,320 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:36,734 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'266'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'279'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9987'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'1m51.438s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_d89d0fbe9c6d4dfa8a2b4765b50433c0'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e0060bca4670e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:36,735 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:36,736 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:36,736 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:36,736 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:36,736 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:36,736 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '266', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '279', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9987', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '1m51.438s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_d89d0fbe9c6d4dfa8a2b4765b50433c0', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e0060bca4670e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:36,737 [DEBUG] openai._base_client: request_id: req_d89d0fbe9c6d4dfa8a2b4765b50433c0
2025-09-12 16:16:36,737 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 16:16:36,737 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 16:16:36,738 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 3, 'city_detected': True, 'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'token_usage': 318}
2025-09-12 16:16:36,738 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?' with conv_history: ''
2025-09-12 16:16:36,740 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:36,742 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:36,743 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:36,743 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:36,744 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:36,744 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:36,744 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:37,414 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'478'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'501'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'198986'), (b'x-ratelimit-reset-requests', b'1m34.462s'), (b'x-ratelimit-reset-tokens', b'304ms'), (b'x-request-id', b'req_6338f5a9844a438b831355d5772ef42d'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e0060e6cd470e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:37,415 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:37,415 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:37,419 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:37,419 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:37,419 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:37,419 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '478', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '501', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9989', 'x-ratelimit-remaining-tokens': '198986', 'x-ratelimit-reset-requests': '1m34.462s', 'x-ratelimit-reset-tokens': '304ms', 'x-request-id': 'req_6338f5a9844a438b831355d5772ef42d', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e0060e6cd470e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:37,420 [DEBUG] openai._base_client: request_id: req_6338f5a9844a438b831355d5772ef42d
2025-09-12 16:16:37,420 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}, cost=0.00017295
2025-09-12 16:16:37,420 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 16:16:37,421 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 16:16:37,421 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': [], 'intent': 'none'}
2025-09-12 16:16:37,421 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: [], intent: none, cost: 0.00017295, token_usage: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}
2025-09-12 16:16:37,421 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | []
2025-09-12 16:16:37,421 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=[] and institution_list length=553)
2025-09-12 16:16:37,421 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: []
2025-09-12 16:16:37,421 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: none
2025-09-12 16:16:37,421 [INFO] app.features.query_analysis.institution_names.institution_names_validation: No specific institution detected
2025-09-12 16:16:37,421 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': None, 'institution_name_mentioned': False, 'error': 'No institution detected', 'intent': 'none', 'detection_method': 'llm', 'cost': 0.00017295, 'token_usage': 1108}
2025-09-12 16:16:37,424 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:37,424 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:37,425 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:37,425 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:37,425 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:37,425 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:37,425 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:37,757 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'160'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'174'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9986'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m58.961s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_a9c8bb79791c47668739cf8e67bdb3ba'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e00612aff170e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:37,758 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:37,758 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:37,759 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:37,759 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:37,759 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:37,759 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '160', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '174', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9986', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m58.961s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_a9c8bb79791c47668739cf8e67bdb3ba', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e00612aff170e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:37,759 [DEBUG] openai._base_client: request_id: req_a9c8bb79791c47668739cf8e67bdb3ba
2025-09-12 16:16:37,760 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}, cost=3.27e-05
2025-09-12 16:16:37,760 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.27e-05, {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}
2025-09-12 16:16:37,760 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.27e-05, 'token_usage': 215}
2025-09-12 16:16:37,763 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:37,764 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:37,764 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:37,764 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:37,764 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:37,764 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:37,764 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:38,290 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'339'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'361'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9985'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'2m8.013s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_2598d54865374accbcfcc1bbd05b6d45'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e00614c99670e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:38,291 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:38,291 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:38,300 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:38,300 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:38,301 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:38,301 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:38 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '339', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '361', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9985', 'x-ratelimit-remaining-tokens': '199678', 'x-ratelimit-reset-requests': '2m8.013s', 'x-ratelimit-reset-tokens': '96ms', 'x-request-id': 'req_2598d54865374accbcfcc1bbd05b6d45', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e00614c99670e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:38,301 [DEBUG] openai._base_client: request_id: req_2598d54865374accbcfcc1bbd05b6d45
2025-09-12 16:16:38,302 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}, cost=4.71e-05
2025-09-12 16:16:38,302 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.71e-05, {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}
2025-09-12 16:16:38,303 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.71e-05, 'token_usage': 311}
2025-09-12 16:16:38,303 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer de la vessie, city=Paris, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 16:16:38,303 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.765e-05, city_cost=7.86e-05, institution_names_cost=0.00017295, institution_type_cost=3.27e-05, number_institutions_cost=4.71e-05
2025-09-12 16:16:38,303 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=318, institution_names_tokens=1108, institution_type_tokens=215, number_institutions_tokens=311
2025-09-12 16:16:38,303 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.86e-05, 'city_token_usage': 318, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017295, 'institution_names_token_usage': 1108, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.27e-05, 'institution_type_token_usage': 215, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.765e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.71e-05, 'number_institutions_token_usage': 311, 'total_cost': 0.000399, 'total_token_usage': 1952}
2025-09-12 16:16:38,304 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer de la vessie', city='Paris', city_detected=True, institution_type='aucune correspondance', number_institutions=3, institution_names=None, institution_name_mentioned=False
2025-09-12 16:16:38,304 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer de la vessie'
2025-09-12 16:16:38,304 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: 'Paris'
2025-09-12 16:16:38,304 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: True
2025-09-12 16:16:38,304 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 16:16:38,304 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 3
2025-09-12 16:16:38,304 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: []
2025-09-12 16:16:38,304 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 16:16:38,304 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'none'
2025-09-12 16:16:38,304 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: False
2025-09-12 16:16:38,343 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 16:16:38,344 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 16:16:38,577 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 16:16:38,577 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 16:16:38,577 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer de la vessie'
2025-09-12 16:16:38,577 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: 'Paris'
2025-09-12 16:16:38,578 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: True
2025-09-12 16:16:38,578 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 16:16:38,578 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: []
2025-09-12 16:16:38,578 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: False
2025-09-12 16:16:38,578 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 3
2025-09-12 16:16:38,578 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer de la vessie, city: Paris, institution_type: aucune correspondance, institution: [], institution_name_mentioned: False
2025-09-12 16:16:38,578 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 16:16:38,578 [DEBUG] app.services.pipeline_orchestrator_service: [CITY DETECTION] Detected city: 'Paris', city_detected: True, DataProcessor.city: 'Paris', DataProcessor.city_detected: True
2025-09-12 16:16:38,578 [DEBUG] app.services.pipeline_orchestrator_service: Calling build_ranking_dataframe_with_distances
2025-09-12 16:16:38,578 [INFO] app.services.pipeline_orchestrator_service: Building ranking DataFrame with distances: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', excel_path='/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx', detected_specialty='cancer de la vessie'
2025-09-12 16:16:38,579 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', detected_specialty='cancer de la vessie', conv_history='None'
2025-09-12 16:16:38,579 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 16:16:38,579 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 16:16:38,579 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 16:16:38,579 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 16:16:38,773 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 16:16:38,773 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history: 
2025-09-12 16:16:38,773 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'
2025-09-12 16:16:38,776 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:38,776 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:38,777 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:38,777 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:38,777 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:38,777 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:38,778 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:39,234 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'293'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'309'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9983'), (b'x-ratelimit-remaining-tokens', b'199553'), (b'x-ratelimit-reset-requests', b'2m23.524s'), (b'x-ratelimit-reset-tokens', b'134ms'), (b'x-request-id', b'req_d3657d90a43e42328ee6063f4f3b768b'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e0061b2e9870e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:39,254 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:39,254 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:39,254 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:39,255 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:39,255 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:39,255 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '293', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '309', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9983', 'x-ratelimit-remaining-tokens': '199553', 'x-ratelimit-reset-requests': '2m23.524s', 'x-ratelimit-reset-tokens': '134ms', 'x-request-id': 'req_d3657d90a43e42328ee6063f4f3b768b', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e0061b2e9870e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:39,255 [DEBUG] openai._base_client: request_id: req_d3657d90a43e42328ee6063f4f3b768b
2025-09-12 16:16:39,256 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 431, 'completion_tokens': 5, 'total_tokens': 436}, cost=6.765e-05
2025-09-12 16:16:39,256 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer de la vessie, method: llm
2025-09-12 16:16:39,256 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer de la vessie', 'detection_method': 'llm', 'cost': 6.765e-05, 'token_usage': 0}
2025-09-12 16:16:39,256 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', conv_history: ''
2025-09-12 16:16:39,259 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:39,259 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:39,259 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:39,260 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:39,260 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:39,260 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:39,260 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:39,657 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'208'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'237'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9983'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'2m23.031s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_5dda6af66b0d455e9a5625f1e6856200'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e0061e28ba70e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:39,658 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:39,658 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:39,664 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:39,664 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:39,664 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:39,665 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '208', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '237', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9983', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '2m23.031s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_5dda6af66b0d455e9a5625f1e6856200', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e0061e28ba70e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:39,665 [DEBUG] openai._base_client: request_id: req_5dda6af66b0d455e9a5625f1e6856200
2025-09-12 16:16:39,665 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 16:16:39,669 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:39,669 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:39,670 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:39,670 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:39,670 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:39,670 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:39,670 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:40,178 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'337'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'350'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9982'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'2m31.268s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_3a49967edcc9497582c522381a2a1938'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e00620babf70e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:40,179 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:40,179 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:40,182 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:40,182 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:40,182 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:40,182 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '337', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '350', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9982', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '2m31.268s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_3a49967edcc9497582c522381a2a1938', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e00620babf70e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:40,183 [DEBUG] openai._base_client: request_id: req_3a49967edcc9497582c522381a2a1938
2025-09-12 16:16:40,183 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 16:16:40,183 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 16:16:40,183 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'status_code': 3, 'token_usage': {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}}
2025-09-12 16:16:40,184 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history=
2025-09-12 16:16:40,186 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:40,187 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:40,187 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:40,187 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:40,187 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:40,187 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:40,187 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:40,504 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'176'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'189'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9981'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'2m39.412s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_7ff1569531f34f5e8120486dc54e4fcf'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e00623fd3470e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:40,505 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:40,505 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:40,512 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:40,512 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:40,512 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:40,512 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '176', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '189', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9981', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '2m39.412s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_7ff1569531f34f5e8120486dc54e4fcf', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e00623fd3470e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:40,512 [DEBUG] openai._base_client: request_id: req_7ff1569531f34f5e8120486dc54e4fcf
2025-09-12 16:16:40,513 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 16:16:40,515 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:40,516 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:40,516 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:40,517 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:40,517 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:40,517 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:40,517 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:41,074 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'377'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'400'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9981'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'2m39.821s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_d115054d74f74320b4435e75933c5e2d'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e006260ed670e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:41,075 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:41,075 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:41,081 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:41,081 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:41,081 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:41,082 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '377', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '400', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9981', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '2m39.821s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_d115054d74f74320b4435e75933c5e2d', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e006260ed670e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:41,082 [DEBUG] openai._base_client: request_id: req_d115054d74f74320b4435e75933c5e2d
2025-09-12 16:16:41,083 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 16:16:41,083 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 16:16:41,083 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 3, 'city_detected': True, 'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'token_usage': 318}
2025-09-12 16:16:41,083 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?' with conv_history: ''
2025-09-12 16:16:41,086 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:41,087 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:41,087 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:41,088 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:41,088 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:41,088 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:41,088 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:41,897 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'588'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'644'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9979'), (b'x-ratelimit-remaining-tokens', b'198986'), (b'x-ratelimit-reset-requests', b'2m55.742s'), (b'x-ratelimit-reset-tokens', b'304ms'), (b'x-request-id', b'req_5a75c5923f374489ba267744efedd177'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e00629997a70e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:41,897 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:41,898 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:41,898 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:41,898 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:41,898 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:41,898 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '588', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '644', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9979', 'x-ratelimit-remaining-tokens': '198986', 'x-ratelimit-reset-requests': '2m55.742s', 'x-ratelimit-reset-tokens': '304ms', 'x-request-id': 'req_5a75c5923f374489ba267744efedd177', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e00629997a70e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:41,898 [DEBUG] openai._base_client: request_id: req_5a75c5923f374489ba267744efedd177
2025-09-12 16:16:41,899 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}, cost=0.00017295
2025-09-12 16:16:41,899 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 16:16:41,899 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{\n  "institutions": [],\n  "intent": "none"\n}'
2025-09-12 16:16:41,899 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': [], 'intent': 'none'}
2025-09-12 16:16:41,899 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: [], intent: none, cost: 0.00017295, token_usage: {'prompt_tokens': 1093, 'completion_tokens': 15, 'total_tokens': 1108}
2025-09-12 16:16:41,900 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | []
2025-09-12 16:16:41,900 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=[] and institution_list length=553)
2025-09-12 16:16:41,900 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: []
2025-09-12 16:16:41,900 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: none
2025-09-12 16:16:41,900 [INFO] app.features.query_analysis.institution_names.institution_names_validation: No specific institution detected
2025-09-12 16:16:41,900 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': None, 'institution_name_mentioned': False, 'error': 'No institution detected', 'intent': 'none', 'detection_method': 'llm', 'cost': 0.00017295, 'token_usage': 1108}
2025-09-12 16:16:41,902 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:41,903 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:41,903 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:41,904 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:41,904 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:41,904 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:41,904 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:42,294 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'203'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'223'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9978'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'3m4.355s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_1ab2600c6afc478eb66c39cf9ffea7a2'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e0062eadde70e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:42,294 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:42,294 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:42,295 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:42,295 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:42,295 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:42,295 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '203', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '223', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9978', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '3m4.355s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_1ab2600c6afc478eb66c39cf9ffea7a2', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e0062eadde70e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:42,295 [DEBUG] openai._base_client: request_id: req_1ab2600c6afc478eb66c39cf9ffea7a2
2025-09-12 16:16:42,296 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}, cost=3.27e-05
2025-09-12 16:16:42,296 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.27e-05, {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}
2025-09-12 16:16:42,297 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.27e-05, 'token_usage': 215}
2025-09-12 16:16:42,299 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:16:42,300 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:16:42,300 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:16:42,300 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:16:42,300 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:16:42,301 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:16:42,301 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:16:42,777 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:16:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'290'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'310'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9977'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'3m11.833s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_188e7d4b30e54eb89334b1819867d980'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e006312ff870e7-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:16:42,777 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:16:42,777 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:16:42,782 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:16:42,782 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:16:42,782 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:16:42,782 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:16:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '290', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '310', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9977', 'x-ratelimit-remaining-tokens': '199678', 'x-ratelimit-reset-requests': '3m11.833s', 'x-ratelimit-reset-tokens': '96ms', 'x-request-id': 'req_188e7d4b30e54eb89334b1819867d980', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e006312ff870e7-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:16:42,783 [DEBUG] openai._base_client: request_id: req_188e7d4b30e54eb89334b1819867d980
2025-09-12 16:16:42,783 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}, cost=4.71e-05
2025-09-12 16:16:42,783 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.71e-05, {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}
2025-09-12 16:16:42,784 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.71e-05, 'token_usage': 311}
2025-09-12 16:16:42,784 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer de la vessie, city=Paris, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 16:16:42,784 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.765e-05, city_cost=7.86e-05, institution_names_cost=0.00017295, institution_type_cost=3.27e-05, number_institutions_cost=4.71e-05
2025-09-12 16:16:42,784 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=318, institution_names_tokens=1108, institution_type_tokens=215, number_institutions_tokens=311
2025-09-12 16:16:42,784 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.86e-05, 'city_token_usage': 318, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017295, 'institution_names_token_usage': 1108, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.27e-05, 'institution_type_token_usage': 215, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.765e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.71e-05, 'number_institutions_token_usage': 311, 'total_cost': 0.000399, 'total_token_usage': 1952}
2025-09-12 16:16:42,784 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer de la vessie', city='Paris', city_detected=True, institution_type='aucune correspondance', number_institutions=3, institution_names=None, institution_name_mentioned=False
2025-09-12 16:16:42,784 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer de la vessie'
2025-09-12 16:16:42,784 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: 'Paris'
2025-09-12 16:16:42,784 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: True
2025-09-12 16:16:42,784 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 16:16:42,784 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 3
2025-09-12 16:16:42,784 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: []
2025-09-12 16:16:42,785 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 16:16:42,785 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'none'
2025-09-12 16:16:42,785 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: False
2025-09-12 16:16:42,817 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 16:16:42,817 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 16:16:42,980 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 16:16:42,980 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 16:16:42,980 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer de la vessie'
2025-09-12 16:16:42,980 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: 'Paris'
2025-09-12 16:16:42,980 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: True
2025-09-12 16:16:42,980 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 16:16:42,980 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: []
2025-09-12 16:16:42,980 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: False
2025-09-12 16:16:42,980 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 3
2025-09-12 16:16:42,981 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer de la vessie, city: Paris, institution_type: aucune correspondance, institution: [], institution_name_mentioned: False
2025-09-12 16:16:42,981 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 16:16:42,981 [INFO] app.services.data_processing_service: generate_data_response called
2025-09-12 16:16:42,981 [DEBUG] app.services.data_processing_service: Extracted values - specialty: 'cancer de la vessie', institution_type: 'aucune correspondance', city: 'Paris'
2025-09-12 16:16:42,981 [DEBUG] app.services.data_processing_service: No institution type match found, loading by specialty only
2025-09-12 16:16:42,981 [INFO] app.services.data_processing_service: Filtering ranking by criteria: specialty='cancer de la vessie', institution_type='None'
2025-09-12 16:16:42,981 [DEBUG] app.services.data_processing_service: Filtering ranking data - specialty: 'cancer de la vessie', institution_type: 'None'
2025-09-12 16:16:42,981 [DEBUG] app.services.data_processing_service: Specialty type: <class 'str'>, length: 19
2025-09-12 16:16:42,981 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer de la vessie
2025-09-12 16:16:42,983 [DEBUG] app.services.data_processing_service: All normalized specialties in DataFrame: ['ablation des varices' 'accidents vasculaires cerebraux'
 'accouchements a risques' 'accouchements normaux'
 'adenome de la prostate' 'amygdales et vegetations'
 'angioplastie coronaire' 'appendicite' 'arthrose de la main' 'audition'
 'calculs urinaires' "cancer de l'estomac et de l'œsophage"
 "cancer de l'ovaire" "cancer de l'uterus" 'cancer de la prostate'
 'cancer de la thyroide' 'cancer de la vessie'
 "cancer des os de l'enfant et de l'adolescent"
 "cancer du colon ou de l'intestin" 'cancer du foie' 'cancer du pancreas'
 'cancer du poumon' 'cancer du rein' 'cancer du sein' 'cancer orl'
 'cancers de la peau' 'cardiologie interventionnelle' 'cataracte'
 'chirurgie cardiaque adulte' 'chirurgie cardiaque pediatrique'
 "chirurgie de l'epaule" "chirurgie de l'obesite"
 'chirurgie de la cheville' 'chirurgie de la cornee'
 'chirurgie dentaire et orale de l’adulte'
 'chirurgie dentaire et orale de l’enfant et de l’adolescent'
 'chirurgie des arteres' "chirurgie des cancers osseux de l'adulte"
 'chirurgie des carotides' 'chirurgie des sarcomes des tissus mous'
 "chirurgie des testicules de l'adulte"
 "chirurgie des testicules de l'enfant et de l'adolescent"
 'chirurgie du canal carpien' "chirurgie du dos de l'adulte"
 "chirurgie du dos de l'enfant et de l'adolescent"
 'chirurgie du nez et des sinus' 'chirurgie du pied' 'chirurgie du rectum'
 'chirurgie maxillo-faciale' 'depression' "diabete de l'adulte"
 "diabete de l'enfant et de l'adolescent" 'endometriose'
 "epilepsie de l'adulte" "epilepsie de l'enfant et de l'adolescent"
 'fibrome uterin' 'glandes salivaires' 'glaucome' "hernies de l'abdomen"
 'hypertension arterielle' 'infarctus du myocarde'
 'insuffisance cardiaque' "leucemie de l'adulte"
 "leucemie de l'enfant et de l'adolescent" 'ligaments du genou'
 "lymphome-myelome de l'adulte" 'maladie de parkinson'
 "maladies inflammatoires chroniques de l'intestin (mici)"
 'medecine vasculaire' 'pneumologie' 'proctologie' 'prothese de genou'
 'prothese de hanche' 'retine' 'schizophrenie' 'sclerose en plaques'
 'stimulateurs cardiaques' 'strabisme'
 'stress post-traumatique de l’adulte' 'troubles bipolaires'
 "tumeurs du cerveau de l'adulte"
 "tumeurs du cerveau de l'enfant et de l'adolescent" 'urgences de la main'
 'vesicule biliaire']
2025-09-12 16:16:42,983 [DEBUG] app.services.data_processing_service: Normalized specialty from query: 'cancer de la vessie'
2025-09-12 16:16:42,984 [DEBUG] app.services.data_processing_service: Normalized specialty from query: ''cancer de la vessie''
2025-09-12 16:16:42,984 [DEBUG] app.services.data_processing_service: Found 2 rows matching single specialty 'cancer de la vessie' (normalized: 'cancer de la vessie')
2025-09-12 16:16:42,985 [DEBUG] app.services.data_processing_service: Specialties found after specialty filtering: ['Cancer de la vessie']
2025-09-12 16:16:42,985 [INFO] app.services.data_processing_service: generate_response_links called with matching_rows: <class 'pandas.core.frame.DataFrame'>
2025-09-12 16:16:42,985 [INFO] app.services.data_processing_service: Generating ranking links
2025-09-12 16:16:42,985 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer de la vessie
2025-09-12 16:16:42,985 [DEBUG] app.services.data_processing_service: Generating links for 2 matching rows
2025-09-12 16:16:42,985 [DEBUG] app.services.data_processing_service: Mapping institution type for URL: Public
2025-09-12 16:16:42,985 [DEBUG] app.services.data_processing_service: Generating web link for specialty 'Cancer de la vessie' and institution_type 'public'
2025-09-12 16:16:42,986 [DEBUG] app.services.data_processing_service: Mapping institution type for URL: Privé
2025-09-12 16:16:42,986 [DEBUG] app.services.data_processing_service: Generating web link for specialty 'Cancer de la vessie' and institution_type 'prive'
2025-09-12 16:16:42,986 [INFO] app.services.data_processing_service: Generated ranking links: ['https://www.lepoint.fr/hopitaux/classements/cancer-de-la-vessie-public.php', 'https://www.lepoint.fr/hopitaux/classements/cancer-de-la-vessie-prive.php']
2025-09-12 16:16:42,986 [INFO] app.services.data_processing_service: load_excel_sheets called with matching_rows of length: 2
2025-09-12 16:16:42,986 [DEBUG] app.services.data_processing_service: Loading sheet: 'CANCER_VESSIE-Public' for category: 'Public'
2025-09-12 16:16:43,147 [DEBUG] app.services.data_processing_service: Sheet 'CANCER_VESSIE-Public' loaded successfully with 40 rows
2025-09-12 16:16:43,147 [DEBUG] app.services.data_processing_service: Loading sheet: 'CANCER_VESSIE-Privé' for category: 'Privé'
2025-09-12 16:16:43,297 [DEBUG] app.services.data_processing_service: Sheet 'CANCER_VESSIE-Privé' loaded successfully with 20 rows
2025-09-12 16:16:43,298 [DEBUG] app.services.data_processing_service: Concatenating 2 dataframes
2025-09-12 16:16:43,298 [INFO] app.services.data_processing_service: Successfully loaded 2 sheets, total rows: 60
2025-09-12 16:16:43,298 [INFO] app.services.data_processing_service: Loaded specialty DataFrame
2025-09-12 16:16:43,298 [INFO] app.services.pipeline_orchestrator_service: Extracting hospital locations and calculating distances
2025-09-12 16:16:43,299 [INFO] app.services.data_processing_service: extract_local_hospitals called with df: <class 'NoneType'>
2025-09-12 16:16:43,299 [INFO] app.services.data_processing_service: Merging ranking data with hospital location data
2025-09-12 16:16:43,302 [DEBUG] app.services.data_processing_service: Merged DataFrame shape (with cities): (60, 6)
2025-09-12 16:16:43,302 [INFO] app.services.data_processing_service: get_df_with_distances called
2025-09-12 16:16:43,302 [INFO] app.services.data_processing_service: Calculating distances from query city: Paris
2025-09-12 16:16:43,346 [DEBUG] urllib3.util.retry: Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-09-12 16:16:43,346 [DEBUG] urllib3.util.retry: Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-09-12 16:16:43,346 [DEBUG] geopy: Nominatim.geocode: https://nominatim.openstreetmap.org/search?q=Paris&format=json&limit=1
2025-09-12 16:16:43,347 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): nominatim.openstreetmap.org:443
2025-09-12 16:16:43,826 [DEBUG] urllib3.connectionpool: https://nominatim.openstreetmap.org:443 "GET /search?q=Paris&format=json&limit=1 HTTP/1.1" 200 444
2025-09-12 16:16:43,829 [DEBUG] app.services.data_processing_service: Query city coordinates: (48.8534951, 2.3483915)
2025-09-12 16:16:43,879 [DEBUG] app.services.data_processing_service: DataFrame with distances shape after filtering: (60, 7)
2025-09-12 16:16:43,879 [DEBUG] app.services.data_processing_service: Distance column values after filtering: [397.16421568228793, 664.5671165057212, 415.42021849676877, 454.6232692587221, 628.9272762614704, 372.76695725398446, 187.64257370100052, 346.44804063177855, 204.9061679313438, 345.3834222363833, 594.4783082353262, 409.73559161431035, 498.73884900510325, 308.98876258531186, 587.6020165018895, 201.6803175167258, 281.9666122654773, 113.41737487155112, 264.6693413955004, 578.6238060003169, 16.726792716267678, 587.6020165018895, 440.6409364823054, 398.5542834873119, 498.73884900510325, 547.7564737199306, 264.6693413955004, 684.864748960447, 441.30736307891743, 382.66401151108664, 409.73559161431035, 481.9811724587299, 0.0, 4.592712151579527, 9.217278413662884, 11.453781374536742, 364.4347650853049, 0.0, 282.41401459727837, 285.7997399851394, 0.0, 0.0, 660.3147713621365, 0.0, 0.0, 660.3147713621365, 204.9061679313438, 638.1373345264166, 378.3676161619013, 380.29745819875353, 660.3147713621365, 0.0, 498.73884900510325, 687.7062403382804, 613.2211062491715, 506.307887243086, 345.3834222363833, 652.4186260952922, 588.3439902102477, 578.6238060003169]
2025-09-12 16:16:43,879 [DEBUG] app.services.pipeline_orchestrator_service: build_ranking_dataframe_with_distances returned DataFrame: <class 'pandas.core.frame.DataFrame'>
2025-09-12 16:16:43,879 [DEBUG] app.services.pipeline_orchestrator_service: Checking if DataFrame is None
2025-09-12 16:16:43,880 [DEBUG] app.services.pipeline_orchestrator_service: Retrieved DataFrame shape: (60, 7)
2025-09-12 16:16:43,880 [DEBUG] app.services.pipeline_orchestrator_service: Checking for geolocation API errors
2025-09-12 16:16:43,880 [DEBUG] app.services.pipeline_orchestrator_service: Getting ranking link for UI
2025-09-12 16:16:43,880 [DEBUG] app.services.pipeline_orchestrator_service: Checking for specialty_ranking_unavailable
2025-09-12 16:16:43,880 [DEBUG] app.services.pipeline_orchestrator_service: Checking if institution is mentioned
2025-09-12 16:16:43,880 [DEBUG] app.services.pipeline_orchestrator_service: Checking if city is detected
2025-09-12 16:16:43,880 [DEBUG] app.services.pipeline_orchestrator_service: [DF COLUMNS] DataFrame columns before city/distance selection: ['Etablissement', 'Ville', 'Latitude', 'Longitude', 'Catégorie', 'Note / 20', 'Distance']
2025-09-12 16:16:43,881 [DEBUG] app.services.pipeline_orchestrator_service: Unique cities in DataFrame before select_hospitals: ['Pierre-Bénite' 'Bayonne' 'Brive-la-Gaillarde' 'Chambéry' 'Dax'
 'La Roche-sur-Yon' 'Valenciennes' 'Clermont-Ferrand' 'Lille' 'Limoges'
 'Montpellier' 'Saint-Etienne' 'Bordeaux' 'Rennes' 'Toulouse' 'Caen'
 'Vandœuvre-lès-Nancy' 'Salouel' 'Angers' 'Nîmes' 'Ermont' 'Royan'
 'Strasbourg' 'Albi' 'Mougins' 'Lorient' 'Saint-Nazaire' 'Grenoble'
 'Paris' 'Le Kremlin-Bicêtre' 'Suresnes' 'Créteil' 'Trévenans' 'Nancy'
 'Vantoux' 'Marseille' 'Aix-en-Provence' 'Plérin' 'Colmar' 'Cabestany'
 'Boujan-sur-Libron' 'Brest' 'Pau' 'Reims']
2025-09-12 16:16:43,881 [INFO] app.services.pipeline_orchestrator_service: City detected, preparing to call select_hospitals.
2025-09-12 16:16:43,881 [DEBUG] app.services.pipeline_orchestrator_service: About to call select_hospitals with df columns: ['Etablissement', 'Ville', 'Latitude', 'Longitude', 'Catégorie', 'Note / 20', 'Distance'], city: Paris, number_institutions: 3
2025-09-12 16:16:43,881 [INFO] app.services.data_processing_service: Selecting hospitals for city: Paris with number_institutions: 3
2025-09-12 16:16:43,881 [INFO] app.services.data_processing_service: Found 7 hospitals in city 'Paris', meeting the requirement of 3.
2025-09-12 16:16:43,886 [DEBUG] app.services.pipeline_orchestrator_service: Formatting response with specialty: base_message='Voici les meilleurs établissements (rayon utilisé : 0 km)', count=3, radius_km=0, city=Paris
2025-09-12 16:16:43,886 [DEBUG] app.services.pipeline_orchestrator_service: Normalizing specialty for display: cancer de la vessie
2025-09-12 16:16:43,886 [INFO] app.services.pipeline_orchestrator_service: Creating response and logging for prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 16:16:43,886 [DEBUG] app.services.pipeline_orchestrator_service: Sanity check results for costs/tokens aggregation: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 16:16:43,886 [DEBUG] app.services.pipeline_orchestrator_service: Query analyst results for costs/tokens aggregation: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.86e-05, 'city_token_usage': 318, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017295, 'institution_names_token_usage': 1108, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.27e-05, 'institution_type_token_usage': 215, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.765e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.71e-05, 'number_institutions_token_usage': 311, 'total_cost': 0.000399, 'total_token_usage': 1952}
2025-09-12 16:16:43,886 [DEBUG] app.services.pipeline_orchestrator_service: Conversation analyst results for costs/tokens aggregation: None
2025-09-12 16:16:43,886 [INFO] app.services.pipeline_orchestrator_service: Aggregated costs and token usage: {'total_cost_sanity_checks_analyst': 0.00028949999999999994, 'total_cost_query_analyst': 0.000798, 'total_cost_conversation_analyst': 0.0, 'total_cost': 0.0010875, 'total_token_usage_sanity_checks_analyst': 1924, 'total_token_usage_query_analyst': 0, 'total_token_usage_conversation_analyst': 0, 'total_token_usage': 1924}
2025-09-12 16:16:43,886 [INFO] app.services.pipeline_orchestrator_service: Final cost/token usage aggregation: {'total_cost_sanity_checks_analyst': 0.00028949999999999994, 'total_cost_query_analyst': 0.000798, 'total_cost_conversation_analyst': 0.0, 'total_cost': 0.0010875, 'total_token_usage_sanity_checks_analyst': 1924, 'total_token_usage_query_analyst': 0, 'total_token_usage_conversation_analyst': 0, 'total_token_usage': 1924}
2025-09-12 16:16:43,886 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 16:16:43,887 [INFO] app.services.data_processing_service: Saving Q&A to CSV: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 16:16:43,888 [DEBUG] app.services.data_processing_service: CSV written to /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/history/results_history_mvp.csv
2025-09-12 16:16:43,888 [DEBUG] app.services.pipeline_orchestrator_service: Formatted response: Voici les meilleurs établissements (rayon utilisé : 0 km)
<br>Aucun établissement privé trouvé.<br>Voici les établissements publics :<br>Institut mutualiste Montsouris, Paris (75): Un établissement Public situé à 0 km. avec une note de 18.63 de 20<br>Hôpital Saint-Louis, Paris (75): Un établissement Public situé à 0 km. avec une note de 18.27 de 20<br>Hôpital européen Georges-Pompidou, Paris (75): Un établissement Public situé à 0 km. avec une note de 18.26 de 20

🔗 Consultez la méthodologie de palmarès hopitaux <a href="https://www.lepoint.fr/sante/la-methodologie-du-palmares-des-hopitaux-et-cliniques-du-point-2024--04-12-2024-2577146_40.php" target="_blank">ici</a>.
2025-09-12 16:16:43,888 [ERROR] app.api.routes: Error processing /ask request: 1 validation error for AskResponse
result
  Input should be a valid string [type=string_type, input_value=('Voici les meilleurs ét...2-2024-2577146_40.php']), input_type=tuple]
    For further information visit https://errors.pydantic.dev/2.11/v/string_type
2025-09-12 16:19:10,791 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:19:10,791 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:19:10,791 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:19:10,791 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:19:10,793 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:19:10,793 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:19:10,793 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:19:10,893 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:19:10,893 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:19:10,893 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:19:10,897 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:19:10,897 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:19:11,090 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:19:11,091 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:19:11,091 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:19:11,092 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:19:11,092 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:19:11,092 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:19:11,163 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:19:11,163 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:19:11,163 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:19:11,165 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:19:11,165 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:19:11,165 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:19:11,166 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:19:11,166 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:19:11,166 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:19:11,166 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:19:11,166 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:19:11,167 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:19:11,167 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:19:11,167 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:19:11,238 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:19:11,238 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:19:11,238 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:19:11,240 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:19:11,240 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:19:11,269 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:19:11,271 [INFO] main: Creating FastAPI app
2025-09-12 16:19:11,271 [INFO] main: CORS middleware added
2025-09-12 16:19:11,272 [INFO] main: API router included
2025-09-12 16:19:11,278 [INFO] app.services.pipeline_orchestrator_service: Starting pipeline processing - prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 16:19:11,279 [INFO] app.services.pipeline_orchestrator_service: Resetting PipelineOrchestrator attributes for new query
2025-09-12 16:19:11,279 [INFO] app.services.pipeline_orchestrator_service: Running sanity checks for prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conversation: [], conv_history: 
2025-09-12 16:19:11,279 [DEBUG] app.features.sanity_checks.sanity_checks_analyst: run_checks called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conversation=[], conv_history=, checks_to_run=['conversation_limit', 'message_length', 'message_pertinence']
2025-09-12 16:19:11,279 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst running checks: ['conversation_limit', 'message_length', 'message_pertinence'] for user_input: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 16:19:11,279 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check medical pertinence prompt sent to LLM.
2025-09-12 16:19:11,283 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nÉvaluez si le message suivant a un rapport avec la santé humaine ou les services de soins.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur la santé.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes de discussions médicales.\nATTENTION: Toute question sur la méthodologie, la fréquence de mise à jour, les critères, ou le fonctionnement du classement des hôpitaux doit TOUJOURS être considérée comme pertinente, même si elle ne concerne pas directement une maladie ou un service de soins.\n\nRépondez UNIQUEMENT avec 1 si pertinent, 0 si non pertinent ou 2 si la question concerne la méthodologie de calcul du classement.\n\nExemples pour messages standalone (repondre 1): \n- \'J\'ai un cancer à Paris\' → 1\n- \'Cataracte\' → 1  \n- \'J\'ai mal aux pieds\' → 1\n- \'Les hôpitaux privés sont ils meilleurs que les publiques?\' → 1\n- \'Comment le classement est-il calculé ?\' → 1\n- \'Quels sont les critères du classement ?\' → 1\n- "Quels experts participent à l\'élaboration du classement ?"\' → 1\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\' → 1\n- "Comment sont traitées les données manquantes dans le classement ?"\' → 1\n- "Le classement est-il le même pour toutes les spécialités ?"\' → 1\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\' → 1\n- "Quels sont les changements dans la méthodologie cette année ?"\' → 1\n- "Comment puis-je accéder au détail de la méthodologie ?"\' → 1\n\nExemples pour messages standalone (repondre 0):\n- \'Je mange des frites\' → 0\n- \'Comment faire une tarte aux pommes ?\' → 0\n- \'Comment s\'abonner Le Point ?\' → 0\n- \'Quel est le meilleur restaurant à Paris ?\' → 0\n\n\nExemples de questions qui concernent la méthodologie de classement (repondre 2):\n- "Comment le classement est-il calculé ?"\n- "Quels sont les critères du classement ?" \n- "Pourquoi l\'hôpital X est mieux classé que Y ?"\n- "Comment sont choisis les critères du classement ?"\n- "Qui réalise le classement des hôpitaux ?"\n- "Quelle est la source des données utilisées pour le classement ?"\n- "Le classement prend-il en compte la satisfaction des patients ?"\n- "Comment sont pondérés les différents critères ?"\n- "Est-ce que le classement est mis à jour chaque année ?"\n- "Pourquoi certains hôpitaux ne figurent pas dans le classement ?"\n- "Comment puis-je vérifier la fiabilité du classement ?"\n- "Quels experts participent à l\'élaboration du classement ?"\n- "Le classement est-il influencé par des partenariats ou des sponsors ?"\n- "Comment sont traitées les données manquantes dans le classement ?"\n- "Le classement est-il le même pour toutes les spécialités ?"\n- "Comment sont comparés les hôpitaux publics et privés dans le classement ?"\n- "Quels sont les changements dans la méthodologie cette année ?"\n- "Comment puis-je accéder au détail de la méthodologie ?"\n\nExemples pour messages avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique montrant une discussion sur les hôpitaux, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur la cardiologie, \'Merci\' → 1 (remerciement dans contexte médical)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n- Même avec contexte médical, \'Parle-moi de football\' → 0 (hors-sujet)\n- Avec historique sur les classements, "Comment sont déterminés les scores ?" → 2 (question sur la méthodologie de classement)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:11,311 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:11,312 [DEBUG] httpcore.connection: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-09-12 16:19:11,351 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x117a8bb60>
2025-09-12 16:19:11,351 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x11762fec0> server_hostname='api.openai.com' timeout=None
2025-09-12 16:19:11,371 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x117ab1e50>
2025-09-12 16:19:11,371 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:11,371 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:11,372 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:11,372 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:11,372 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:12,267 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'738'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'754'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'198877'), (b'x-ratelimit-reset-requests', b'1m0.046s'), (b'x-ratelimit-reset-tokens', b'336ms'), (b'x-request-id', b'req_61fb7c509aa64e43a82278731539d3c3'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=KSmnCTKLlDNccRp.R3IpFw.GrO6idS4ZnyPXXZxKcpg-1757686752-1.0.1.1-jUbzAyng.IkS6zHsr.A0LKENpi0.gdSaM5eam_EPRhLnX0cghPgutUYxrimdQ_av49Vvf3fCfW3tyy3QilOOsz53waOek1uGiaDxci5D4.g; path=/; expires=Fri, 12-Sep-25 14:49:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=g2n785k45g82YdrD.RpSgudzpOlLmuHFK1c4dNob5dw-1757686752389-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e009d4ee47e17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:12,268 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:12,268 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:12,274 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:12,274 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:12,274 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:12,274 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Fri, 12 Sep 2025 14:19:12 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'le-point-hv3izr'), ('openai-processing-ms', '738'), ('openai-project', 'proj_auvPnKXq8lce0dksWKRj2pvx'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '754'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9993'), ('x-ratelimit-remaining-tokens', '198877'), ('x-ratelimit-reset-requests', '1m0.046s'), ('x-ratelimit-reset-tokens', '336ms'), ('x-request-id', 'req_61fb7c509aa64e43a82278731539d3c3'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=KSmnCTKLlDNccRp.R3IpFw.GrO6idS4ZnyPXXZxKcpg-1757686752-1.0.1.1-jUbzAyng.IkS6zHsr.A0LKENpi0.gdSaM5eam_EPRhLnX0cghPgutUYxrimdQ_av49Vvf3fCfW3tyy3QilOOsz53waOek1uGiaDxci5D4.g; path=/; expires=Fri, 12-Sep-25 14:49:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=g2n785k45g82YdrD.RpSgudzpOlLmuHFK1c4dNob5dw-1757686752389-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '97e009d4ee47e17d-MRS'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-09-12 16:19:12,275 [DEBUG] openai._base_client: request_id: req_61fb7c509aa64e43a82278731539d3c3
2025-09-12 16:19:12,281 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_medical_pertinence' successful: {'prompt_tokens': 1112, 'completion_tokens': 1, 'total_tokens': 1113}, cost=0.00016739999999999998
2025-09-12 16:19:12,282 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for medical pertinence:
1
2025-09-12 16:19:12,282 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed medical pertinence value: 1 (type: <class 'int'>)
2025-09-12 16:19:12,282 [DEBUG] app.features.sanity_checks.message_pertinence_check: medical_pertinence_result: {'result': 1, 'cost': 0.00016739999999999998, 'token_usage': 1113}
2025-09-12 16:19:12,282 [DEBUG] app.features.sanity_checks.message_pertinence_check: Sanity check chatbot pertinence prompt sent to LLM.
2025-09-12 16:19:12,285 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nVérifiez si cette question concerne le classement des hôpitaux.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ÉVALUER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Un message peut être pertinent même s\'il semble incomplet ou ambigu, si le contexte de la conversation montre qu\'il s\'agit d\'une suite logique d\'une discussion sur les classements d\'hôpitaux.\n\nATTENTION: Les questions de suivi sur les hôpitaux publics/privés sont TOUJOURS pertinentes. Les mots comme "privé", "public", "et privé?", "et public?" dans le contexte d\'une discussion sur les hôpitaux sont des continuations légitimes.\n\nRépondez UNIQUEMENT avec:\n- 1 si la question est pertinente pour le chatbot (classement, recherche d\'établissement, etc.)\n- 0 si la question n\'est pas pertinente\n\nUne question est pertinente si elle concerne au moins un des cas suivants:\n- Une maladie, un symptôme ou une spécialité médicale  \n- Le classement des hôpitaux et cliniques  \n- La recherche d\'un hôpital, d\'une clinique ou d\'un service médical  \n- Une question de suivi sur les secteurs public/privé des hôpitaux\n\nExemples de questions pertinentes pour messages standalone (repondre 1):  \n- Quel est la meilleur clinique de France ?\n- Conseille moi un hôpital à Lyon \n- Je chercher un service de pneumologie\n- Où faire soigner mon glaucome ? \n- Je veux corriger mon audition\n- Il y a fréquemment du sang dans mes urines. Conseille-moi un hôpital. \n- Je veux cherche à faire soigner mes troubles bipôlaires\n- Est-ce que l\'Institut mutualiste Montsouris est bon ?\n- Y a-t-il des hôpitaux privés avec un service de cardiologie interventionnelle ?\n\nExemples de questions non pertinentes pour messages standalone (repondre 0):  \n- Pourquoi les hôpitaux sont-ils en crise ?  #Il s\'agit d\'une demande d\'information qui n\'est pas dans le cadre direct de la recherche d\'un établissement de soin\n- Dois-je prendre du paracétamol pour ma fièvre ? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n- Puis-je perdre la vue si j\'ai un glaucome? #Il s\'agit d\'une demande d\'expertise médical qui n\'est pas dans le cadre de la recherche d\'un établissement de soin\n\n\n\nExemples avec contexte conversationnel (TRÈS IMPORTANT):\n- Avec historique sur les hôpitaux parisiens, \'Et à Lyon ?\' → 1 (question de suivi sur les hôpitaux)\n- Avec historique sur les classements, \'Combien coûte une consultation ?\' → 0 (question sur les coûts, pas sur les classements)\n- Avec historique sur la recherche d\'hôpital, \'Merci beaucoup\' → 1 (remerciement dans contexte de recherche d\'hôpital)\n- Avec historique sur hôpitaux publics, \'et privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique sur hôpitaux privés, \'et public?\' → 1 (question de suivi sur le secteur public)\n- Avec historique sur cardiologie publique, \'privé?\' → 1 (question de suivi sur le secteur privé)\n- Avec historique mentionnant "privés", \'et privé?\' → 1 (demande de précision sur le secteur privé)\n- Avec historique sur hôpitaux de Bordeaux, \'publics aussi?\' → 1 (question de suivi sur le secteur public)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:12,286 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:12,286 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:12,287 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:12,287 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:12,287 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:12,287 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:12,735 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'281'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'296'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'199169'), (b'x-ratelimit-reset-requests', b'59.128s'), (b'x-ratelimit-reset-tokens', b'249ms'), (b'x-request-id', b'req_9e618ab41faa46598039eea178b7ce30'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e009daab1ce17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:12,736 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:12,736 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:12,739 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:12,739 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:12,739 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:12,740 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '281', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '296', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9993', 'x-ratelimit-remaining-tokens': '199169', 'x-ratelimit-reset-requests': '59.128s', 'x-ratelimit-reset-tokens': '249ms', 'x-request-id': 'req_9e618ab41faa46598039eea178b7ce30', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e009daab1ce17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:12,740 [DEBUG] openai._base_client: request_id: req_9e618ab41faa46598039eea178b7ce30
2025-09-12 16:19:12,741 [DEBUG] app.utility.llm_helpers: LLM call 'sanity_check_chatbot_pertinence' successful: {'prompt_tokens': 810, 'completion_tokens': 1, 'total_tokens': 811}, cost=0.00012209999999999999
2025-09-12 16:19:12,741 [DEBUG] app.features.sanity_checks.message_pertinence_check: Raw LLM response for chatbot pertinence:
1
2025-09-12 16:19:12,741 [DEBUG] app.features.sanity_checks.message_pertinence_check: Parsed chatbot pertinence value: 1 (type: <class 'int'>)
2025-09-12 16:19:12,741 [INFO] app.features.sanity_checks.sanity_checks_analyst: SanityChecksAnalyst completed checks. All passed: True, Total cost: 0.00028949999999999994, Total tokens: 1924
2025-09-12 16:19:12,741 [INFO] app.features.sanity_checks.sanity_checks_analyst: Sanity check results: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 16:19:12,742 [INFO] app.services.pipeline_orchestrator_service: Sanity checks result: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 16:19:12,742 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', detected_specialty='None', conv_history=''
2025-09-12 16:19:12,742 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 16:19:12,742 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 16:19:12,742 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 16:19:12,742 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 16:19:12,953 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 16:19:12,953 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history: 
2025-09-12 16:19:12,954 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'
2025-09-12 16:19:12,956 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:12,957 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:12,957 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:12,958 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:12,958 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:12,958 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:12,958 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:13,376 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'279'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'292'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9992'), (b'x-ratelimit-remaining-tokens', b'199552'), (b'x-ratelimit-reset-requests', b'1m7.11s'), (b'x-ratelimit-reset-tokens', b'134ms'), (b'x-request-id', b'req_e383fbdf9b39407eb24a9b0ed10ba3d8'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e009dedcf7e17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:13,376 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:13,376 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:13,379 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:13,379 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:13,379 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:13,379 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:13 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '279', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '292', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9992', 'x-ratelimit-remaining-tokens': '199552', 'x-ratelimit-reset-requests': '1m7.11s', 'x-ratelimit-reset-tokens': '134ms', 'x-request-id': 'req_e383fbdf9b39407eb24a9b0ed10ba3d8', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e009dedcf7e17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:13,379 [DEBUG] openai._base_client: request_id: req_e383fbdf9b39407eb24a9b0ed10ba3d8
2025-09-12 16:19:13,380 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 431, 'completion_tokens': 5, 'total_tokens': 436}, cost=6.765e-05
2025-09-12 16:19:13,380 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer de la vessie, method: llm
2025-09-12 16:19:13,381 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer de la vessie', 'detection_method': 'llm', 'cost': 6.765e-05, 'token_usage': 0}
2025-09-12 16:19:13,381 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', conv_history: ''
2025-09-12 16:19:13,383 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:13,384 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:13,384 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:13,385 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:13,385 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:13,385 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:13,385 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:13,693 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'146'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'160'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9991'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m15.314s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_67e6c503ebc6437795867ad9db0ee44a'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e009e18b03e17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:13,693 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:13,694 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:13,696 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:13,696 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:13,696 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:13,696 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:13 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '146', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '160', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9991', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m15.314s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_67e6c503ebc6437795867ad9db0ee44a', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e009e18b03e17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:13,697 [DEBUG] openai._base_client: request_id: req_67e6c503ebc6437795867ad9db0ee44a
2025-09-12 16:19:13,697 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 16:19:13,700 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:13,700 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:13,701 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:13,701 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:13,701 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:13,701 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:13,701 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:14,292 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'391'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'426'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9991'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'1m15.733s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_219892a773164d7ab38cab6a0369f756'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e009e37f67e17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:14,293 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:14,293 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:14,293 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:14,293 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:14,293 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:14,293 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '391', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '426', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9991', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '1m15.733s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_219892a773164d7ab38cab6a0369f756', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e009e37f67e17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:14,294 [DEBUG] openai._base_client: request_id: req_219892a773164d7ab38cab6a0369f756
2025-09-12 16:19:14,294 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 16:19:14,294 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 16:19:14,295 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'status_code': 3, 'token_usage': {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}}
2025-09-12 16:19:14,295 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history=
2025-09-12 16:19:14,297 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:14,298 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:14,298 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:14,298 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:14,298 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:14,299 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:14,299 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:14,598 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'160'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'175'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9988'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m40.329s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_00e569bc53f543a1ae4e7840812a3667'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e009e7386fe17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:14,598 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:14,599 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:14,600 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:14,600 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:14,600 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:14,601 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '160', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '175', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9988', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m40.329s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_00e569bc53f543a1ae4e7840812a3667', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e009e7386fe17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:14,601 [DEBUG] openai._base_client: request_id: req_00e569bc53f543a1ae4e7840812a3667
2025-09-12 16:19:14,601 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 16:19:14,604 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:14,604 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:14,605 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:14,605 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:14,605 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:14,605 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:14,605 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:15,015 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'251'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'272'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9990'), (b'x-ratelimit-remaining-tokens', b'199647'), (b'x-ratelimit-reset-requests', b'1m22.729s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_0677ea299a4c485eab063409c4b30cc5'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e009e92c8ae17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:15,016 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:15,016 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:15,018 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:15,019 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:15,019 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:15,019 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:15 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '251', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '272', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9990', 'x-ratelimit-remaining-tokens': '199647', 'x-ratelimit-reset-requests': '1m22.729s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_0677ea299a4c485eab063409c4b30cc5', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e009e92c8ae17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:15,019 [DEBUG] openai._base_client: request_id: req_0677ea299a4c485eab063409c4b30cc5
2025-09-12 16:19:15,022 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 16:19:15,023 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 16:19:15,023 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 3, 'city_detected': True, 'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'token_usage': 318}
2025-09-12 16:19:15,023 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?' with conv_history: ''
2025-09-12 16:19:15,026 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:15,027 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:15,027 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:15,027 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:15,027 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:15,028 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:15,028 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:15,600 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'396'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'412'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9988'), (b'x-ratelimit-remaining-tokens', b'198986'), (b'x-ratelimit-reset-requests', b'1m40.337s'), (b'x-ratelimit-reset-tokens', b'304ms'), (b'x-request-id', b'req_c66afbb7177c91009b533f71b01ded30'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e009ebc9f3e17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:15,601 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:15,601 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:15,601 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:15,601 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:15,601 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:15,601 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:15 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '396', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '412', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9988', 'x-ratelimit-remaining-tokens': '198986', 'x-ratelimit-reset-requests': '1m40.337s', 'x-ratelimit-reset-tokens': '304ms', 'x-request-id': 'req_c66afbb7177c91009b533f71b01ded30', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e009ebc9f3e17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:15,602 [DEBUG] openai._base_client: request_id: req_c66afbb7177c91009b533f71b01ded30
2025-09-12 16:19:15,603 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1093, 'completion_tokens': 11, 'total_tokens': 1104}, cost=0.00017055
2025-09-12 16:19:15,603 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{"institutions": [], "intent": "none"}'
2025-09-12 16:19:15,604 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{"institutions": [], "intent": "none"}'
2025-09-12 16:19:15,604 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': [], 'intent': 'none'}
2025-09-12 16:19:15,604 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: [], intent: none, cost: 0.00017055, token_usage: {'prompt_tokens': 1093, 'completion_tokens': 11, 'total_tokens': 1104}
2025-09-12 16:19:15,604 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | []
2025-09-12 16:19:15,604 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=[] and institution_list length=553)
2025-09-12 16:19:15,604 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: []
2025-09-12 16:19:15,604 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: none
2025-09-12 16:19:15,604 [INFO] app.features.query_analysis.institution_names.institution_names_validation: No specific institution detected
2025-09-12 16:19:15,604 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': None, 'institution_name_mentioned': False, 'error': 'No institution detected', 'intent': 'none', 'detection_method': 'llm', 'cost': 0.00017055, 'token_usage': 1104}
2025-09-12 16:19:15,607 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:15,608 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:15,608 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:15,608 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:15,608 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:15,609 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:15,609 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:16,703 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'277'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'934'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9987'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'1m47.641s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_9c66f9261af84ce8b0e2ea8c613c026a'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e009ef68fee17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:16,703 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:16,703 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:16,707 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:16,708 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:16,708 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:16,708 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:16 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '277', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '934', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9987', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '1m47.641s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_9c66f9261af84ce8b0e2ea8c613c026a', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e009ef68fee17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:16,708 [DEBUG] openai._base_client: request_id: req_9c66f9261af84ce8b0e2ea8c613c026a
2025-09-12 16:19:16,709 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}, cost=3.27e-05
2025-09-12 16:19:16,709 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.27e-05, {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}
2025-09-12 16:19:16,709 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.27e-05, 'token_usage': 215}
2025-09-12 16:19:16,712 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:16,712 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:16,712 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:16,713 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:16,713 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:16,713 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:16,713 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:17,142 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'266'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'281'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9984'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'2m13.22s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_f776df70a5264485b98e7fc5e1826927'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e009f65846e17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:17,143 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:17,143 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:17,147 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:17,147 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:17,147 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:17,147 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '266', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '281', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9984', 'x-ratelimit-remaining-tokens': '199678', 'x-ratelimit-reset-requests': '2m13.22s', 'x-ratelimit-reset-tokens': '96ms', 'x-request-id': 'req_f776df70a5264485b98e7fc5e1826927', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e009f65846e17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:17,147 [DEBUG] openai._base_client: request_id: req_f776df70a5264485b98e7fc5e1826927
2025-09-12 16:19:17,148 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}, cost=4.71e-05
2025-09-12 16:19:17,148 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.71e-05, {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}
2025-09-12 16:19:17,148 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.71e-05, 'token_usage': 311}
2025-09-12 16:19:17,148 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer de la vessie, city=Paris, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 16:19:17,148 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.765e-05, city_cost=7.86e-05, institution_names_cost=0.00017055, institution_type_cost=3.27e-05, number_institutions_cost=4.71e-05
2025-09-12 16:19:17,148 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=318, institution_names_tokens=1104, institution_type_tokens=215, number_institutions_tokens=311
2025-09-12 16:19:17,149 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.86e-05, 'city_token_usage': 318, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017055, 'institution_names_token_usage': 1104, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.27e-05, 'institution_type_token_usage': 215, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.765e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.71e-05, 'number_institutions_token_usage': 311, 'total_cost': 0.0003966, 'total_token_usage': 1948}
2025-09-12 16:19:17,149 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer de la vessie', city='Paris', city_detected=True, institution_type='aucune correspondance', number_institutions=3, institution_names=None, institution_name_mentioned=False
2025-09-12 16:19:17,149 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer de la vessie'
2025-09-12 16:19:17,149 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: 'Paris'
2025-09-12 16:19:17,149 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: True
2025-09-12 16:19:17,149 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 16:19:17,149 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 3
2025-09-12 16:19:17,149 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: []
2025-09-12 16:19:17,149 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 16:19:17,149 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'none'
2025-09-12 16:19:17,149 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: False
2025-09-12 16:19:17,178 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 16:19:17,179 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 16:19:17,394 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 16:19:17,394 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 16:19:17,394 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer de la vessie'
2025-09-12 16:19:17,394 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: 'Paris'
2025-09-12 16:19:17,394 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: True
2025-09-12 16:19:17,394 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 16:19:17,394 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: []
2025-09-12 16:19:17,395 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: False
2025-09-12 16:19:17,395 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 3
2025-09-12 16:19:17,395 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer de la vessie, city: Paris, institution_type: aucune correspondance, institution: [], institution_name_mentioned: False
2025-09-12 16:19:17,395 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 16:19:17,395 [DEBUG] app.services.pipeline_orchestrator_service: [CITY DETECTION] Detected city: 'Paris', city_detected: True, DataProcessor.city: 'Paris', DataProcessor.city_detected: True
2025-09-12 16:19:17,395 [DEBUG] app.services.pipeline_orchestrator_service: Calling build_ranking_dataframe_with_distances
2025-09-12 16:19:17,395 [INFO] app.services.pipeline_orchestrator_service: Building ranking DataFrame with distances: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', excel_path='/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx', detected_specialty='cancer de la vessie'
2025-09-12 16:19:17,395 [INFO] app.services.pipeline_orchestrator_service: Extracting query parameters: prompt='Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', detected_specialty='cancer de la vessie', conv_history='None'
2025-09-12 16:19:17,395 [INFO] app.features.query_analysis.query_analyst: Initializing QueryAnalyst
2025-09-12 16:19:17,395 [INFO] app.features.query_analysis.city.city_analyst: Initializing CityAnalyst
2025-09-12 16:19:17,395 [INFO] app.features.query_analysis.city.city_detection: Initializing CityDetector
2025-09-12 16:19:17,396 [INFO] app.features.query_analysis.city.city_validation: Initializing CityValidator
2025-09-12 16:19:17,584 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 16:19:17,584 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst running all detections for text: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history: 
2025-09-12 16:19:17,584 [INFO] app.features.query_analysis.specialty.specialty_detection: Detecting specialty from prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'
2025-09-12 16:19:17,587 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nVoici un message pour lequel tu vas devoir détecter la ou les pathologie(s) ou spécialité(s) médicale(s) mentionnées ou sous-entendues.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analyse le nouveau message en tenant compte du contexte conversationnel. Une spécialité ou pathologie peut être mentionnée de manière implicite si le contexte montre qu'on parle d'un sujet médical spécifique.\n\nTa tâche :\n- Liste toutes les pathologies ou spécialités médicales que tu détectes dans le message (même si elles sont implicites ou sous-entendues).\n- Si tu détectes plusieurs spécialités/pathologies, liste-les séparées par une virgule.\n- Si aucune spécialité/pathologie médicale n'est détectée, réponds exactement : 'aucune correspondance'.\n- N'invente pas de spécialité ou pathologie qui n'est pas mentionnée ou sous-entendue dans le message.\n\nExemples :\n- Pour le message 'Je veux soigner mon AVC?', tu répondras 'Accidents vasculaires cérébraux'.\n- Pour le message 'Je cherche un hôpital pour un accouchement', tu répondras 'Accouchements à risques, Accouchements normaux' (si les deux sont sous-entendus).\n- Pour le message 'J'ai mal au genou', tu répondras 'genou' (si les deux sont sous-entendus).\n- Pour le message 'Quel est le classement de CH de Vannes pour la cancer au sein ?', tu répondras 'Cancer du sein'.\n- Pour le message 'Quels sont les meilleurs hôpitaux pour la cataracte ?', tu répondras 'Cataracte'.\n- Pour le message 'Quels sont les meilleurs hôpitaux à Paris ?', tu répondras 'aucune correspondance'.\n\nN'invente pas de spécialité qui n'est pas dans le message ou le contexte.\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:17,588 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:17,588 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:17,588 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:17,588 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:17,588 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:17,588 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:18,043 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'309'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'323'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9984'), (b'x-ratelimit-remaining-tokens', b'199553'), (b'x-ratelimit-reset-requests', b'2m11.602s'), (b'x-ratelimit-reset-tokens', b'134ms'), (b'x-request-id', b'req_8534c3c187864ff58645bf78f34fd8c9'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e009fbcbf4e17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:18,043 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:18,043 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:18,044 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:18,044 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:18,044 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:18,044 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:18 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '309', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '323', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9984', 'x-ratelimit-remaining-tokens': '199553', 'x-ratelimit-reset-requests': '2m11.602s', 'x-ratelimit-reset-tokens': '134ms', 'x-request-id': 'req_8534c3c187864ff58645bf78f34fd8c9', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e009fbcbf4e17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:18,044 [DEBUG] openai._base_client: request_id: req_8534c3c187864ff58645bf78f34fd8c9
2025-09-12 16:19:18,045 [DEBUG] app.utility.llm_helpers: LLM call 'detect_specialty_llm' successful: {'prompt_tokens': 431, 'completion_tokens': 5, 'total_tokens': 436}, cost=6.765e-05
2025-09-12 16:19:18,045 [INFO] app.features.query_analysis.specialty.specialty_detection: Specialty detection result: Cancer de la vessie, method: llm
2025-09-12 16:19:18,045 [DEBUG] app.features.query_analysis.specialty.specialty_analyst: Specialty detection and validation result: {'specialty': 'cancer de la vessie', 'detection_method': 'llm', 'cost': 6.765e-05, 'token_usage': 0}
2025-09-12 16:19:18,045 [INFO] app.features.query_analysis.city.city_analyst: Calling CityDetector.detect_city with prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?', conv_history: ''
2025-09-12 16:19:18,048 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:18,048 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:18,049 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:18,049 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:18,049 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:18,049 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:18,049 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:18,474 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'244'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'264'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9984'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'2m11.124s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_4c3ee9c2996b4d18a0efaad5c0122392'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e009feab46e17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:18,475 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:18,475 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:18,475 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:18,475 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:18,475 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:18,475 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:18 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '244', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '264', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9984', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '2m11.124s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_4c3ee9c2996b4d18a0efaad5c0122392', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e009feab46e17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:18,476 [DEBUG] openai._base_client: request_id: req_4c3ee9c2996b4d18a0efaad5c0122392
2025-09-12 16:19:18,476 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 16:19:18,479 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:18,480 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:18,480 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:18,480 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:18,480 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:18,481 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:18,481 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:19,087 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'406'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'447'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9983'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'2m20.075s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_131e561eca6547639246dd5737138773'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e00a01591ae17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:19,087 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:19,087 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:19,087 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:19,088 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:19,088 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:19,088 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:19 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '406', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '447', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9983', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '2m20.075s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_131e561eca6547639246dd5737138773', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e00a01591ae17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:19,088 [DEBUG] openai._base_client: request_id: req_131e561eca6547639246dd5737138773
2025-09-12 16:19:19,089 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 16:19:19,089 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 16:19:19,089 [INFO] app.features.query_analysis.city.city_analyst: Raw detected_result from CityDetector: {'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'status_code': 3, 'token_usage': {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}}
2025-09-12 16:19:19,089 [DEBUG] app.features.query_analysis.city.city_validation: check called: user_input=Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?, conv_history=
2025-09-12 16:19:19,091 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nAnalysez cette phrase pour détecter des informations de localisation.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nRépondez avec:\n- 0 si aucune localisation n'est mentionnée\n- 1 si ville étrangère  \n- 2 si confusion entre villes françaises\n- 3 si une ville ou localisation française claire est mentionnée\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 3 (Lyon est mentionné)\n- Avec historique sur Marseille, 'Merci' → 0 (aucune nouvelle localisation)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:19,092 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:19,092 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:19,093 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:19,093 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:19,093 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:19,093 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:19,396 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'141'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'155'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9981'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'2m36.007s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_b27d770847dd4ee5acb49d4422c08353'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e00a0539cde17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:19,397 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:19,397 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:19,397 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:19,397 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:19,397 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:19,397 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:19 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '141', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '155', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9981', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '2m36.007s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_b27d770847dd4ee5acb49d4422c08353', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e00a0539cde17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:19,398 [DEBUG] openai._base_client: request_id: req_b27d770847dd4ee5acb49d4422c08353
2025-09-12 16:19:19,398 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_status' successful: {'prompt_tokens': 199, 'completion_tokens': 1, 'total_tokens': 200}, cost=3.0449999999999998e-05
2025-09-12 16:19:19,401 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nQuelle ville ou département est mentionné par la phrase suivante?\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Une ville peut être mentionnée de manière implicite si le contexte de la conversation montre qu'on parle d'une localisation spécifique.\n\nSi une ville est mentionnée, réponds UNIQUEMENT avec le nom de ville.\nPar exemple: pour la phrase 'Trouve moi un hôpital à Lyon', tu me retourneras: 'Lyon'.\n\nSi un département est mentionné, réponds UNIQUEMENT avec le numéro du département.\nPar exemple: pour la phrase 'Je veux être hospitalisé dans le 92', tu me retourneras: '92'.               \n\nSi aucune localisation n'est mentionnée dans ma phrase, renvoie moi EXACTEMENT ces deux mots: 'aucune correspondance'.\nPar exemple: pour la phrase 'Je veux un classement des meilleurs établissements en France', tu me retourneras: 'aucune correspondance'.\nPar exemple: pour la phrase 'Quelle est la meilleur clinique pour une chirurgie à la montagne', tu me retourneras: 'aucune correspondance'.\n\nExemples avec contexte conversationnel:\n- Avec historique mentionnant Paris, 'Et à Lyon ?' → 'Lyon'\n- Avec historique sur Marseille, 'Merci' → 'aucune correspondance'\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:19,401 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:19,401 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:19,402 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:19,402 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:19,402 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:19,402 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:19,853 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'281'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'295'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9980'), (b'x-ratelimit-remaining-tokens', b'199648'), (b'x-ratelimit-reset-requests', b'2m44.334s'), (b'x-ratelimit-reset-tokens', b'105ms'), (b'x-request-id', b'req_f178bd91a2b143f386682662b8dbc692'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e00a072f70e17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:19,854 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:19,854 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:19,854 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:19,854 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:19,854 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:19,854 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:19 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '281', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '295', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9980', 'x-ratelimit-remaining-tokens': '199648', 'x-ratelimit-reset-requests': '2m44.334s', 'x-ratelimit-reset-tokens': '105ms', 'x-request-id': 'req_f178bd91a2b143f386682662b8dbc692', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e00a072f70e17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:19,854 [DEBUG] openai._base_client: request_id: req_f178bd91a2b143f386682662b8dbc692
2025-09-12 16:19:19,855 [DEBUG] app.utility.llm_helpers: LLM call 'detect_city_name' successful: {'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}, cost=4.815e-05
2025-09-12 16:19:19,855 [DEBUG] app.features.query_analysis.city.city_detection: City detection result: city=Paris, status=3, method=llm, cost=7.86e-05, tokens={'prompt_tokens': 317, 'completion_tokens': 1, 'total_tokens': 318}
2025-09-12 16:19:19,855 [DEBUG] app.features.query_analysis.city.city_analyst: City detection and validation result: {'status_code': 3, 'city_detected': True, 'city': 'Paris', 'detection_method': 'llm', 'cost': 7.86e-05, 'token_usage': 318}
2025-09-12 16:19:19,855 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detecting institution names in prompt: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?' with conv_history: ''
2025-09-12 16:19:19,858 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nTon rôle est d\'extraire les noms exacts d\'établissements mentionnés dans une question et de déterminer l\'intention de la demande.\n\n---\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\n---\n\nINSTRUCTIONS:\n\n1. Extrait tous les noms d\'établissements tels qu\'ils apparaissent dans le message (même avec fautes ou variantes).\n   - Retourne-les tels que l\'utilisateur les a écrits, sans corriger ni compléter.\n   - Si aucun établissement n\'est mentionné, retourne une liste vide.\n   - NE RETOURNE PAS de mots génériques ou de catégories comme "hôpital", "hôpitaux", "clinique", "cliniques", "établissement", "établissements", "centre", "centres", "hôpital public", "hôpital privé", "hôpitaux publics", "hôpitaux privés", "cliniques privées", "cliniques publiques", ni de noms de villes ou régions.\n   - NE RETOURNE PAS de sigles ou abréviations génériques comme "CH", "CHU", "CHR", "CHRU" s\'ils sont seuls, sans nom de ville ou de site associé (ex: "CH de Vannes" est correct, mais "CH" seul ne l\'est pas).\n   - Ne considère comme établissement que les noms propres ou dénominations précises d\'un hôpital ou d\'une clinique (ex: "CH de Vannes", "Hôpital Edouard-Herriot", "Clinique Pasteur").\n\n2. Détermine l\'intention de la question :\n   - "single" : L\'utilisateur parle d\'un seul établissement (même si le mot "classement" est utilisé, s\'il n\'y a qu\'un seul nom d\'établissement, l\'intention est "single").\n   - "multi" : L\'utilisateur demande des infos sur plusieurs établissements (mais sans comparaison).\n   - "compare" : L\'utilisateur compare ou demande un classement entre plusieurs établissements (utilise des formulations comme "lequel est meilleur", "vs", "comparaison", etc. ET il y a au moins deux établissements mentionnés).\n   - "none" : Pas d\'intention claire. S\'il y a au moins un établissement qui n\'est pas dans la liste, retourne "none".\n\n3. Retourne toujours un objet JSON :\n   {\n     "institutions": [...],\n     "intent": "single|multi|compare|none"\n   }\n\n---\n\nEXEMPLES :\n\n1. "Est-ce que l\'Hôpital Edouard-Herriot est bon ?"  \n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n2. "Montre-moi les classements pour Hôpital A, Hôpital B et Hôpital C"  \n{"institutions": ["Hôpital A", "Hôpital B", "Hôpital C"], "intent": "multi"}\n\n3. "Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur ?"  \n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n4. "Je cherche un hôpital à Toulon"  \n{"institutions": [], "intent": "none"}\n\n5. “Est-ce que l’Hôpital Edouard-Herriot est bien pour la cardiologie ?”\n{"institutions": ["Hôpital Edouard-Herriot"], "intent": "single"}\n\n6. “Le CHU de Lille est-il recommandé pour la pédiatrie ?”\n{"institutions": ["CHU de Lille"], "intent": "single"}\n\n7. “Hôpital Saint-Louis ou Clinique Pasteur, lequel est meilleur pour la neurologie ?”\n{"institutions": ["Hôpital Saint-Louis", "Clinique Pasteur"], "intent": "compare"}\n\n8. “CH de Toulon vs CHU de Bordeaux, lequel est le mieux classé ?”\n{"institutions": ["CH de Toulon", "CHU de Bordeaux"], "intent": "compare"}\n\n9. “Montre-moi les classements pour CHU de Toulouse, Hôpital Pompidou et CHU de Nantes”\n{"institutions": ["CHU de Toulouse", "Hôpital Pompidou", "CHU de Nantes"], "intent": "multi"}\n\n10. “Je cherche un hôpital à Rouen pour la chirurgie cardiaque”\n{"institutions": [], "intent": "none"}\n\n11. “Classement CH Roubaix ?”\n{"institutions": ["CH Roubaix"], "intent": "single"}\n\n12. “Quels sont les meilleurs hôpitaux pour les urgences en France ?”\n{"institutions": [], "intent": "none"}\n\n13. “Le CHU de Grenoble est-il bon en oncologie ?”\n{"institutions": ["CHU de Grenoble"], "intent": "single"}\n\n14. “Classement CHU de Lyon et Hôpital Pitié-Salpêtrière pour la neurologie ?”\n{"institutions": ["CHU de Lyon", "Hôpital Pitié-Salpêtrière"], "intent": "multi"}\n\nRéponds UNIQUEMENT avec un JSON.\n\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:19,859 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:19,859 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:19,859 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:19,859 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:19,859 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:19,860 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:20,532 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'493'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'518'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9980'), (b'x-ratelimit-remaining-tokens', b'198986'), (b'x-ratelimit-reset-requests', b'2m44.625s'), (b'x-ratelimit-reset-tokens', b'304ms'), (b'x-request-id', b'req_7dfd86f9464c4348b78780404c9aadd4'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e00a09fe3ae17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:20,532 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:20,532 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:20,539 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:20,539 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:20,540 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:20,540 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '493', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '518', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9980', 'x-ratelimit-remaining-tokens': '198986', 'x-ratelimit-reset-requests': '2m44.625s', 'x-ratelimit-reset-tokens': '304ms', 'x-request-id': 'req_7dfd86f9464c4348b78780404c9aadd4', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e00a09fe3ae17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:20,540 [DEBUG] openai._base_client: request_id: req_7dfd86f9464c4348b78780404c9aadd4
2025-09-12 16:19:20,541 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_names' successful: {'prompt_tokens': 1093, 'completion_tokens': 11, 'total_tokens': 1104}, cost=0.00017055
2025-09-12 16:19:20,541 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Raw LLM response: '{"institutions": [], "intent": "none"}'
2025-09-12 16:19:20,541 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Cleaned LLM response for JSON: '{"institutions": [], "intent": "none"}'
2025-09-12 16:19:20,541 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type after json.loads: <class 'dict'> | Value: {'institutions': [], 'intent': 'none'}
2025-09-12 16:19:20,541 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Detected institutions: [], intent: none, cost: 0.00017055, token_usage: {'prompt_tokens': 1093, 'completion_tokens': 11, 'total_tokens': 1104}
2025-09-12 16:19:20,541 [DEBUG] app.features.query_analysis.institution_names.institution_names_detection: Type and value of institution_names before validation: <class 'list'> | []
2025-09-12 16:19:20,541 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: validate_institution_names called with detected_names=[] and institution_list length=553)
2025-09-12 16:19:20,541 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Validation result: []
2025-09-12 16:19:20,541 [DEBUG] app.features.query_analysis.institution_names.institution_names_validation: Intent validated: none
2025-09-12 16:19:20,541 [INFO] app.features.query_analysis.institution_names.institution_names_validation: No specific institution detected
2025-09-12 16:19:20,541 [DEBUG] app.features.query_analysis.institution_names.institution_names_analyst: Institution detection and validation result: {'institutions': None, 'institution_name_mentioned': False, 'error': 'No institution detected', 'intent': 'none', 'detection_method': 'llm', 'cost': 0.00017055, 'token_usage': 1104}
2025-09-12 16:19:20,544 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': "\nDétectez le type d'établissement de soin dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: 'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le type d'établissement peut être mentionné de manière implicite si le contexte de la conversation montre qu'on parle d'un type spécifique.\n\nRépondez UNIQUEMENT avec:\n- 0 si aucun type mentionné\n- 1 si public\n- 2 si privé\n\nExemples avec contexte conversationnel:\n- Avec historique sur les hôpitaux publics, 'et privé?' → 2 (demande maintenant le privé)\n- Avec historique sur les hôpitaux privés, 'et public?' → 1 (demande maintenant le public)\n- Avec historique général, 'aussi' → 0 (aucun type spécifique mentionné)\n", 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:20,544 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:20,545 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:20,545 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:20,545 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:20,545 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:20,545 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:21,040 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'288'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'327'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9978'), (b'x-ratelimit-remaining-tokens', b'199781'), (b'x-ratelimit-reset-requests', b'3m9.098s'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_02fb048270df4bfa9ea29cb56ff64bc2'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e00a0e4881e17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:21,041 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:21,041 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:21,041 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:21,042 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:21,042 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:21,042 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:21 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '288', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '327', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9978', 'x-ratelimit-remaining-tokens': '199781', 'x-ratelimit-reset-requests': '3m9.098s', 'x-ratelimit-reset-tokens': '65ms', 'x-request-id': 'req_02fb048270df4bfa9ea29cb56ff64bc2', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e00a0e4881e17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:21,042 [DEBUG] openai._base_client: request_id: req_02fb048270df4bfa9ea29cb56ff64bc2
2025-09-12 16:19:21,043 [DEBUG] app.utility.llm_helpers: LLM call 'detect_institution_type' successful: {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}, cost=3.27e-05
2025-09-12 16:19:21,043 [DEBUG] app.features.query_analysis.institution_type.institution_type_detection: Institution type detection result: no match, 3.27e-05, {'prompt_tokens': 214, 'completion_tokens': 1, 'total_tokens': 215}
2025-09-12 16:19:21,043 [DEBUG] app.features.query_analysis.institution_type.institution_type_analyst: Institution type detection and validation result: {'institution_type': 'aucune correspondance', 'detection_method': 'llm', 'cost': 3.27e-05, 'token_usage': 215}
2025-09-12 16:19:21,046 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\nExtrayez le nombre d\'établissements demandés dans le message suivant.\n\nHISTORIQUE DE CONVERSATION:\n\n\nMESSAGE À ANALYSER: \'Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?\'\n\nSi un historique de conversation est fourni ci-dessus, analysez le nouveau message en tenant compte du contexte conversationnel. Le nombre d\'établissements peut être mentionné de manière implicite si le contexte de la conversation montre qu\'on parle d\'un nombre spécifique.\n\nRépondez UNIQUEMENT avec le nombre (1-50) ou 0 si non mentionné.\n\nPar exemple: pour la phrase \'Quels sont les trois meilleurs hôpitaux pour soigner mon audition ?\', tu me retourneras: \'3\'.\n\nSi la phrase inclue une expression comme \'le plus xxx\' ou du superlatif qui implique implicitement une seule entité comme \'le meilleur\', alors tu me retourneras \'1\'\nPar exemple: pour la phrase \'Quel est la meilleur clinique de Nantes?\' ou \'Dis moi l\'établissement le plus populaire de France\' tu me retourneras: \'1\'.\n\nExemples avec contexte conversationnel:\n- Avec historique demandant "les 5 meilleurs", \'et privé?\' → 5 (garde le nombre du contexte)\n- Avec historique général, \'le meilleur\' → 1 (nouveau nombre explicite)\n- Avec historique sans nombre, \'aussi\' → 0 (aucun nombre mentionné)\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}
2025-09-12 16:19:21,047 [DEBUG] openai._base_client: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-09-12 16:19:21,047 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-09-12 16:19:21,047 [DEBUG] httpcore.http11: send_request_headers.complete
2025-09-12 16:19:21,047 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-09-12 16:19:21,047 [DEBUG] httpcore.http11: send_request_body.complete
2025-09-12 16:19:21,048 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-09-12 16:19:21,547 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 12 Sep 2025 14:19:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'le-point-hv3izr'), (b'openai-processing-ms', b'315'), (b'openai-project', b'proj_auvPnKXq8lce0dksWKRj2pvx'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'339'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9979'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'2m59.96s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_a10055adf71a4813b4e8906c77013bac'), (b'x-openai-proxy-wasm', b'v0.1'), (b'cf-cache-status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97e00a116809e17d-MRS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-12 16:19:21,547 [INFO] httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-12 16:19:21,547 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-09-12 16:19:21,559 [DEBUG] httpcore.http11: receive_response_body.complete
2025-09-12 16:19:21,559 [DEBUG] httpcore.http11: response_closed.started
2025-09-12 16:19:21,559 [DEBUG] httpcore.http11: response_closed.complete
2025-09-12 16:19:21,559 [DEBUG] openai._base_client: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Fri, 12 Sep 2025 14:19:21 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'le-point-hv3izr', 'openai-processing-ms': '315', 'openai-project': 'proj_auvPnKXq8lce0dksWKRj2pvx', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '339', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9979', 'x-ratelimit-remaining-tokens': '199678', 'x-ratelimit-reset-requests': '2m59.96s', 'x-ratelimit-reset-tokens': '96ms', 'x-request-id': 'req_a10055adf71a4813b4e8906c77013bac', 'x-openai-proxy-wasm': 'v0.1', 'cf-cache-status': 'DYNAMIC', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '97e00a116809e17d-MRS', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-12 16:19:21,559 [DEBUG] openai._base_client: request_id: req_a10055adf71a4813b4e8906c77013bac
2025-09-12 16:19:21,560 [DEBUG] app.utility.llm_helpers: LLM call 'detect_number_institutions' successful: {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}, cost=4.71e-05
2025-09-12 16:19:21,560 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_detection: Number of institutions detection result: 0, 4.71e-05, {'prompt_tokens': 310, 'completion_tokens': 1, 'total_tokens': 311}
2025-09-12 16:19:21,560 [DEBUG] app.features.query_analysis.number_institutions.number_institutions_analyst: Number of institutions detection and validation result: {'number_institutions': 3, 'detection_method': 'llm', 'cost': 4.71e-05, 'token_usage': 311}
2025-09-12 16:19:21,560 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst detected: specialty=cancer de la vessie, city=Paris, institution_names=None, institution_type=aucune correspondance, number_institutions=3
2025-09-12 16:19:21,560 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst costs/tokens: specialty_cost=6.765e-05, city_cost=7.86e-05, institution_names_cost=0.00017055, institution_type_cost=3.27e-05, number_institutions_cost=4.71e-05
2025-09-12 16:19:21,560 [INFO] app.features.query_analysis.query_analyst: QueryAnalyst tokens: specialty_tokens=0, city_tokens=318, institution_names_tokens=1104, institution_type_tokens=215, number_institutions_tokens=311
2025-09-12 16:19:21,561 [DEBUG] app.services.pipeline_orchestrator_service: Full detections dict: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.86e-05, 'city_token_usage': 318, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017055, 'institution_names_token_usage': 1104, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.27e-05, 'institution_type_token_usage': 215, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.765e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.71e-05, 'number_institutions_token_usage': 311, 'total_cost': 0.0003966, 'total_token_usage': 1948}
2025-09-12 16:19:21,561 [DEBUG] app.services.data_processing_service: set_detection_results: specialty='cancer de la vessie', city='Paris', city_detected=True, institution_type='aucune correspondance', number_institutions=3, institution_names=None, institution_name_mentioned=False
2025-09-12 16:19:21,561 [DEBUG] app.services.data_processing_service: DataProcessor.specialty set to: 'cancer de la vessie'
2025-09-12 16:19:21,561 [DEBUG] app.services.data_processing_service: DataProcessor.city set to: 'Paris'
2025-09-12 16:19:21,561 [DEBUG] app.services.data_processing_service: DataProcessor.city_detected set to: True
2025-09-12 16:19:21,561 [DEBUG] app.services.data_processing_service: DataProcessor.institution_type set to: 'aucune correspondance'
2025-09-12 16:19:21,561 [DEBUG] app.services.data_processing_service: DataProcessor.number_institutions set to: 3
2025-09-12 16:19:21,561 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names set to: []
2025-09-12 16:19:21,561 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_with_types set to: []
2025-09-12 16:19:21,561 [DEBUG] app.services.data_processing_service: DataProcessor.institution_names_intent set to: 'none'
2025-09-12 16:19:21,561 [DEBUG] app.services.data_processing_service: DataProcessor.institution_name_mentioned set to: False
2025-09-12 16:19:21,591 [INFO] app.services.data_processing_service: Getting institution list from coordinates DataFrame
2025-09-12 16:19:21,591 [DEBUG] app.services.data_processing_service: Loading ranking data from: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/classments-hopitaux-cliniques-2024.xlsx
2025-09-12 16:19:21,738 [DEBUG] app.services.data_processing_service: Loaded ranking DataFrame with 136 rows
2025-09-12 16:19:21,738 [DEBUG] app.services.data_processing_service: Ranking DataFrame columns: ['Spécialité', 'Catégorie', 'Sheet', 'Date']
2025-09-12 16:19:21,738 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.specialty set to: 'cancer de la vessie'
2025-09-12 16:19:21,738 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city set to: 'Paris'
2025-09-12 16:19:21,739 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.city_detected set to: True
2025-09-12 16:19:21,739 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_type set to: 'aucune correspondance'
2025-09-12 16:19:21,739 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_names set to: []
2025-09-12 16:19:21,739 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.institution_name_mentioned set to: False
2025-09-12 16:19:21,739 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator.number_institutions set to: 3
2025-09-12 16:19:21,739 [DEBUG] app.services.pipeline_orchestrator_service: PipelineOrchestrator infos - specialty: cancer de la vessie, city: Paris, institution_type: aucune correspondance, institution: [], institution_name_mentioned: False
2025-09-12 16:19:21,739 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 16:19:21,739 [INFO] app.services.data_processing_service: generate_data_response called
2025-09-12 16:19:21,739 [DEBUG] app.services.data_processing_service: Extracted values - specialty: 'cancer de la vessie', institution_type: 'aucune correspondance', city: 'Paris'
2025-09-12 16:19:21,739 [DEBUG] app.services.data_processing_service: No institution type match found, loading by specialty only
2025-09-12 16:19:21,739 [INFO] app.services.data_processing_service: Filtering ranking by criteria: specialty='cancer de la vessie', institution_type='None'
2025-09-12 16:19:21,739 [DEBUG] app.services.data_processing_service: Filtering ranking data - specialty: 'cancer de la vessie', institution_type: 'None'
2025-09-12 16:19:21,739 [DEBUG] app.services.data_processing_service: Specialty type: <class 'str'>, length: 19
2025-09-12 16:19:21,740 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer de la vessie
2025-09-12 16:19:21,741 [DEBUG] app.services.data_processing_service: All normalized specialties in DataFrame: ['ablation des varices' 'accidents vasculaires cerebraux'
 'accouchements a risques' 'accouchements normaux'
 'adenome de la prostate' 'amygdales et vegetations'
 'angioplastie coronaire' 'appendicite' 'arthrose de la main' 'audition'
 'calculs urinaires' "cancer de l'estomac et de l'œsophage"
 "cancer de l'ovaire" "cancer de l'uterus" 'cancer de la prostate'
 'cancer de la thyroide' 'cancer de la vessie'
 "cancer des os de l'enfant et de l'adolescent"
 "cancer du colon ou de l'intestin" 'cancer du foie' 'cancer du pancreas'
 'cancer du poumon' 'cancer du rein' 'cancer du sein' 'cancer orl'
 'cancers de la peau' 'cardiologie interventionnelle' 'cataracte'
 'chirurgie cardiaque adulte' 'chirurgie cardiaque pediatrique'
 "chirurgie de l'epaule" "chirurgie de l'obesite"
 'chirurgie de la cheville' 'chirurgie de la cornee'
 'chirurgie dentaire et orale de l’adulte'
 'chirurgie dentaire et orale de l’enfant et de l’adolescent'
 'chirurgie des arteres' "chirurgie des cancers osseux de l'adulte"
 'chirurgie des carotides' 'chirurgie des sarcomes des tissus mous'
 "chirurgie des testicules de l'adulte"
 "chirurgie des testicules de l'enfant et de l'adolescent"
 'chirurgie du canal carpien' "chirurgie du dos de l'adulte"
 "chirurgie du dos de l'enfant et de l'adolescent"
 'chirurgie du nez et des sinus' 'chirurgie du pied' 'chirurgie du rectum'
 'chirurgie maxillo-faciale' 'depression' "diabete de l'adulte"
 "diabete de l'enfant et de l'adolescent" 'endometriose'
 "epilepsie de l'adulte" "epilepsie de l'enfant et de l'adolescent"
 'fibrome uterin' 'glandes salivaires' 'glaucome' "hernies de l'abdomen"
 'hypertension arterielle' 'infarctus du myocarde'
 'insuffisance cardiaque' "leucemie de l'adulte"
 "leucemie de l'enfant et de l'adolescent" 'ligaments du genou'
 "lymphome-myelome de l'adulte" 'maladie de parkinson'
 "maladies inflammatoires chroniques de l'intestin (mici)"
 'medecine vasculaire' 'pneumologie' 'proctologie' 'prothese de genou'
 'prothese de hanche' 'retine' 'schizophrenie' 'sclerose en plaques'
 'stimulateurs cardiaques' 'strabisme'
 'stress post-traumatique de l’adulte' 'troubles bipolaires'
 "tumeurs du cerveau de l'adulte"
 "tumeurs du cerveau de l'enfant et de l'adolescent" 'urgences de la main'
 'vesicule biliaire']
2025-09-12 16:19:21,741 [DEBUG] app.services.data_processing_service: Normalized specialty from query: 'cancer de la vessie'
2025-09-12 16:19:21,742 [DEBUG] app.services.data_processing_service: Normalized specialty from query: ''cancer de la vessie''
2025-09-12 16:19:21,743 [DEBUG] app.services.data_processing_service: Found 2 rows matching single specialty 'cancer de la vessie' (normalized: 'cancer de la vessie')
2025-09-12 16:19:21,743 [DEBUG] app.services.data_processing_service: Specialties found after specialty filtering: ['Cancer de la vessie']
2025-09-12 16:19:21,743 [INFO] app.services.data_processing_service: generate_response_links called with matching_rows: <class 'pandas.core.frame.DataFrame'>
2025-09-12 16:19:21,743 [INFO] app.services.data_processing_service: Generating ranking links
2025-09-12 16:19:21,743 [DEBUG] app.services.data_processing_service: Checking if specialty is 'no match': cancer de la vessie
2025-09-12 16:19:21,743 [DEBUG] app.services.data_processing_service: Generating links for 2 matching rows
2025-09-12 16:19:21,744 [DEBUG] app.services.data_processing_service: Mapping institution type for URL: Public
2025-09-12 16:19:21,744 [DEBUG] app.services.data_processing_service: Generating web link for specialty 'Cancer de la vessie' and institution_type 'public'
2025-09-12 16:19:21,744 [DEBUG] app.services.data_processing_service: Mapping institution type for URL: Privé
2025-09-12 16:19:21,744 [DEBUG] app.services.data_processing_service: Generating web link for specialty 'Cancer de la vessie' and institution_type 'prive'
2025-09-12 16:19:21,744 [INFO] app.services.data_processing_service: Generated ranking links: ['https://www.lepoint.fr/hopitaux/classements/cancer-de-la-vessie-public.php', 'https://www.lepoint.fr/hopitaux/classements/cancer-de-la-vessie-prive.php']
2025-09-12 16:19:21,744 [INFO] app.services.data_processing_service: load_excel_sheets called with matching_rows of length: 2
2025-09-12 16:19:21,744 [DEBUG] app.services.data_processing_service: Loading sheet: 'CANCER_VESSIE-Public' for category: 'Public'
2025-09-12 16:19:21,898 [DEBUG] app.services.data_processing_service: Sheet 'CANCER_VESSIE-Public' loaded successfully with 40 rows
2025-09-12 16:19:21,898 [DEBUG] app.services.data_processing_service: Loading sheet: 'CANCER_VESSIE-Privé' for category: 'Privé'
2025-09-12 16:19:22,057 [DEBUG] app.services.data_processing_service: Sheet 'CANCER_VESSIE-Privé' loaded successfully with 20 rows
2025-09-12 16:19:22,057 [DEBUG] app.services.data_processing_service: Concatenating 2 dataframes
2025-09-12 16:19:22,058 [INFO] app.services.data_processing_service: Successfully loaded 2 sheets, total rows: 60
2025-09-12 16:19:22,058 [INFO] app.services.data_processing_service: Loaded specialty DataFrame
2025-09-12 16:19:22,058 [INFO] app.services.pipeline_orchestrator_service: Extracting hospital locations and calculating distances
2025-09-12 16:19:22,058 [INFO] app.services.data_processing_service: extract_local_hospitals called with df: <class 'NoneType'>
2025-09-12 16:19:22,058 [INFO] app.services.data_processing_service: Merging ranking data with hospital location data
2025-09-12 16:19:22,061 [DEBUG] app.services.data_processing_service: Merged DataFrame shape (with cities): (60, 6)
2025-09-12 16:19:22,061 [INFO] app.services.data_processing_service: get_df_with_distances called
2025-09-12 16:19:22,061 [INFO] app.services.data_processing_service: Calculating distances from query city: Paris
2025-09-12 16:19:22,098 [DEBUG] urllib3.util.retry: Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-09-12 16:19:22,098 [DEBUG] urllib3.util.retry: Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-09-12 16:19:22,098 [DEBUG] geopy: Nominatim.geocode: https://nominatim.openstreetmap.org/search?q=Paris&format=json&limit=1
2025-09-12 16:19:22,099 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): nominatim.openstreetmap.org:443
2025-09-12 16:19:22,587 [DEBUG] urllib3.connectionpool: https://nominatim.openstreetmap.org:443 "GET /search?q=Paris&format=json&limit=1 HTTP/1.1" 200 445
2025-09-12 16:19:22,589 [DEBUG] app.services.data_processing_service: Query city coordinates: (48.8588897, 2.320041)
2025-09-12 16:19:22,635 [DEBUG] app.services.data_processing_service: DataFrame with distances shape after filtering: (60, 7)
2025-09-12 16:19:22,635 [DEBUG] app.services.data_processing_service: Distance column values after filtering: [398.70213057522426, 664.1329805968085, 415.6976821108837, 456.3753545488687, 628.5636395855853, 371.53864948697446, 188.04439273291007, 347.38835700895703, 204.84959346013898, 345.4649244848459, 595.5008902204977, 411.1022519634651, 498.30864007464044, 307.11690064797057, 587.9427444030024, 199.5223595902802, 284.075379397104, 112.69616845777115, 263.2951918331629, 579.7853407617778, 15.448518739010675, 587.9427444030024, 439.88315580403156, 400.657053919146, 498.30864007464044, 548.2992970130894, 263.2951918331629, 686.5090545808996, 439.43590560192064, 381.05038822552, 411.1022519634651, 483.6329891583387, 2.1651925416878903, 5.820139852698343, 7.058718567800975, 13.344491221595566, 366.59097743231456, 2.1651925416878903, 284.5159766579497, 287.7829290194155, 2.1651925416878903, 2.1651925416878903, 661.6477361717699, 2.1651925416878903, 2.1651925416878903, 661.6477361717699, 204.84959346013898, 639.5091707240583, 376.32784187895174, 382.45487086736125, 661.6477361717699, 2.1651925416878903, 498.30864007464044, 688.455077598661, 614.0681822359634, 504.2656113212524, 345.4649244848459, 652.2830983962782, 590.2248196222363, 579.7853407617778]
2025-09-12 16:19:22,635 [DEBUG] app.services.pipeline_orchestrator_service: build_ranking_dataframe_with_distances returned DataFrame: <class 'pandas.core.frame.DataFrame'>
2025-09-12 16:19:22,636 [DEBUG] app.services.pipeline_orchestrator_service: Checking if DataFrame is None
2025-09-12 16:19:22,636 [DEBUG] app.services.pipeline_orchestrator_service: Retrieved DataFrame shape: (60, 7)
2025-09-12 16:19:22,636 [DEBUG] app.services.pipeline_orchestrator_service: Checking for geolocation API errors
2025-09-12 16:19:22,636 [DEBUG] app.services.pipeline_orchestrator_service: Getting ranking link for UI
2025-09-12 16:19:22,636 [DEBUG] app.services.pipeline_orchestrator_service: Checking for specialty_ranking_unavailable
2025-09-12 16:19:22,636 [DEBUG] app.services.pipeline_orchestrator_service: Checking if institution is mentioned
2025-09-12 16:19:22,636 [DEBUG] app.services.pipeline_orchestrator_service: Checking if city is detected
2025-09-12 16:19:22,636 [DEBUG] app.services.pipeline_orchestrator_service: [DF COLUMNS] DataFrame columns before city/distance selection: ['Etablissement', 'Ville', 'Latitude', 'Longitude', 'Catégorie', 'Note / 20', 'Distance']
2025-09-12 16:19:22,636 [DEBUG] app.services.pipeline_orchestrator_service: Unique cities in DataFrame before select_hospitals: ['Pierre-Bénite' 'Bayonne' 'Brive-la-Gaillarde' 'Chambéry' 'Dax'
 'La Roche-sur-Yon' 'Valenciennes' 'Clermont-Ferrand' 'Lille' 'Limoges'
 'Montpellier' 'Saint-Etienne' 'Bordeaux' 'Rennes' 'Toulouse' 'Caen'
 'Vandœuvre-lès-Nancy' 'Salouel' 'Angers' 'Nîmes' 'Ermont' 'Royan'
 'Strasbourg' 'Albi' 'Mougins' 'Lorient' 'Saint-Nazaire' 'Grenoble'
 'Paris' 'Le Kremlin-Bicêtre' 'Suresnes' 'Créteil' 'Trévenans' 'Nancy'
 'Vantoux' 'Marseille' 'Aix-en-Provence' 'Plérin' 'Colmar' 'Cabestany'
 'Boujan-sur-Libron' 'Brest' 'Pau' 'Reims']
2025-09-12 16:19:22,636 [INFO] app.services.pipeline_orchestrator_service: City detected, preparing to call select_hospitals.
2025-09-12 16:19:22,637 [DEBUG] app.services.pipeline_orchestrator_service: About to call select_hospitals with df columns: ['Etablissement', 'Ville', 'Latitude', 'Longitude', 'Catégorie', 'Note / 20', 'Distance'], city: Paris, number_institutions: 3
2025-09-12 16:19:22,637 [INFO] app.services.data_processing_service: Selecting hospitals for city: Paris with number_institutions: 3
2025-09-12 16:19:22,637 [INFO] app.services.data_processing_service: Found 7 hospitals in city 'Paris', meeting the requirement of 3.
2025-09-12 16:19:22,641 [DEBUG] app.services.pipeline_orchestrator_service: Formatting response with specialty: base_message='Voici les meilleurs établissements (rayon utilisé : 0 km)', count=3, radius_km=0, city=Paris
2025-09-12 16:19:22,641 [DEBUG] app.services.pipeline_orchestrator_service: Normalizing specialty for display: cancer de la vessie
2025-09-12 16:19:22,641 [INFO] app.services.pipeline_orchestrator_service: Creating response and logging for prompt: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 16:19:22,641 [DEBUG] app.services.pipeline_orchestrator_service: Sanity check results for costs/tokens aggregation: {'conversation_limit': {'passed': True}, 'message_length': {'passed': True}, 'message_pertinence': {'passed': True, 'cost': 0.00028949999999999994, 'token_usage': 1924}, 'passed': True, 'total_cost': 0.00028949999999999994, 'total_tokens': 1924}
2025-09-12 16:19:22,641 [DEBUG] app.services.pipeline_orchestrator_service: Query analyst results for costs/tokens aggregation: {'city': 'Paris', 'city_detected': True, 'city_detection_method': 'llm', 'city_cost': 7.86e-05, 'city_token_usage': 318, 'institution_name_mentioned': False, 'institution_names': None, 'institution_names_detection_method': 'llm', 'institution_names_cost': 0.00017055, 'institution_names_token_usage': 1104, 'institution_names_intent': 'none', 'institution_type': 'aucune correspondance', 'institution_type_detection_method': 'llm', 'institution_type_cost': 3.27e-05, 'institution_type_token_usage': 215, 'specialty': 'cancer de la vessie', 'specialty_detection_method': 'llm', 'specialty_cost': 6.765e-05, 'specialty_token_usage': 0, 'number_institutions': 3, 'number_institutions_detection_method': 'llm', 'number_institutions_cost': 4.71e-05, 'number_institutions_token_usage': 311, 'total_cost': 0.0003966, 'total_token_usage': 1948}
2025-09-12 16:19:22,641 [DEBUG] app.services.pipeline_orchestrator_service: Conversation analyst results for costs/tokens aggregation: None
2025-09-12 16:19:22,641 [INFO] app.services.pipeline_orchestrator_service: Aggregated costs and token usage: {'total_cost_sanity_checks_analyst': 0.00028949999999999994, 'total_cost_query_analyst': 0.0007932, 'total_cost_conversation_analyst': 0.0, 'total_cost': 0.0010826999999999998, 'total_token_usage_sanity_checks_analyst': 1924, 'total_token_usage_query_analyst': 0, 'total_token_usage_conversation_analyst': 0, 'total_token_usage': 1924}
2025-09-12 16:19:22,641 [INFO] app.services.pipeline_orchestrator_service: Final cost/token usage aggregation: {'total_cost_sanity_checks_analyst': 0.00028949999999999994, 'total_cost_query_analyst': 0.0007932, 'total_cost_conversation_analyst': 0.0, 'total_cost': 0.0010826999999999998, 'total_token_usage_sanity_checks_analyst': 1924, 'total_token_usage_query_analyst': 0, 'total_token_usage_conversation_analyst': 0, 'total_token_usage': 1924}
2025-09-12 16:19:22,642 [INFO] app.services.pipeline_orchestrator_service: Detected variables: specialty=cancer de la vessie, city=Paris, institution_type=aucune correspondance, institution_names=[], number_institutions=3
2025-09-12 16:19:22,642 [INFO] app.services.data_processing_service: Saving Q&A to CSV: Quels sont les meilleurs hôpitaux à Paris pour la cancer de la vessie ?
2025-09-12 16:19:22,643 [DEBUG] app.services.data_processing_service: CSV written to /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/history/results_history_mvp.csv
2025-09-12 16:19:22,643 [DEBUG] app.services.pipeline_orchestrator_service: Formatted response: Voici les meilleurs établissements (rayon utilisé : 0 km)
<br>Aucun établissement privé trouvé.<br>Voici les établissements publics :<br>Institut mutualiste Montsouris, Paris (75): Un établissement Public situé à 2 km. avec une note de 18.63 de 20<br>Hôpital Saint-Louis, Paris (75): Un établissement Public situé à 2 km. avec une note de 18.27 de 20<br>Hôpital européen Georges-Pompidou, Paris (75): Un établissement Public situé à 2 km. avec une note de 18.26 de 20

🔗 Consultez la méthodologie de palmarès hopitaux <a href="https://www.lepoint.fr/sante/la-methodologie-du-palmares-des-hopitaux-et-cliniques-du-point-2024--04-12-2024-2577146_40.php" target="_blank">ici</a>.
2025-09-12 16:19:22,643 [ERROR] app.api.routes: Error processing /ask request: 1 validation error for AskResponse
result
  Input should be a valid string [type=string_type, input_value=AskResponse(result='Voici...2-2024-2577146_40.php']), input_type=AskResponse]
    For further information visit https://errors.pydantic.dev/2.11/v/string_type
2025-09-12 16:21:45,608 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:21:45,609 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:21:45,609 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:21:45,609 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:21:45,611 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:21:45,611 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:21:45,611 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:21:45,714 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:21:45,714 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:21:45,714 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:21:45,718 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:21:45,718 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:21:45,925 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:21:45,925 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:21:45,925 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:21:45,926 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:21:45,927 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:21:45,927 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:21:46,003 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:21:46,004 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:21:46,004 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:21:46,006 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:21:46,006 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:21:46,006 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:21:46,006 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:21:46,006 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:21:46,006 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:21:46,006 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:21:46,006 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:21:46,007 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:21:46,007 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:21:46,007 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:21:46,082 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:21:46,082 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:21:46,083 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:21:46,084 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:21:46,085 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:21:46,114 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:21:46,116 [INFO] main: Creating FastAPI app
2025-09-12 16:21:46,116 [INFO] main: CORS middleware added
2025-09-12 16:21:46,118 [INFO] main: API router included
2025-09-12 16:22:20,510 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:22:20,510 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:22:20,510 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:22:20,510 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:22:20,512 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:22:20,512 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:22:20,512 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:22:20,622 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:22:20,622 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:22:20,622 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:22:20,626 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:22:20,626 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:22:20,841 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:22:20,842 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:22:20,842 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:22:20,843 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:22:20,843 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:22:20,843 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:22:20,922 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:22:20,922 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:22:20,922 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:22:20,924 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:22:20,924 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:22:20,924 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:22:20,924 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:22:20,924 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:22:20,925 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:22:20,925 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:22:20,925 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:22:20,925 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:22:20,926 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:22:20,926 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:22:21,004 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:22:21,005 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:22:21,005 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:22:21,006 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:22:21,007 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:22:21,036 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:22:21,039 [INFO] main: Creating FastAPI app
2025-09-12 16:22:21,039 [INFO] main: CORS middleware added
2025-09-12 16:22:21,040 [INFO] main: API router included
2025-09-12 16:23:12,095 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:23:12,095 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:23:12,095 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:23:12,096 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:23:12,098 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:23:12,098 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:23:12,098 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:23:12,201 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:23:12,201 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:23:12,201 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:23:12,205 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:23:12,205 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:23:12,407 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:23:12,407 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:23:12,407 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:23:12,408 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:23:12,408 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:23:12,408 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:23:12,483 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:23:12,483 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:23:12,484 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:23:12,486 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:23:12,486 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:23:12,486 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:23:12,486 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:23:12,486 [INFO] app.services.pipeline_orchestrator_service: Initializing PipelineOrchestrator
2025-09-12 16:23:12,486 [INFO] app.services.data_processing_service: Initializing DataProcessor
2025-09-12 16:23:12,486 [INFO] app.services.llm_handler_service: LLMHandler __init__ called
2025-09-12 16:23:12,486 [INFO] app.services.llm_handler_service: Initializing LLMHandler
2025-09-12 16:23:12,487 [INFO] app.services.llm_handler_service: init_model called: Initializing ChatOpenAI model
2025-09-12 16:23:12,487 [DEBUG] app.services.llm_handler_service: OPENAI_API_KEY loaded: set
2025-09-12 16:23:12,487 [DEBUG] app.services.llm_handler_service: Creating ChatOpenAI instance
2025-09-12 16:23:12,565 [INFO] app.services.llm_handler_service: ChatOpenAI model initialized
2025-09-12 16:23:12,565 [INFO] app.services.llm_handler_service: Trying to load mapping_word_path: /Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data/resultats_llm_v5.csv
2025-09-12 16:23:12,566 [INFO] app.services.llm_handler_service: Files in data directory (/Users/apassan/Documents/Dev/ChatbotHopitaux/backendchatbothopitaux/data): ['classments-hopitaux-cliniques-2024.xlsx', "Tableaux_d'honneur_2024_PRIVE.csv", 'fichier_hopitaux_avec_coordonnees_avec_privacitee.xlsx', "Tableaux_d'honneur_2024_PUBLIC.csv", 'resultats_llm_v5.csv']
2025-09-12 16:23:12,567 [INFO] app.features.conversation.conversation_analyst: Initializing ConversationAnalyst
2025-09-12 16:23:12,567 [INFO] app.features.conversation.llm_responder: Initializing LLMResponder
2025-09-12 16:23:12,599 [INFO] app.features.sanity_checks.sanity_checks_analyst: Initializing SanityChecksAnalyst
2025-09-12 16:23:12,600 [INFO] main: Creating FastAPI app
2025-09-12 16:23:12,601 [INFO] main: CORS middleware added
2025-09-12 16:23:12,602 [INFO] main: API router included
